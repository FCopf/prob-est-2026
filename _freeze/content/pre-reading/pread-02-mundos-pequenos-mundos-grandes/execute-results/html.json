{
  "hash": "479d32dfa3703f3032e70b4a79ff8151",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Mundos Pequenos e Mundos Grandes\"\nsubtitle: \"Probabilidade e EstatÃ­stica â€” Aula 2\"\nauthor:\n  - \"Prof. Fabio Cop (*fcferreira@unifesp.br*)\"\n  - \"Instituto do Mar - Unifesp\"\ndate: today\nlang: pt-BR\nlanguage:\n  title-block-author-single: \"\"\n  title-block-author-plural: \"\"\nformat:\n  html:\n    toc: true\n    toc-title: \"ConteÃºdo\"\n    toc-depth: 3\n    number-sections: true\n    embed-resources: true\n    code-fold: false\n    code-tools: true\nexecute:\n  eval: false\n  echo: true\n---\n\n\n\n\n::: {.callout-note appearance=\"minimal\" title=\"Sobre este material\"}\nTraduÃ§Ã£o adaptada do livro *Statistical Rethinking: A Bayesian Course with Examples in R and Stan* (2Âª ed.) de Richard McElreath. Os recursos originais do autor, vÃ­deos das aulas, cÃ³digos e materiais complementares, estÃ£o disponÃ­veis em [https://xcelab.net/rm/](https://xcelab.net/rm/) e [https://github.com/rmcelreath/stat_rethinking_2026](https://github.com/rmcelreath/stat_rethinking_2026).\n:::\n\nQuando Cristoforo Colombo (CristÃ³vÃ£o Colombo) navegou infamemente para o oeste no ano de 1492, ele acreditava que a Terra era esfÃ©rica. Nisso, ele era como a maioria das pessoas instruÃ­das de sua Ã©poca. Ele diferia da maioria, porÃ©m, ao acreditar que o planeta era muito menor do que realmente Ã© â€” apenas 30.000 km ao redor de seu equador, em vez dos 40.000 km reais (Figura 2.1). Esse foi um dos erros mais consequentes da histÃ³ria europeia. Se Colombo tivesse acreditado que a Terra tinha 40.000 km de circunferÃªncia, ele teria raciocinado corretamente que sua frota nÃ£o poderia carregar comida e Ã¡gua potÃ¡vel suficientes para completar uma viagem inteiramente para o oeste atÃ© a Ãsia. Mas com 30.000 km de circunferÃªncia, a Ãsia estaria um pouco a oeste da costa da CalifÃ³rnia. Era possÃ­vel carregar suprimentos suficientes para chegar tÃ£o longe. Encorajado em parte por sua estimativa nÃ£o convencional, Colombo zarpou, eventualmente aportando nas Bahamas.\n\nColombo fez uma prediÃ§Ã£o baseada em sua visÃ£o de que o mundo era pequeno. Mas como ele vivia em um mundo grande, aspectos da prediÃ§Ã£o estavam errados. No seu caso, o erro foi sortudo. Seu modelo de mundo pequeno estava errado de uma maneira inesperada: havia muita terra no caminho. Se ele tivesse errado da maneira esperada, com nada alÃ©m de oceano entre a Europa e a Ãsia, ele e toda a sua expediÃ§Ã£o teriam ficado sem suprimentos muito antes de alcanÃ§ar as Ãndias Orientais.\n\nOs mundos pequeno e grande de Colombo oferecem um contraste entre modelo e realidade. Toda modelagem estatÃ­stica possui esses mesmos dois enquadramentos: o mundo pequeno do modelo em si e o mundo grande no qual esperamos aplicar o modelo. Navegar entre esses dois mundos permanece um desafio central da modelagem estatÃ­stica. O desafio Ã© agravado quando se esquece a distinÃ§Ã£o.\n\nO **mundo pequeno** Ã© o mundo lÃ³gico autocontido do modelo. Dentro do mundo pequeno, todas as possibilidades sÃ£o nomeadas. NÃ£o hÃ¡ surpresas puras, como a existÃªncia de um enorme continente entre a Europa e a Ãsia. Dentro do mundo pequeno do modelo, Ã© importante ser capaz de verificar a lÃ³gica do modelo, assegurando que ele funciona conforme esperado sob suposiÃ§Ãµes favorÃ¡veis. Modelos bayesianos tÃªm algumas vantagens nesse aspecto, pois possuem reivindicaÃ§Ãµes razoÃ¡veis de otimalidade: nenhum modelo alternativo poderia fazer melhor uso da informaÃ§Ã£o nos dados e apoiar melhores decisÃµes, assumindo que o mundo pequeno Ã© uma descriÃ§Ã£o precisa do mundo real.\n\nO **mundo grande** Ã© o contexto mais amplo no qual se aplica um modelo. No mundo grande, podem existir eventos que nÃ£o foram imaginados no mundo pequeno. AlÃ©m disso, o modelo Ã© sempre uma representaÃ§Ã£o incompleta do mundo grande, e portanto cometerÃ¡ erros, mesmo que todos os tipos de eventos tenham sido devidamente nomeados. A consistÃªncia lÃ³gica de um modelo no mundo pequeno nÃ£o Ã© garantia de que ele serÃ¡ Ã³timo no mundo grande. Mas certamente Ã© um conforto reconfortante.\n\n![](cap-02-small-worlds-large-worlds-pt/_page_1_Figure_2.jpeg)\n\nFigura 2.1. IlustraÃ§Ã£o do globo de Martin Behaim de 1492, mostrando o mundo pequeno que Colombo antecipava. A Europa estÃ¡ no lado direito. A Ãsia estÃ¡ Ã  esquerda. A grande ilha rotulada \"Cipangu\" Ã© o JapÃ£o.\n\nNeste capÃ­tulo, vocÃª comeÃ§arÃ¡ a construir modelos bayesianos. A maneira como modelos bayesianos aprendem a partir de evidÃªncias Ã© indiscutivelmente Ã³tima no mundo pequeno. Quando suas suposiÃ§Ãµes se aproximam da realidade, eles tambÃ©m tÃªm bom desempenho no mundo grande. Mas o desempenho no mundo grande precisa ser demonstrado, e nÃ£o deduzido logicamente. Transitar entre esses dois mundos permite que tanto mÃ©todos formais, como a inferÃªncia bayesiana, quanto mÃ©todos informais, como a revisÃ£o por pares, desempenhem um papel indispensÃ¡vel.\n\nEste capÃ­tulo foca no mundo pequeno. Ele explica a teoria da probabilidade em sua forma essencial: contando as maneiras como as coisas podem acontecer. A inferÃªncia bayesiana surge automaticamente dessa perspectiva. Em seguida, o capÃ­tulo apresenta os componentes estilizados de um modelo estatÃ­stico bayesiano, um modelo para aprender a partir de dados. Depois, mostra como animar o modelo para produzir estimativas.\n\n> **Repensando: RÃ¡pido e frugal no mundo grande.** O mundo natural Ã© complexo, como a tentativa de fazer ciÃªncia nos lembra. No entanto, tudo, desde o humilde carrapato atÃ© o industrioso esquilo e a preguiÃ§a ociosa, consegue frequentemente tomar decisÃµes adaptativas. Mas Ã© uma boa aposta que a maioria dos animais nÃ£o Ã© bayesiana, atÃ© porque ser bayesiano Ã© caro e depende de ter um bom modelo. Em vez disso, os animais usam diversas heurÃ­sticas que sÃ£o ajustadas aos seus ambientes, passados ou presentes. Essas heurÃ­sticas tomam atalhos adaptativos e, portanto, podem superar uma anÃ¡lise bayesiana rigorosa, uma vez que os custos de coleta e processamento de informaÃ§Ã£o sÃ£o levados em conta. Uma vez que vocÃª jÃ¡ sabe qual informaÃ§Ã£o ignorar ou prestar atenÃ§Ã£o, ser completamente bayesiano Ã© um desperdÃ­cio. NÃ£o Ã© necessÃ¡rio nem suficiente para tomar boas decisÃµes, como animais reais demonstram. Mas para animais humanos, a anÃ¡lise bayesiana fornece uma maneira geral de descobrir informaÃ§Ãµes relevantes e processÃ¡-las logicamente. Apenas nÃ£o pense que Ã© a Ãºnica maneira.\n\n## O jardim dos dados bifurcantes\n\nNosso objetivo nesta seÃ§Ã£o serÃ¡ construir a inferÃªncia bayesiana a partir de origens humildes, para que nÃ£o haja superstiÃ§Ã£o a respeito dela. A inferÃªncia bayesiana Ã© realmente apenas contagem e comparaÃ§Ã£o de possibilidades. Considere, por analogia, o conto de Jorge Luis Borges, \"O Jardim dos Caminhos que se Bifurcam.\" A histÃ³ria Ã© sobre um homem que encontra um livro cheio de contradiÃ§Ãµes. Na maioria dos livros, os personagens chegam a pontos da trama e devem decidir entre caminhos alternativos. Uma protagonista pode chegar Ã  casa de um homem. Ela pode matar o homem, ou entÃ£o tomar uma xÃ­cara de chÃ¡. Apenas um desses caminhos Ã© tomado â€” assassinato ou chÃ¡. Mas o livro dentro da histÃ³ria de Borges explora todos os caminhos, com cada decisÃ£o se ramificando para fora em um jardim cada vez mais amplo de caminhos bifurcantes.\n\nEste Ã© o mesmo dispositivo que a inferÃªncia bayesiana oferece. Para fazer boas inferÃªncias sobre o que realmente aconteceu, ajuda considerar tudo o que poderia ter acontecido. Uma anÃ¡lise bayesiana Ã© um jardim de dados bifurcantes, no qual sequÃªncias alternativas de eventos sÃ£o cultivadas. Ã€ medida que aprendemos sobre o que aconteceu, algumas dessas sequÃªncias alternativas sÃ£o podadas. No final, o que resta Ã© apenas o que Ã© logicamente consistente com nosso conhecimento.\n\nEssa abordagem fornece uma classificaÃ§Ã£o quantitativa de hipÃ³teses, uma classificaÃ§Ã£o que Ã© maximamente conservadora, dadas as suposiÃ§Ãµes e os dados que a alimentam. A abordagem nÃ£o pode garantir uma resposta correta em termos de mundo grande. Mas pode garantir a melhor resposta possÃ­vel, em termos de mundo pequeno, que poderia ser derivada da informaÃ§Ã£o fornecida.\n\nConsidere o seguinte exemplo didÃ¡tico.\n\n### Contando possibilidades {-}\n\nSuponha que haja um saco contendo quatro bolinhas de gude. Essas bolinhas vÃªm em duas cores: azul e branca. Sabemos que hÃ¡ quatro bolinhas no saco, mas nÃ£o sabemos quantas sÃ£o de cada cor. Sabemos que existem cinco possibilidades: (1) [âšªâšªâšªâšª], (2) [ğŸ”µâšªâšªâšª], (3) [ğŸ”µğŸ”µâšªâšª], (4) [ğŸ”µğŸ”µğŸ”µâšª], (5) [ğŸ”µğŸ”µğŸ”µğŸ”µ]. Essas sÃ£o as Ãºnicas possibilidades consistentes com o que sabemos sobre o conteÃºdo do saco. Chame essas cinco possibilidades de conjecturas.\n\nNosso objetivo Ã© descobrir qual dessas conjecturas Ã© mais plausÃ­vel, dada alguma evidÃªncia sobre o conteÃºdo do saco. Temos alguma evidÃªncia: uma sequÃªncia de trÃªs bolinhas Ã© retirada do saco, uma de cada vez, recolocando a bolinha cada vez e agitando o saco antes de retirar outra bolinha. A sequÃªncia que emerge Ã©: ğŸ”µâšªğŸ”µ, nessa ordem. Esses sÃ£o os dados.\n\nEntÃ£o, vamos plantar o jardim e ver como usar os dados para inferir o que estÃ¡ no saco. Comecemos considerando apenas a conjectura [ğŸ”µâšªâšªâšª], de que o saco contÃ©m uma bolinha azul e trÃªs brancas. Na primeira retirada do saco, uma de quatro coisas poderia acontecer, correspondendo a uma das quatro bolinhas no saco. Assim, podemos visualizar as possibilidades se ramificando:\n\n![](cap-02-small-worlds-large-worlds-pt/_page_2_Picture_1b.jpeg)\n\nNote que, embora as trÃªs bolinhas brancas pareÃ§am iguais de uma perspectiva de dados â€” afinal, registramos apenas a cor das bolinhas â€” elas sÃ£o realmente eventos diferentes. Isso Ã© importante, porque significa que hÃ¡ trÃªs vezes mais maneiras de ver âšª do que de ver ğŸ”µ.\n\nAgora considere o jardim Ã  medida que obtemos outra retirada do saco. Ele expande o jardim em mais uma camada:\n\n![](cap-02-small-worlds-large-worlds-pt/_page_2_Picture_12.jpeg)\n\nAgora hÃ¡ 16 caminhos possÃ­veis atravÃ©s do jardim, um para cada par de retiradas. Na segunda retirada do saco, cada um dos caminhos acima se bifurca novamente em quatro caminhos possÃ­veis. Por quÃª?\n\n![](cap-02-small-worlds-large-worlds-pt/_page_3_Figure_2.jpeg)\n\nFigura 2.2. Os 64 caminhos possÃ­veis gerados ao supor que o saco contÃ©m uma bolinha azul e trÃªs brancas.\n\nPorque acreditamos que nossa agitaÃ§Ã£o do saco dÃ¡ a cada bolinha uma chance justa de ser retirada, independentemente de qual bolinha foi retirada anteriormente. A terceira camada Ã© construÃ­da da mesma maneira, e o jardim completo Ã© mostrado na Figura 2.2. HÃ¡ $4^3 = 64$ caminhos possÃ­veis no total.\n\nÃ€ medida que consideramos cada retirada do saco, alguns desses caminhos sÃ£o logicamente eliminados. A primeira retirada resultou em ğŸ”µ, lembre-se, entÃ£o os trÃªs caminhos brancos na parte inferior do jardim sÃ£o eliminados imediatamente. Se vocÃª imaginar os dados reais traÃ§ando um caminho pelo jardim, eles devem ter passado pelo Ãºnico caminho azul perto da origem. A segunda retirada do saco produz âšª, entÃ£o trÃªs dos caminhos que se bifurcam a partir da primeira bolinha azul permanecem. Conforme os dados traÃ§am um caminho, sabemos que ele deve ter passado por um desses trÃªs caminhos brancos (depois do primeiro caminho azul), mas nÃ£o sabemos por qual, porque registramos apenas a cor de cada bolinha. Finalmente, a terceira retirada Ã© ğŸ”µ. Cada um dos trÃªs caminhos restantes na camada intermediÃ¡ria sustenta um caminho azul, deixando um total de trÃªs maneiras para a sequÃªncia ğŸ”µâšªğŸ”µ aparecer, supondo que o saco contÃ©m [ğŸ”µâšªâšªâšª]. A Figura 2.3 mostra o jardim novamente, agora com caminhos logicamente eliminados esmaecidos. NÃ£o podemos ter certeza de qual desses trÃªs caminhos os dados reais tomaram. Mas, enquanto estivermos considerando apenas a possibilidade de que o saco contenha uma bolinha azul e trÃªs brancas, podemos ter certeza de que os dados tomaram um desses trÃªs caminhos. Esses sÃ£o os Ãºnicos caminhos consistentes tanto com nosso conhecimento sobre o conteÃºdo do saco (quatro bolinhas, brancas ou azuis) quanto com os dados (ğŸ”µâšªğŸ”µ).\n\nIsso demonstra que hÃ¡ trÃªs (de 64) maneiras para um saco contendo [ğŸ”µâšªâšªâšª] produzir os dados ğŸ”µâšªğŸ”µ. NÃ£o temos como decidir entre essas trÃªs maneiras. O poder inferencial vem de comparar essa contagem com os nÃºmeros de maneiras que cada uma das outras conjecturas sobre o conteÃºdo do saco poderia produzir os mesmos dados. Por exemplo, considere a conjectura [âšªâšªâšªâšª]. HÃ¡ zero maneiras para essa conjectura produzir os dados observados, porque mesmo uma Ãºnica ğŸ”µ Ã© logicamente incompatÃ­vel com ela. A conjectura [ğŸ”µğŸ”µğŸ”µğŸ”µ] Ã© igualmente logicamente incompatÃ­vel com os dados. Portanto, podemos eliminar essas duas conjecturas, porque nenhuma fornece sequer um Ãºnico caminho consistente com os dados.\n\nA Figura 2.4 exibe o jardim completo agora, para as trÃªs conjecturas restantes: [ğŸ”µâšªâšªâšª], [ğŸ”µğŸ”µâšªâšª] e [ğŸ”µğŸ”µğŸ”µâšª]. A fatia superior esquerda exibe o mesmo jardim da Figura 2.3. A superior direita mostra o jardim anÃ¡logo para a conjectura de que o saco contÃ©m trÃªs bolinhas azuis e uma branca. E a fatia inferior mostra o jardim para duas bolinhas azuis\n\n![](cap-02-small-worlds-large-worlds-pt/_page_4_Figure_2.jpeg)\n\nFigura 2.3. ApÃ³s eliminar caminhos inconsistentes com a sequÃªncia observada, apenas 3 dos 64 caminhos permanecem.\n\ne duas brancas. Agora contamos todas as maneiras que cada conjectura poderia produzir os dados observados. Para uma azul e trÃªs brancas, hÃ¡ trÃªs maneiras, como jÃ¡ contamos. Para duas azuis e duas brancas, hÃ¡ oito caminhos que se bifurcam pelo jardim que sÃ£o logicamente consistentes com a sequÃªncia observada. Para trÃªs azuis e uma branca, hÃ¡ nove caminhos que sobrevivem.\n\nPara resumir, consideramos cinco conjecturas diferentes sobre o conteÃºdo do saco, variando de zero bolinhas azuis a quatro bolinhas azuis. Para cada uma dessas conjecturas, contamos quantas sequÃªncias, caminhos pelo jardim de dados bifurcantes, poderiam potencialmente produzir os dados observados, ğŸ”µâšªğŸ”µ\n\n| Conjectura                          | Maneiras de produzir ğŸ”µâšªğŸ”µ  |\n|-------------------------------------|------------------------------|\n| [âšªâšªâšªâšª]                          | $0 \\times 4 \\times 0 = 0$   |\n| [ğŸ”µâšªâšªâšª]                          | $1 \\times 3 \\times 1 = 3$   |\n| [ğŸ”µğŸ”µâšªâšª]                          | $2 \\times 2 \\times 2 = 8$   |\n| [ğŸ”µğŸ”µğŸ”µâšª]                          | $3 \\times 1 \\times 3 = 9$   |\n| [ğŸ”µğŸ”µğŸ”µğŸ”µ]                          | $4 \\times 0 \\times 4 = 0$   |\n\nNote que o nÃºmero de maneiras de produzir os dados ğŸ”µâšªğŸ”µ, para cada conjectura, pode ser calculado contando primeiro o nÃºmero de caminhos em cada \"anel\" do jardim e depois multiplicando essas contagens. Isso Ã© apenas um artifÃ­cio computacional. Ele nos diz a mesma coisa que a Figura 2.4, mas sem precisar desenhar o jardim. O fato de que os nÃºmeros sÃ£o multiplicados durante o cÃ¡lculo nÃ£o muda o fato de que isso ainda Ã© apenas contagem de caminhos logicamente possÃ­veis. Esse ponto surgirÃ¡ novamente quando vocÃª encontrar a representaÃ§Ã£o mais formal da inferÃªncia bayesiana.\n\nEntÃ£o, para que servem essas contagens? Ao comparar essas contagens, temos parte de uma soluÃ§Ã£o para uma maneira de classificar a plausibilidade relativa de cada composiÃ§Ã£o conjecturada do saco. Mas Ã© apenas uma parte de uma soluÃ§Ã£o, porque, para comparar essas contagens, primeiro precisamos decidir de quantas maneiras cada conjectura poderia ela mesma ser realizada. PoderÃ­amos argumentar que, quando nÃ£o temos motivo para supor o contrÃ¡rio, podemos simplesmente considerar cada conjectura igualmente plausÃ­vel e comparar as contagens diretamente. Mas frequentemente temos motivo para supor o contrÃ¡rio.\n\n![](cap-02-small-worlds-large-worlds-pt/_page_5_Figure_2.jpeg)\n\nFigura 2.4. O jardim de dados bifurcantes, mostrando para cada possÃ­vel composiÃ§Ã£o do saco os caminhos bifurcantes que sÃ£o logicamente compatÃ­veis com os dados.\n\n> **Repensando: Justificativa.** Usar contagens de caminhos pelo jardim como medidas de plausibilidade relativa pode ser justificado de diversas maneiras. A justificativa aqui Ã© lÃ³gica: se desejamos raciocinar sobre plausibilidade e permanecer consistentes com a lÃ³gica ordinÃ¡ria â€” afirmaÃ§Ãµes sobre verdadeiro e falso â€” entÃ£o devemos obedecer a este procedimento. HÃ¡ diversas outras justificativas que levam ao mesmo procedimento matemÃ¡tico. Independentemente de como vocÃª escolha justificÃ¡-lo filosoficamente, note que ele realmente funciona. Justificativas e filosofia motivam procedimentos, mas sÃ£o os resultados que importam. As muitas aplicaÃ§Ãµes bem-sucedidas no mundo real da inferÃªncia bayesiana podem ser toda a justificativa que vocÃª precisa. Apenas tenha cuidado para nÃ£o supor que, porque a inferÃªncia bayesiana Ã© justificada, nenhuma outra abordagem tambÃ©m pode ser justificada. Golems vÃªm em muitos tipos, e alguns de todos os tipos sÃ£o Ãºteis.\n\n### Combinando outras informaÃ§Ãµes {-}\n\nPodemos ter informaÃ§Ãµes adicionais sobre a plausibilidade relativa de cada conjectura. Essa informaÃ§Ã£o pode surgir do conhecimento de como o conteÃºdo do saco foi gerado. Pode tambÃ©m surgir de dados anteriores. Seja qual for a fonte, seria Ãºtil ter uma maneira de combinar diferentes fontes de informaÃ§Ã£o para atualizar as plausibilidades. Felizmente, hÃ¡ uma soluÃ§Ã£o natural: basta multiplicar as contagens.\n\nPara entender essa soluÃ§Ã£o, suponha que estejamos dispostos a dizer que cada conjectura Ã© igualmente plausÃ­vel no inÃ­cio. EntÃ£o, simplesmente comparamos as contagens de maneiras em que cada conjectura Ã© compatÃ­vel com os dados observados. Essa comparaÃ§Ã£o sugere que [ğŸ”µğŸ”µğŸ”µâšª] Ã© ligeiramente mais plausÃ­vel que [ğŸ”µğŸ”µâšªâšª], e ambos sÃ£o cerca de trÃªs vezes mais plausÃ­veis que [ğŸ”µâšªâšªâšª]. Como essas sÃ£o nossas contagens iniciais, e vamos atualizÃ¡-las em seguida, vamos rotulÃ¡-las *a priori*.\n\nAgora suponha que retiremos outra bolinha do saco para obter outra observaÃ§Ã£o: ğŸ”µ. Agora vocÃª tem duas escolhas. VocÃª poderia comeÃ§ar tudo de novo, fazendo um jardim com quatro camadas para traÃ§ar os caminhos compatÃ­veis com a sequÃªncia de dados ğŸ”µ âšª ğŸ”µ ğŸ”µ. Ou poderia pegar as contagens anteriores â€” as contagens a priori â€” sobre as conjecturas (0, 3, 8, 9, 0) e simplesmente atualizÃ¡-las Ã  luz da nova observaÃ§Ã£o. Acontece que esses dois mÃ©todos sÃ£o matematicamente idÃªnticos, desde que a nova observaÃ§Ã£o seja logicamente independente das observaÃ§Ãµes anteriores.\n\nVeja como fazer isso. Primeiro, contamos o nÃºmero de maneiras que cada conjectura poderia produzir a nova observaÃ§Ã£o, ğŸ”µ. Depois multiplicamos cada uma dessas novas contagens pelos nÃºmeros a priori de maneiras para cada conjectura. Em forma de tabela:\n\n| Conjectura | Maneiras de produzir ğŸ”µ | Contagens a priori | Nova contagem     |\n|------------|-----------|--------|-------------------|\n| [âšªâšªâšªâšª]   | 0         | 0      | $0 \\times 0 = 0$  |\n| [ğŸ”µâšªâšªâšª]   | 1         | 3      | $3 \\times 1 = 3$  |\n| [ğŸ”µğŸ”µâšªâšª]   | 2         | 8      | $8 \\times 2 = 16$ |\n| [ğŸ”µğŸ”µğŸ”µâšª]   | 3         | 9      | $9 \\times 3 = 27$ |\n| [ğŸ”µğŸ”µğŸ”µğŸ”µ]   | 4         | 0      | $0 \\times 4 = 0$  |\n\nAs novas contagens na coluna da direita acima resumem toda a evidÃªncia para cada conjectura. Ã€ medida que novos dados chegam, e desde que esses dados sejam independentes das observaÃ§Ãµes anteriores, o nÃºmero de maneiras logicamente possÃ­veis para uma conjectura produzir todos os dados atÃ© aquele ponto pode ser calculado simplesmente multiplicando a nova contagem pela contagem antiga.\n\nEssa abordagem de atualizaÃ§Ã£o nada mais Ã© do que afirmar que (1) quando temos informaÃ§Ã£o anterior sugerindo que hÃ¡ $W_{\\rm prior}$ maneiras para uma conjectura produzir uma observaÃ§Ã£o anterior $D_{\\rm prior}$ e (2) adquirimos novas observaÃ§Ãµes $D_{\\rm new}$ que a mesma conjectura pode produzir de $W_{\\rm new}$ maneiras, entÃ£o (3) o nÃºmero de maneiras que a conjectura pode explicar tanto $D_{\\rm prior}$ quanto $D_{\\rm new}$ Ã© simplesmente o produto $W_{\\rm prior} \\times W_{\\rm new}$. Por exemplo, na tabela acima, a conjectura [ğŸ”µğŸ”µâšªâšª] tem $W_{\\rm prior} = 8$ maneiras de produzir $D_{\\rm prior} = ğŸ”µâšªğŸ”µ$. Ela tambÃ©m tem $W_{\\rm new} = 2$ maneiras de produzir a nova observaÃ§Ã£o $D_{\\rm new} = ğŸ”µ$. Portanto, hÃ¡ $8 \\times 2 = 16$ maneiras para a conjectura produzir tanto $D_{\\rm prior}$ quanto $D_{\\rm new}$. Por que multiplicar? A multiplicaÃ§Ã£o Ã© apenas um atalho para enumerar e contar todos os caminhos pelo jardim que poderiam produzir todas as observaÃ§Ãµes.\n\nNeste exemplo, os dados a priori e os novos dados sÃ£o do mesmo tipo: bolinhas retiradas do saco. Mas, em geral, os dados a priori e os novos dados podem ser de tipos diferentes. Suponha, por exemplo, que alguÃ©m da fÃ¡brica de bolinhas lhe diga que bolinhas azuis sÃ£o raras. EntÃ£o, para cada saco contendo [ğŸ”µğŸ”µğŸ”µâšª], eles fizeram dois sacos contendo [ğŸ”µğŸ”µâšªâšª] e trÃªs sacos contendo [ğŸ”µâšªâšªâšª]. Eles tambÃ©m garantiram que cada saco contivesse pelo menos uma bolinha azul e uma branca. Podemos atualizar nossas contagens novamente:\n\n|  Conjectura   |  Contagem a priori  |   Contagem da fÃ¡brica   |       Nova contagem             |\n|---------------|---------------------|-------------------------|---------------------------------|\n| [âšªâšªâšªâšª]    | 0                   | 0                       | $0 \\times 0 = 0$                |\n| [ğŸ”µâšªâšªâšª]    | 3                   | 3                       | $3 \\times 3 = 9$                |\n| [ğŸ”µğŸ”µâšªâšª]    | 16                  | 2                       | $16 \\times 2 = 32$              |\n| [ğŸ”µğŸ”µğŸ”µâšª]    | 27                  | 1                       | $27 \\times 1 = 27$              |\n| [ğŸ”µğŸ”µğŸ”µğŸ”µ]    | 0                   | 0                       | $0 \\times 0 = 0$                |\n\nAgora a conjectura [ğŸ”µğŸ”µâšªâšª] Ã© a mais plausÃ­vel, mas apenas ligeiramente melhor que [ğŸ”µğŸ”µğŸ”µâšª].\n\n> **Repensando: IgnorÃ¢ncia original.** Qual suposiÃ§Ã£o devemos usar quando nÃ£o hÃ¡ informaÃ§Ã£o anterior sobre as conjecturas? A soluÃ§Ã£o mais comum Ã© atribuir um nÃºmero igual de maneiras em que cada conjectura poderia estar correta, antes de ver quaisquer dados. Isso Ã© Ã s vezes conhecido como o PRINCÃPIO DA INDIFERENÃ‡A: quando nÃ£o hÃ¡ razÃ£o para dizer que uma conjectura Ã© mais plausÃ­vel que outra, pese todas as conjecturas igualmente.\n\n### De contagens a probabilidades {-}\n\nÃ‰ Ãºtil pensar nessa estratÃ©gia como aderindo a um princÃ­pio de ignorÃ¢ncia honesta: quando nÃ£o sabemos o que causou os dados, causas potenciais que podem produzir os dados de mais maneiras sÃ£o mais plausÃ­veis. Isso nos leva a contar caminhos pelo jardim de dados bifurcantes.\n\nÃ‰ difÃ­cil usar essas contagens, porÃ©m, entÃ£o quase sempre as padronizamos de uma maneira que as transforma em probabilidades. Por que Ã© difÃ­cil trabalhar com as contagens? Primeiro, como o valor relativo Ã© tudo que importa, o tamanho das contagens 3, 8 e 9 nÃ£o contÃ©m informaÃ§Ã£o de valor. Elas poderiam ser igualmente 30, 80 e 90. O significado seria o mesmo. SÃ£o apenas os valores relativos que importam. Segundo, conforme a quantidade de dados cresce, as contagens crescerÃ£o muito rapidamente, tornando-se muito grandes e difÃ­ceis de manipular.\n\nFelizmente, hÃ¡ uma maneira matemÃ¡tica de comprimir tudo isso. Especificamente, definimos a plausibilidade atualizada de cada possÃ­vel composiÃ§Ã£o do saco, apÃ³s ver os dados, como:\n\n$$ \\texttt{plausibilidade de [ğŸ”µâšªâšªâšª] apÃ³s ver ğŸ”µâšªğŸ”µ }$$\n$$\\propto$$\n$$ \\texttt{maneiras que [ğŸ”µâšªâšªâšª] pode produzir ğŸ”µâšªğŸ”µ }$$\n$$\\times$$\n$$ \\texttt{plausibilidade a priori de [ğŸ”µâšªâšªâšª] }$$\n\nAquele pequeno $\\propto$ significa *proporcional a*. Queremos comparar a plausibilidade de cada possÃ­vel composiÃ§Ã£o do saco. EntÃ£o serÃ¡ Ãºtil definir p como a proporÃ§Ã£o de bolinhas que sÃ£o azuis. Para [ğŸ”µâšªâšªâšª], p = 1/4 = 0,25. TambÃ©m defina $D_{\\text{new}} = ğŸ”µâšªğŸ”µ$. E agora podemos escrever:\n\n> plausibilidade de p apÃ³s $D_{\\text{new}} \\propto \\text{maneiras que } p$ pode produzir $D_{\\text{new}} \\times \\text{plausibilidade a priori de } p$\n\nO acima apenas significa que, para qualquer valor que p possa assumir, julgamos a plausibilidade desse valor p como proporcional ao nÃºmero de maneiras que ele pode passar pelo jardim de dados bifurcantes.\n\nFinalmente, construÃ­mos probabilidades padronizando a plausibilidade de modo que a soma das plausibilidades para todas as conjecturas possÃ­veis seja um. Tudo o que vocÃª precisa fazer para padronizar Ã© somar todos os produtos, um para cada valor que p pode assumir, e depois dividir cada produto pela soma dos produtos:\n\n$$\\texttt{plausibilidade de p apÃ³s} D_{\\text{new}} = \\frac{\\text{maneiras que } p \\text{ pode produzir } D_{\\text{new}} \\times \\text{plausibilidade a priori de } p}{\\text{soma dos produtos}}$$\n\nUm exemplo trabalhado Ã© necessÃ¡rio para que isso realmente faÃ§a sentido. EntÃ£o considere novamente a tabela de antes, agora atualizada usando nossas definiÃ§Ãµes de *p* e \"plausibilidade\":\n\n| ComposiÃ§Ã£o possÃ­vel | p       | Maneiras de produzir dados | Plausibilidade |\n|---------------------|---------|----------------------------|----------------|\n| [âšªâšªâšªâšª]           | 0       | 0                          | 0              |\n| [ğŸ”µâšªâšªâšª]           | 0,25    | 3                          | 0,15           |\n| [ğŸ”µğŸ”µâšªâšª]           | 0,5     | 8                          | 0,40           |\n| [ğŸ”µğŸ”µğŸ”µâšª]           | 0,75    | 9                          | 0,45           |\n| [ğŸ”µğŸ”µğŸ”µğŸ”µ]           | 1       | 0                          | 0              |\n\nVocÃª pode calcular rapidamente essas plausibilidades em R:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nways <- c( 0 , 3 , 8 , 9 , 0 )\nways/sum(ways)\n```\n:::\n\n\n\n\n```\n[1] 0.00 0.15 0.40 0.45 0.00\n```\n\nOs valores em ways sÃ£o os produtos mencionados antes. E sum(ways) Ã© o denominador \"soma dos produtos\" na expressÃ£o perto do topo da pÃ¡gina.\n\nEssas plausibilidades tambÃ©m sÃ£o *probabilidades* â€” sÃ£o nÃºmeros reais nÃ£o negativos (zero ou positivos) que somam um. E todas as coisas matemÃ¡ticas que vocÃª pode fazer com probabilidades tambÃ©m pode fazer com esses valores. Especificamente, cada peÃ§a do cÃ¡lculo tem um parceiro direto na teoria da probabilidade aplicada. Esses parceiros tÃªm nomes estereotipados, entÃ£o vale a pena aprendÃª-los, pois vocÃª os verÃ¡ repetidamente.\n\n- Um valor conjecturado da proporÃ§Ã£o de bolinhas azuis, *p*, Ã© geralmente chamado de valor de **PARÃ‚METRO**. Ã‰ apenas uma maneira de indexar explicaÃ§Ãµes possÃ­veis dos dados.\n- O nÃºmero relativo de maneiras que um valor *p* pode produzir os dados Ã© geralmente chamado de **VEROSSIMILHANÃ‡A**. Ã‰ derivada enumerando todas as sequÃªncias de dados possÃ­veis que poderiam ter acontecido e depois eliminando aquelas sequÃªncias inconsistentes com os dados.\n- A plausibilidade a priori de qualquer *p* especÃ­fico Ã© geralmente chamada de **PROBABILIDADE A PRIORI**.\n- A nova plausibilidade atualizada de qualquer *p* especÃ­fico Ã© geralmente chamada de **PROBABILIDADE A POSTERIORI**.\n\n> **Repensando: AleatorizaÃ§Ã£o.** Quando vocÃª embaralha um baralho de cartas ou atribui sujeitos a tratamentos jogando uma moeda, Ã© comum dizer que o baralho resultante e as atribuiÃ§Ãµes de tratamento sÃ£o aleatorizados. O que significa aleatorizar algo? Significa apenas que processamos a coisa de modo que sabemos quase nada sobre seu arranjo. Embaralhar um baralho de cartas muda nosso estado de conhecimento, de modo que nÃ£o temos mais informaÃ§Ã£o especÃ­fica sobre a ordenaÃ§Ã£o das cartas. Entretanto, o bÃ´nus que surge disso Ã© que, se realmente embaralhamos o suficiente para apagar qualquer conhecimento prÃ©vio da ordenaÃ§Ã£o, entÃ£o a ordem em que as cartas terminam Ã© muito provavelmente uma das muitas ordenaÃ§Ãµes com alta **entropia informacional**.\n\n## Construindo um modelo\n\nAo trabalhar com probabilidades em vez de contagens brutas, a inferÃªncia bayesiana se torna muito mais fÃ¡cil, mas parece muito mais difÃ­cil. EntÃ£o, nesta seÃ§Ã£o, damos sequÃªncia ao jardim de dados bifurcantes apresentando a forma convencional de um modelo estatÃ­stico bayesiano. O exemplo didÃ¡tico que usaremos aqui tem a anatomia de uma anÃ¡lise estatÃ­stica tÃ­pica, entÃ£o Ã© o estilo ao qual vocÃª se acostumarÃ¡. Mas cada peÃ§a dele pode ser mapeada no jardim de dados bifurcantes. A lÃ³gica Ã© a mesma.\n\nSuponha que vocÃª tenha um globo terrestre representando nosso planeta, a Terra. Essa versÃ£o do mundo Ã© pequena o suficiente para caber em suas mÃ£os. VocÃª tem curiosidade sobre quanta da superfÃ­cie Ã© coberta por Ã¡gua. VocÃª adota a seguinte estratÃ©gia: jogarÃ¡ o globo para cima. Quando pegÃ¡-lo, registrarÃ¡ se a superfÃ­cie sob seu dedo indicador direito Ã© Ã¡gua ou terra. EntÃ£o jogarÃ¡ o globo para cima novamente e repetirÃ¡ o procedimento. Essa estratÃ©gia gera uma sequÃªncia de amostras da superfÃ­cie do globo. As primeiras nove amostras podem parecer com:\n\n$$\\text{W L W W W L W L W}$$\n\nonde $\\text{W}$ indica Ã¡gua (water) e $\\text{L}$ indica terra (land). EntÃ£o, neste exemplo, vocÃª observa seis observaÃ§Ãµes $\\text{W}$ (Ã¡gua) e trÃªs observaÃ§Ãµes $\\text{L}$ (terra). Chame essa sequÃªncia de observaÃ§Ãµes de dados.\n\nPara colocar a lÃ³gica em movimento, precisamos fazer suposiÃ§Ãµes, e essas suposiÃ§Ãµes constituem o modelo. Projetar um modelo bayesiano simples se beneficia de um ciclo de design com trÃªs etapas.\n\n- (1) HistÃ³ria dos dados: motive o modelo narrando como os dados podem ter surgido.\n- (2) AtualizaÃ§Ã£o: eduque seu modelo alimentando-o com os dados.\n- (3) AvaliaÃ§Ã£o: todos os modelos estatÃ­sticos requerem supervisÃ£o, levando possivelmente Ã  revisÃ£o do modelo.\n\nAs prÃ³ximas seÃ§Ãµes percorrem essas etapas, no contexto da evidÃªncia do lanÃ§amento do globo.\n\n### Uma histÃ³ria dos dados {-}\n\nA anÃ¡lise bayesiana de dados geralmente significa produzir uma histÃ³ria para como os dados vieram a existir. Essa histÃ³ria pode ser descritiva, especificando associaÃ§Ãµes que podem ser usadas para prever resultados, dadas observaÃ§Ãµes. Ou pode ser causal, uma teoria de como alguns eventos produzem outros eventos. Tipicamente, qualquer histÃ³ria que vocÃª pretenda ser causal tambÃ©m pode ser descritiva. Mas muitas histÃ³rias descritivas sÃ£o difÃ­ceis de interpretar causalmente. Contudo, todas as histÃ³rias de dados sÃ£o completas, no sentido de que sÃ£o suficientes para especificar um algoritmo para simular novos dados.\n\nVocÃª pode motivar sua histÃ³ria dos dados tentando explicar como cada dado nasce. Isso geralmente significa descrever aspectos da realidade subjacente, bem como o processo de amostragem. A histÃ³ria dos dados neste caso Ã© simplesmente uma reformulaÃ§Ã£o do processo de amostragem:\n\n- (1) A verdadeira proporÃ§Ã£o de Ã¡gua cobrindo o globo Ã© $p$.\n- (2) Um Ãºnico lanÃ§amento do globo tem probabilidade $p$ de produzir uma observaÃ§Ã£o de Ã¡gua ($\\text{W}$). Tem probabilidade $1-p$ de produzir uma observaÃ§Ã£o de terra ($\\text{L}$).\n- (3) Cada lanÃ§amento do globo Ã© independente dos outros.\n\n### AtualizaÃ§Ã£o bayesiana {-}\n\nNosso problema Ã© usar a evidÃªncia â€” a sequÃªncia de lanÃ§amentos do globo â€” para decidir entre diferentes proporÃ§Ãµes possÃ­veis de Ã¡gua no globo. Essas proporÃ§Ãµes sÃ£o como as bolinhas conjecturadas dentro do saco, de antes neste capÃ­tulo. Cada proporÃ§Ã£o possÃ­vel pode ser mais ou menos plausÃ­vel, dada a evidÃªncia. Um modelo bayesiano comeÃ§a com um conjunto de plausibilidades atribuÃ­das a cada uma dessas possibilidades. Essas sÃ£o as plausibilidades a priori. EntÃ£o ele as atualiza Ã  luz dos dados, para produzir as plausibilidades a posteriori. Esse processo de atualizaÃ§Ã£o Ã© um tipo de aprendizado, chamado **atualizaÃ§Ã£o bayesiana**.\n\nApenas para efeito do exemplo, vamos programar nossa mÃ¡quina bayesiana para atribuir inicialmente a mesma plausibilidade a cada proporÃ§Ã£o de Ã¡gua, cada valor de p. Depois faremos melhor que isso. Agora olhe o grÃ¡fico superior esquerdo na Figura 2.5. A linha horizontal tracejada representa essa plausibilidade inicial de cada valor possÃ­vel de p. ApÃ³s ver o primeiro lanÃ§amento, que Ã© um \"W\", o modelo atualiza as plausibilidades para a linha sÃ³lida. A plausibilidade de p = 0 caiu agora para exatamente zero â€” o equivalente a \"impossÃ­vel\". Por quÃª? Porque observamos pelo menos uma parcela de Ã¡gua no globo, entÃ£o agora sabemos que hÃ¡ alguma Ã¡gua. O modelo executa essa lÃ³gica automaticamente. VocÃª nÃ£o precisa instruÃ­-lo a considerar essa consequÃªncia. A teoria da probabilidade cuida disso para vocÃª, porque Ã© essencialmente contagem de caminhos pelo jardim de dados bifurcantes, como na seÃ§Ã£o anterior.\n\nDa mesma forma, a plausibilidade de p > 0,5 aumentou. Isso ocorre porque ainda nÃ£o hÃ¡ evidÃªncia de que haja terra no globo, entÃ£o as plausibilidades iniciais sÃ£o modificadas para serem consistentes com isso. Note, entretanto, que sÃ£o as plausibilidades relativas que importam, e ainda nÃ£o hÃ¡\n\n![](cap-02-small-worlds-large-worlds-pt/_page_11_Figure_2.jpeg)\n\nFigura 2.5. Como um modelo bayesiano aprende. Cada lanÃ§amento do globo produz uma observaÃ§Ã£o de Ã¡gua (W) ou terra (L). A estimativa do modelo da proporÃ§Ã£o de Ã¡gua no globo Ã© uma plausibilidade para cada valor possÃ­vel. As linhas e curvas nesta figura sÃ£o essas coleÃ§Ãµes de plausibilidades. Em cada grÃ¡fico, plausibilidades anteriores (curva tracejada) sÃ£o atualizadas Ã  luz da Ãºltima observaÃ§Ã£o para produzir um novo conjunto de plausibilidades (curva sÃ³lida).\n\nmuita evidÃªncia. Portanto, as diferenÃ§as em plausibilidade ainda nÃ£o sÃ£o muito grandes. Dessa forma, a quantidade de evidÃªncia vista atÃ© agora Ã© incorporada nas plausibilidades de cada valor de p.\n\nNos grÃ¡ficos restantes da Figura 2.5, as amostras adicionais do globo sÃ£o introduzidas ao modelo, uma de cada vez. Cada curva tracejada Ã© simplesmente a curva sÃ³lida do grÃ¡fico anterior, movendo-se da esquerda para a direita e de cima para baixo. Toda vez que um \"W\" Ã© visto, o pico da curva de plausibilidade se move para a direita, em direÃ§Ã£o a valores maiores de p. Toda vez que um \"L\" Ã© visto, ela se move na outra direÃ§Ã£o. A altura mÃ¡xima da curva aumenta com cada amostra, significando que menos valores de p acumulam mais plausibilidade conforme a quantidade de evidÃªncia aumenta. Conforme cada nova observaÃ§Ã£o Ã© adicionada, a curva Ã© atualizada de maneira consistente com todas as observaÃ§Ãµes anteriores.\n\nNote que cada conjunto atualizado de plausibilidades se torna as plausibilidades iniciais para a prÃ³xima observaÃ§Ã£o. Toda conclusÃ£o Ã© o ponto de partida para inferÃªncia futura. Contudo, esse processo de atualizaÃ§Ã£o funciona tanto para trÃ¡s quanto para frente. Dado o conjunto final de plausibilidades no grÃ¡fico inferior direito da Figura 2.5, e sabendo a observaÃ§Ã£o final (W), Ã© possÃ­vel matematicamente dividir a observaÃ§Ã£o, para inferir a curva de plausibilidade anterior. EntÃ£o os dados poderiam ser apresentados ao seu modelo em qualquer ordem, ou todos de uma vez. Na maioria dos casos, vocÃª apresentarÃ¡ os dados todos de uma vez, por conveniÃªncia. Mas Ã© importante perceber que isso meramente representa a abreviaÃ§Ã£o de um processo iterativo de aprendizado.\n\n> **Repensando: Tamanho amostral e inferÃªncia confiÃ¡vel.** Ã‰ comum ouvir que hÃ¡ um nÃºmero mÃ­nimo de observaÃ§Ãµes para uma estimativa estatÃ­stica Ãºtil. Por exemplo, hÃ¡ uma superstiÃ§Ã£o difundida de que 30 observaÃ§Ãµes sÃ£o necessÃ¡rias antes de se poder usar uma distribuiÃ§Ã£o gaussiana. Por quÃª? Na inferÃªncia estatÃ­stica nÃ£o bayesiana, os procedimentos sÃ£o frequentemente justificados pelo comportamento do mÃ©todo com tamanhos amostrais muito grandes, o chamado comportamento assintÃ³tico. Como resultado, o desempenho com tamanhos amostrais pequenos Ã© questionÃ¡vel.\n>\n> Em contraste, estimativas bayesianas sÃ£o vÃ¡lidas para qualquer tamanho amostral. Isso nÃ£o significa que mais dados nÃ£o ajudem â€” certamente ajudam. Em vez disso, as estimativas tÃªm uma interpretaÃ§Ã£o clara e vÃ¡lida, independentemente do tamanho amostral. Mas o preÃ§o desse poder Ã© a dependÃªncia das plausibilidades iniciais, a distribuiÃ§Ã£o a priori. Se a distribuiÃ§Ã£o a priori for ruim, a inferÃªncia resultante serÃ¡ enganosa. NÃ£o hÃ¡ almoÃ§o grÃ¡tis quando se trata de aprender sobre o mundo. Um golem bayesiano deve escolher uma plausibilidade inicial, e um golem nÃ£o bayesiano deve escolher um estimador. Ambos os golems pagam pelo almoÃ§o com suas suposiÃ§Ãµes.\n\n### AvaliaÃ§Ã£o {-}\n\nO modelo bayesiano aprende de uma maneira que Ã© comprovadamente Ã³tima, desde que o mundo real, o mundo grande, seja descrito com precisÃ£o pelo modelo. Ou seja, sua mÃ¡quina bayesiana garante inferÃªncia perfeita, dentro do mundo pequeno. Nenhuma outra maneira de usar a informaÃ§Ã£o disponÃ­vel, e comeÃ§ando com o mesmo estado de informaÃ§Ã£o, poderia fazer melhor.\n\nNÃ£o fique muito empolgado com essa virtude lÃ³gica, contudo. Os cÃ¡lculos podem falhar, entÃ£o os resultados sempre precisam ser verificados. E se houver diferenÃ§as importantes entre o modelo e a realidade, entÃ£o nÃ£o hÃ¡ garantia lÃ³gica de desempenho no mundo grande. E mesmo que os dois mundos coincidissem, qualquer amostra particular de dados poderia ainda ser enganosa. EntÃ£o vale a pena manter em mente pelo menos dois princÃ­pios cautelosos.\n\nPrimeiro, a certeza do modelo nÃ£o Ã© garantia de que o modelo Ã© bom. Conforme a quantidade de dados aumenta, o modelo de lanÃ§amento do globo ficarÃ¡ cada vez mais seguro da proporÃ§Ã£o de Ã¡gua. Isso significa que as curvas na Figura 2.5 se tornarÃ£o cada vez mais estreitas e altas, restringindo valores plausÃ­veis dentro de uma faixa muito estreita. Mas modelos de todos os tipos â€” bayesianos ou nÃ£o â€” podem ser muito confiantes sobre uma inferÃªncia, mesmo quando o modelo Ã© seriamente enganoso. Isso ocorre porque as inferÃªncias sÃ£o condicionais ao modelo.\n\nSegundo, Ã© importante supervisionar e criticar o trabalho do seu modelo. Considere novamente o fato de que a atualizaÃ§Ã£o na seÃ§Ã£o anterior funciona em qualquer ordem de chegada dos dados. PoderÃ­amos embaralhar a ordem das observaÃ§Ãµes, contanto que seis W's e trÃªs L's permaneÃ§am, e ainda terminar com a mesma curva de plausibilidade final. Isso sÃ³ Ã© verdade, contudo, porque o modelo assume que a ordem Ã© irrelevante para a inferÃªncia. Quando algo Ã© irrelevante para a mÃ¡quina, nÃ£o afetarÃ¡ a inferÃªncia diretamente. Mas pode afetÃ¡-la indiretamente, porque os dados dependerÃ£o da ordem. EntÃ£o Ã© importante verificar as inferÃªncias do modelo Ã  luz de aspectos dos dados que ele nÃ£o conhece. Tais verificaÃ§Ãµes sÃ£o um empreendimento inerentemente criativo, deixado para o analista e a comunidade cientÃ­fica. Golems sÃ£o muito ruins nisso.\n\nO objetivo nÃ£o Ã© testar o valor de verdade das suposiÃ§Ãµes do modelo. Sabemos que as suposiÃ§Ãµes do modelo nunca sÃ£o exatamente corretas, no sentido de corresponder ao verdadeiro processo gerador de dados. Portanto, nÃ£o hÃ¡ motivo para verificar se o modelo Ã© verdadeiro. A falha em concluir que um modelo Ã© falso deve ser uma falha de nossa imaginaÃ§Ã£o, nÃ£o um sucesso do modelo. AlÃ©m disso, modelos nÃ£o precisam ser exatamente verdadeiros para produzir inferÃªncias altamente precisas e Ãºteis. Em vez disso, o objetivo Ã© verificar a adequaÃ§Ã£o do modelo para algum propÃ³sito.\n\n> **Repensando: EstatÃ­stica deflacionÃ¡ria.** Pode ser que a inferÃªncia bayesiana seja o melhor mÃ©todo de inferÃªncia de propÃ³sito geral conhecido. Contudo, a inferÃªncia bayesiana Ã© muito menos poderosa do que gostarÃ­amos que fosse. NÃ£o hÃ¡ abordagem Ã  inferÃªncia que forneÃ§a garantias universais. Nenhum ramo da matemÃ¡tica aplicada tem acesso irrestrito Ã  realidade, porque a matemÃ¡tica nÃ£o Ã© descoberta, como o prÃ³ton. Em vez disso, ela Ã© inventada, como a pÃ¡.\n\n## Componentes do modelo\n\nAgora que vocÃª viu como o modelo bayesiano se comporta, Ã© hora de abrir a mÃ¡quina e aprender como ela funciona. Considere trÃªs tipos diferentes de coisas que contamos nas seÃ§Ãµes anteriores.\n\n- (1) O nÃºmero de maneiras que cada conjectura poderia produzir uma observaÃ§Ã£o\n- (2) O nÃºmero acumulado de maneiras que cada conjectura poderia produzir os dados inteiros\n- (3) A plausibilidade inicial de cada causa conjecturada dos dados\n\nCada uma dessas coisas tem um anÃ¡logo direto na teoria da probabilidade convencional. E assim, a maneira usual de construir um modelo estatÃ­stico envolve escolher distribuiÃ§Ãµes e dispositivos para cada uma que representem os nÃºmeros relativos de maneiras que as coisas podem acontecer.\n\n### VariÃ¡veis {-}\n\nVariÃ¡veis sÃ£o simplesmente sÃ­mbolos que podem assumir diferentes valores. Em um contexto cientÃ­fico, variÃ¡veis incluem coisas que desejamos inferir, como proporÃ§Ãµes e taxas, bem como coisas que podemos observar, os dados. No modelo de lanÃ§amento do globo, hÃ¡ trÃªs variÃ¡veis.\n\nA primeira variÃ¡vel Ã© nosso alvo de inferÃªncia, p, a proporÃ§Ã£o de Ã¡gua no globo. Essa variÃ¡vel nÃ£o pode ser observada. VariÃ¡veis nÃ£o observadas sÃ£o geralmente chamadas de **parÃ¢metros**. Mas, embora p em si nÃ£o seja observado, podemos inferi-lo a partir das outras variÃ¡veis.\n\nAs outras variÃ¡veis sÃ£o as variÃ¡veis observadas, as contagens de Ã¡gua e terra. Chame a contagem de Ã¡gua de W e a contagem de terra de L. A soma dessas duas variÃ¡veis Ã© o nÃºmero de lanÃ§amentos do globo: N = W + L.\n\n### DefiniÃ§Ãµes {-}\n\nUma vez que temos as variÃ¡veis listadas, precisamos definir cada uma delas. Ao definir cada uma, construÃ­mos um modelo que relaciona as variÃ¡veis umas Ã s outras. Lembre-se, o objetivo Ã© contar todas as maneiras que os dados poderiam surgir, dadas as suposiÃ§Ãµes.\n\n#### VariÃ¡veis observadas {-}\n\nPara a contagem de Ã¡gua W e terra L, definimos quÃ£o plausÃ­vel qualquer combinaÃ§Ã£o de W e L seria, para um valor especÃ­fico de p. Cada valor especÃ­fico de p corresponde a uma plausibilidade especÃ­fica dos dados, como na Figura 2.5.\n\nPara que nÃ£o tenhamos que literalmente contar, podemos usar uma funÃ§Ã£o matemÃ¡tica que nos diz a plausibilidade correta. Na estatÃ­stica convencional, uma funÃ§Ã£o de distribuiÃ§Ã£o atribuÃ­da a uma variÃ¡vel observada Ã© geralmente chamada de **verossimilhanÃ§a**.\n\nNo caso do modelo de lanÃ§amento do globo, a funÃ§Ã£o que precisamos pode ser derivada diretamente da histÃ³ria dos dados. Uma vez que adicionamos nossas suposiÃ§Ãµes de que (1) cada lanÃ§amento Ã© independente dos outros e (2) a probabilidade de W Ã© a mesma em cada lanÃ§amento, a teoria da probabilidade fornece uma resposta Ãºnica, conhecida como distribuiÃ§Ã£o binomial. E assim a probabilidade de observar W Ã¡guas e L terras, com probabilidade p de Ã¡gua em cada lanÃ§amento, Ã©:\n\n$$\\Pr(W, L|p) = \\frac{(W+L)!}{W!L!} p^{W} (1-p)^{L}$$\n\nLeia o acima como:\n\n> *As contagens de \"Ã¡gua\" W e \"terra\" L sÃ£o distribuÃ­das binomialmente, com probabilidade p de \"Ã¡gua\" em cada lanÃ§amento.*\n\nE a fÃ³rmula da distribuiÃ§Ã£o binomial estÃ¡ embutida no R, entÃ£o vocÃª pode facilmente calcular a verossimilhanÃ§a dos dados â€” seis W's em nove lanÃ§amentos â€” sob qualquer valor de p com:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom( 6 , size=9 , prob=0.5 )\n```\n:::\n\n\n\n\n```\n[1] 0.1640625\n```\n\nEsse nÃºmero Ã© o nÃºmero relativo de maneiras de obter seis Ã¡guas, mantendo p em 0,5 e $N = W + L$ em nove. EntÃ£o ele faz o trabalho de contar o nÃºmero relativo de caminhos pelo jardim. Mude o 0,5 para qualquer outro valor, para ver como o valor muda.\n\n> **Pensando Mais um Pouco: Nomes e distribuiÃ§Ãµes de probabilidade.** O \"d\" em `dbinom` significa *densidade*. FunÃ§Ãµes nomeadas assim quase sempre tÃªm parceiras correspondentes que comeÃ§am com \"r\" para amostras aleatÃ³rias e que comeÃ§am com \"p\" para probabilidades acumuladas. Veja, por exemplo, a ajuda `?dbinom`.\n\n#### VariÃ¡veis nÃ£o observadas {-}\n\nAs distribuiÃ§Ãµes que atribuÃ­mos Ã s variÃ¡veis observadas tipicamente tÃªm suas prÃ³prias variÃ¡veis. Na binomial acima, hÃ¡ p, a probabilidade de amostrar Ã¡gua. Como p nÃ£o Ã© observado, geralmente o chamamos de **PARÃ‚METRO**. Embora nÃ£o possamos observar p, ainda precisamos defini-lo.\n\nNa modelagem estatÃ­stica, muitas das perguntas mais comuns que fazemos sobre dados sÃ£o respondidas diretamente por parÃ¢metros:\n\n- Qual Ã© a diferenÃ§a mÃ©dia entre grupos de tratamento?\n- QuÃ£o forte Ã© a associaÃ§Ã£o entre um tratamento e um resultado?\n- O efeito do tratamento depende de uma covariÃ¡vel?\n- Quanta variaÃ§Ã£o hÃ¡ entre grupos?\n\nPara cada parÃ¢metro que vocÃª pretende que sua mÃ¡quina bayesiana considere, vocÃª deve fornecer uma distribuiÃ§Ã£o de plausibilidade a priori, sua **DISTRIBUIÃ‡ÃƒO A PRIORI**. Uma mÃ¡quina bayesiana deve ter uma atribuiÃ§Ã£o inicial de plausibilidade para cada valor possÃ­vel do parÃ¢metro, e essas atribuiÃ§Ãµes iniciais fazem trabalho Ãºtil.\n\nEntÃ£o, de onde vÃªm as distribuiÃ§Ãµes a priori? Elas sÃ£o tanto suposiÃ§Ãµes de engenharia, escolhidas para ajudar a mÃ¡quina a aprender, quanto suposiÃ§Ãµes cientÃ­ficas, escolhidas para refletir o que sabemos sobre um fenÃ´meno. A distribuiÃ§Ã£o a priori plana na Figura 2.5 Ã© muito comum, mas raramente Ã© a melhor distribuiÃ§Ã£o a priori.\n\n> **Pensando Mais um Pouco: A distribuiÃ§Ã£o a priori como distribuiÃ§Ã£o de probabilidade.** VocÃª poderia escrever a distribuiÃ§Ã£o a priori no exemplo aqui como:\n>\n>$$\\Pr(p) = \\frac{1}{1-0} = 1.$$\n>\n>A distribuiÃ§Ã£o a priori Ã© uma distribuiÃ§Ã£o de probabilidade para o parÃ¢metro. Em geral, para uma distribuiÃ§Ã£o a priori uniforme de a atÃ© b, a probabilidade de qualquer ponto no intervalo Ã© 1/(b-a). Se vocÃª estÃ¡ incomodado pelo fato de que a probabilidade de cada valor de p Ã© 1, lembre-se de que toda distribuiÃ§Ã£o de probabilidade deve somar (integrar) para 1. A expressÃ£o 1/(b-a) garante que a Ã¡rea sob a linha plana de a atÃ© b Ã© igual a 1.\n\n> **Repensando: Dado ou parÃ¢metro?** Ã‰ tÃ­pico conceber dados e parÃ¢metros como tipos de entidades completamente diferentes. Dados sÃ£o mensurados e conhecidos; parÃ¢metros sÃ£o desconhecidos e devem ser estimados a partir dos dados. Utilmente, no framework bayesiano, a distinÃ§Ã£o entre um dado e um parÃ¢metro nÃ£o Ã© tÃ£o fundamental. Ã€s vezes observamos uma variÃ¡vel, mas Ã s vezes nÃ£o. Nesse caso, a mesma funÃ§Ã£o de distribuiÃ§Ã£o se aplica, mesmo que nÃ£o tenhamos observado a variÃ¡vel. Como resultado, a mesma suposiÃ§Ã£o pode parecer uma \"verossimilhanÃ§a\" ou uma \"distribuiÃ§Ã£o a priori\", dependendo do contexto, sem qualquer mudanÃ§a no modelo.\n\n### Um modelo nasce {-}\n\nCom todo o trabalho acima, podemos agora resumir nosso modelo. As variÃ¡veis observadas W e L recebem contagens relativas atravÃ©s da distribuiÃ§Ã£o binomial. EntÃ£o podemos escrever, como atalho:\n\n$$W \\sim \\text{Binomial}(N, p)$$\n\nonde N = W + L. O acima Ã© apenas uma convenÃ§Ã£o para comunicar a suposiÃ§Ã£o de que as contagens relativas de maneiras de realizar W em N tentativas com probabilidade p em cada tentativa vÃªm da distribuiÃ§Ã£o binomial. E o parÃ¢metro nÃ£o observado p similarmente recebe:\n\n$$p \\sim \\text{Uniform}(0,1)$$\n\nIsso significa que p tem uma distribuiÃ§Ã£o a priori uniforme â€” plana â€” sobre toda a sua faixa possÃ­vel, de zero a um. Como mencionei anteriormente, isso obviamente nÃ£o Ã© o melhor que poderÃ­amos fazer, pois sabemos que a Terra tem mais Ã¡gua que terra, mesmo que ainda nÃ£o saibamos a proporÃ§Ã£o exata.\n\n## Fazendo o modelo funcionar\n\nUma vez que vocÃª nomeou todas as variÃ¡veis e escolheu definiÃ§Ãµes para cada uma, um modelo bayesiano pode atualizar todas as distribuiÃ§Ãµes a priori para suas consequÃªncias puramente lÃ³gicas: a **distribuiÃ§Ã£o a posteriori**. Para cada combinaÃ§Ã£o Ãºnica de dados, verossimilhanÃ§a, parÃ¢metros e distribuiÃ§Ã£o a priori, hÃ¡ uma distribuiÃ§Ã£o a posteriori Ãºnica. Essa distribuiÃ§Ã£o contÃ©m a plausibilidade relativa de diferentes valores de parÃ¢metros, condicional nos dados e no modelo. A distribuiÃ§Ã£o a posteriori assume a forma da probabilidade dos parÃ¢metros, condicional nos dados. Neste caso, seria Pr(p|W, L), a probabilidade de cada valor possÃ­vel de p, condicional nos W e L especÃ­ficos que observamos.\n\n### O teorema de Bayes {-}\n\nA definiÃ§Ã£o matemÃ¡tica da distribuiÃ§Ã£o a posteriori surge do **teorema de Bayes**. Este Ã© o teorema que dÃ¡ Ã  anÃ¡lise bayesiana de dados seu nome. Mas o teorema em si Ã© uma implicaÃ§Ã£o trivial da teoria da probabilidade.\n\nA probabilidade conjunta dos dados W e L e qualquer valor particular de p Ã©:\n\n$$\\Pr(W, L, p) = \\Pr(W, L|p) \\Pr(p)$$\n\nIsso apenas diz que a probabilidade de W, L e p Ã© o produto de Pr(W, L|p) e a probabilidade a priori Pr(p). Ã‰ como dizer que a probabilidade de chuva e frio no mesmo dia Ã© igual Ã  probabilidade de chuva, quando estÃ¡ frio, vezes a probabilidade de que esteja frio. AtÃ© aqui Ã© apenas definiÃ§Ã£o. Mas Ã© igualmente verdade que:\n\n$$\\Pr(W, L, p) = \\Pr(p|W, L) \\Pr(W, L)$$\n\nTudo o que fiz foi inverter qual probabilidade Ã© condicional, no lado direito. Agora, como ambos os lados direitos acima sÃ£o iguais Ã  mesma coisa, Pr(W, L, p), eles tambÃ©m sÃ£o iguais entre si:\n\n$$\\Pr(W, L|p) \\Pr(p) = \\Pr(p|W, L) \\Pr(W, L)$$\n\nEntÃ£o podemos agora resolver para o que queremos, Pr(p|W, L):\n\n$$\\Pr(p|W,L) = \\frac{\\Pr(W,L|p)\\Pr(p)}{\\Pr(W,L)}$$\n\nE este Ã© o teorema de Bayes. Ele diz que a probabilidade de qualquer valor particular de p, considerando os dados, Ã© igual ao produto da plausibilidade relativa dos dados, condicional em p, e da plausibilidade a priori de p, dividido pela probabilidade mÃ©dia dos dados. Em forma de palavras:\n\n$$Posterior = \\frac{\\text{Probabilidade dos dados} \\times \\text{A priori}}{\\text{Probabilidade mÃ©dia dos dados}}$$\n\nA probabilidade mÃ©dia dos dados, Pr(W, L), Ã© literalmente a probabilidade mÃ©dia dos dados. MÃ©dia sobre o quÃª? Sobre a distribuiÃ§Ã£o a priori. Seu trabalho Ã© apenas padronizar a distribuiÃ§Ã£o a posteriori, para garantir que ela some (integre) para um. Em forma matemÃ¡tica:\n\n$$\\Pr(W, L) = \\mathbb{E}(\\Pr(W, L|p)) = \\int \\Pr(W, L|p) \\Pr(p) dp$$\n\nA liÃ§Ã£o principal Ã© que a distribuiÃ§Ã£o a posteriori Ã© proporcional ao produto da distribuiÃ§Ã£o a priori e da probabilidade dos dados.\n\n![](cap-02-small-worlds-large-worlds-pt/_page_19_Figure_2.jpeg)\n\nFigura 2.6. A distribuiÃ§Ã£o a posteriori, como produto da distribuiÃ§Ã£o a priori e da verossimilhanÃ§a. Linha superior: uma distribuiÃ§Ã£o a priori plana constrÃ³i uma distribuiÃ§Ã£o a posteriori que Ã© simplesmente proporcional Ã  verossimilhanÃ§a. Linha do meio: uma distribuiÃ§Ã£o a priori em degrau, atribuindo probabilidade zero a todos os valores menores que 0,5, resultando em uma distribuiÃ§Ã£o a posteriori truncada. Linha inferior: uma distribuiÃ§Ã£o a priori com pico que desloca e distorce a distribuiÃ§Ã£o a posteriori, relativamente Ã  verossimilhanÃ§a.\n\nA Figura 2.6 ilustra a interaÃ§Ã£o multiplicativa de uma distribuiÃ§Ã£o a priori e uma probabilidade dos dados. Em cada linha, uma distribuiÃ§Ã£o a priori Ã  esquerda Ã© multiplicada pela probabilidade dos dados no meio para produzir uma distribuiÃ§Ã£o a posteriori Ã  direita. A probabilidade dos dados em cada caso Ã© a mesma. As distribuiÃ§Ãµes a priori, contudo, variam. Como resultado, as distribuiÃ§Ãµes a posteriori variam.\n\n### Motores de estimaÃ§Ã£o {-}\n\nLembre-se de que seu modelo bayesiano Ã© uma mÃ¡quina, um golem figurativo. Ele tem definiÃ§Ãµes embutidas para a verossimilhanÃ§a, os parÃ¢metros e a distribuiÃ§Ã£o a priori. E entÃ£o, em seu coraÃ§Ã£o, reside um motor que processa dados, produzindo uma distribuiÃ§Ã£o a posteriori.\n\nVÃ¡rias tÃ©cnicas numÃ©ricas sÃ£o necessÃ¡rias para aproximar a matemÃ¡tica que segue da definiÃ§Ã£o do teorema de Bayes. HÃ¡ trÃªs motores de condicionamento diferentes, tÃ©cnicas numÃ©ricas para calcular distribuiÃ§Ãµes a posteriori:\n\n- (1) AproximaÃ§Ã£o por grade\n- (2) AproximaÃ§Ã£o quadrÃ¡tica\n- (3) Markov chain Monte Carlo (MCMC)\n\nHÃ¡ muitos outros motores, e novos estÃ£o sendo inventados o tempo todo. Mas os trÃªs acima sÃ£o comuns e amplamente Ãºteis.\n\n### AproximaÃ§Ã£o por grade {-}\n\nUma das tÃ©cnicas de condicionamento mais simples Ã© a aproximaÃ§Ã£o por grade. Embora a maioria dos parÃ¢metros seja *contÃ­nua*, capaz de assumir um nÃºmero infinito de valores, acontece que podemos alcanÃ§ar uma excelente aproximaÃ§Ã£o da distribuiÃ§Ã£o a posteriori contÃ­nua considerando apenas uma grade finita de valores de parÃ¢metros. Em qualquer valor particular de um parÃ¢metro, p', Ã© simples calcular a probabilidade a posteriori: basta multiplicar a probabilidade a priori de p' pela verossimilhanÃ§a em p'. Repetir esse procedimento para cada valor na grade gera uma imagem aproximada da distribuiÃ§Ã£o a posteriori exata. Esse procedimento Ã© chamado de **APROXIMAÃ‡ÃƒO POR GRADE**.\n\nA aproximaÃ§Ã£o por grade serÃ¡ principalmente Ãºtil como ferramenta pedagÃ³gica, pois aprendÃª-la forÃ§a o usuÃ¡rio a realmente entender a natureza da atualizaÃ§Ã£o bayesiana. Mas na maioria da sua modelagem real, a aproximaÃ§Ã£o por grade nÃ£o Ã© prÃ¡tica, porque ela escala muito mal conforme o nÃºmero de parÃ¢metros aumenta.\n\nNo contexto do problema de lanÃ§amento do globo, a aproximaÃ§Ã£o por grade funciona extremamente bem. Aqui estÃ¡ a receita:\n\n- (1) Defina a grade. Isso significa que vocÃª decide quantos pontos usar na estimaÃ§Ã£o da distribuiÃ§Ã£o a posteriori e entÃ£o faz uma lista dos valores de parÃ¢metros na grade.\n- (2) Calcule o valor da distribuiÃ§Ã£o a priori em cada valor de parÃ¢metro na grade.\n- (3) Calcule a verossimilhanÃ§a em cada valor de parÃ¢metro.\n- (4) Calcule a distribuiÃ§Ã£o a posteriori nÃ£o padronizada em cada valor de parÃ¢metro, multiplicando a distribuiÃ§Ã£o a priori pela verossimilhanÃ§a.\n- (5) Finalmente, padronize a distribuiÃ§Ã£o a posteriori, dividindo cada valor pela soma de todos os valores.\n\nNo contexto do lanÃ§amento do globo, aqui estÃ¡ o cÃ³digo para completar todas as cinco etapas:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# define grid\np_grid <- seq( from=0 , to=1 , length.out=20 )\n\n# define prior\nprior <- rep( 1 , 20 )\n\n# compute likelihood at each value in grid\nlikelihood <- dbinom( 6 , size=9 , prob=p_grid )\n\n# compute product of likelihood and prior\nunstd.posterior <- likelihood * prior\n\n# standardize the posterior, so it sums to 1\nposterior <- unstd.posterior / sum(unstd.posterior)\n```\n:::\n\n\n\n\nO cÃ³digo acima faz uma grade de apenas 20 pontos. Para exibir a distribuiÃ§Ã£o a posteriori agora:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot( p_grid , posterior , type=\"b\" ,\n      xlab=\"probability of water\" , ylab=\"posterior probability\" )\nmtext( \"20 points\" )\n```\n:::\n\n\n\n\n|  |  |\n|:--------:|:--------:|\n| ![](cap-02-small-worlds-large-worlds-pt/_page_22_Figure_2.jpeg) | ![](cap-02-small-worlds-large-worlds-pt/_page_22_Figure_3.jpeg) |\n\nFigura 2.7. Calculando a distribuiÃ§Ã£o a posteriori por aproximaÃ§Ã£o por grade. Em cada grÃ¡fico, a distribuiÃ§Ã£o a posteriori para os dados e modelo de lanÃ§amento do globo Ã© aproximada com um nÃºmero finito de pontos igualmente espaÃ§ados. Com apenas 5 pontos (esquerda), a aproximaÃ§Ã£o Ã© terrÃ­vel. Mas com 20 pontos (direita), a aproximaÃ§Ã£o jÃ¡ Ã© bastante boa.\n\nVocÃª obterÃ¡ o grÃ¡fico da direita na Figura 2.7. Tente grades mais esparsas (5 pontos) e mais densas (100 ou 1000 pontos). A densidade correta para sua grade Ã© determinada por quÃ£o precisa vocÃª quer que sua aproximaÃ§Ã£o seja. Mais pontos significa mais precisÃ£o. Neste exemplo simples, vocÃª pode exagerar e usar 100.000 pontos, mas nÃ£o haverÃ¡ muita mudanÃ§a na inferÃªncia apÃ³s os primeiros 100.\n\nAgora, para replicar as diferentes distribuiÃ§Ãµes a priori na Figura 2.5, tente estas linhas de cÃ³digo â€” uma de cada vez â€” para a grade da distribuiÃ§Ã£o a priori:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior <- ifelse( p_grid < 0.5 , 0 , 1 )\nprior <- exp( -5*abs( p_grid - 0.5 ) )\n```\n:::\n\n\n\n\nO restante do cÃ³digo permanece o mesmo.\n\n> **Pensando Mais um Pouco: VetorizaÃ§Ã£o.** Uma das caracterÃ­sticas Ãºteis do R Ã© que ele torna trabalhar com listas de nÃºmeros quase tÃ£o fÃ¡cil quanto trabalhar com valores Ãºnicos. EntÃ£o, embora ambas as linhas de cÃ³digo acima nÃ£o digam nada sobre quÃ£o densa Ã© sua grade, qualquer comprimento que vocÃª tenha escolhido para o vetor p_grid determinarÃ¡ o comprimento do vetor prior. No jargÃ£o do R, os cÃ¡lculos acima sÃ£o *vetorizados*, porque trabalham com listas de valores, *vetores*. Em um cÃ¡lculo vetorizado, o cÃ¡lculo Ã© realizado em cada elemento do vetor de entrada â€” p_grid neste caso â€” e a saÃ­da resultante, portanto, tem o mesmo comprimento. Em outros ambientes computacionais, o mesmo cÃ¡lculo exigiria um *loop*. R tambÃ©m pode usar loops, mas cÃ¡lculos vetorizados sÃ£o tipicamente mais rÃ¡pidos.\n\n### AproximaÃ§Ã£o quadrÃ¡tica {-}\n\nContinuaremos com a aproximaÃ§Ã£o por grade da distribuiÃ§Ã£o a posteriori do lanÃ§amento do globo pelo restante deste capÃ­tulo. Mas em breve vocÃª terÃ¡ que recorrer a outra aproximaÃ§Ã£o, uma que faz suposiÃ§Ãµes mais fortes. A razÃ£o Ã© que o nÃºmero de valores Ãºnicos a considerar na grade cresce rapidamente conforme o nÃºmero de parÃ¢metros em seu modelo aumenta.\n\nUma abordagem Ãºtil Ã© a **APROXIMAÃ‡ÃƒO QUADRÃTICA**. Sob condiÃ§Ãµes bem gerais, a regiÃ£o perto do pico da distribuiÃ§Ã£o a posteriori serÃ¡ quase gaussiana â€” ou \"normal\" â€” em forma. Isso significa que a distribuiÃ§Ã£o a posteriori pode ser utilmente aproximada por uma distribuiÃ§Ã£o gaussiana. Uma distribuiÃ§Ã£o gaussiana Ã© conveniente, porque pode ser completamente descrita por apenas dois nÃºmeros: a localizaÃ§Ã£o de seu centro (mÃ©dia) e sua dispersÃ£o (variÃ¢ncia).\n\nUma aproximaÃ§Ã£o gaussiana Ã© chamada de \"aproximaÃ§Ã£o quadrÃ¡tica\" porque o logaritmo de uma distribuiÃ§Ã£o gaussiana forma uma parÃ¡bola.\n\nO procedimento contÃ©m dois passos:\n\n- (1) Encontre a moda a posteriori. Isso Ã© geralmente alcanÃ§ado por algum algoritmo de otimizaÃ§Ã£o.\n- (2) Uma vez que vocÃª encontra o pico da distribuiÃ§Ã£o a posteriori, deve estimar a curvatura perto do pico. Essa curvatura Ã© suficiente para calcular uma aproximaÃ§Ã£o quadrÃ¡tica de toda a distribuiÃ§Ã£o a posteriori.\n\nPara calcular a aproximaÃ§Ã£o quadrÃ¡tica dos dados de lanÃ§amento do globo usando base R:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Encontrar o MAP (pico da posterior) via otimizaÃ§Ã£o\nW <- 6\nL <- 3\n\n# FunÃ§Ã£o log-posterior (prior uniforme + binomial)\nlog_post <- function(p) {\n  dbinom(W, W + L, p, log = TRUE) + dunif(p, 0, 1, log = TRUE)\n}\n\n# Otimizar para encontrar o MAP\nresultado <- optimize(log_post, interval = c(0, 1), maximum = TRUE)\np_map <- resultado$maximum\n\n# Curvatura (desvio padrÃ£o da aproximaÃ§Ã£o quadrÃ¡tica)\ndelta <- 1e-4\nd2 <- (log_post(p_map + delta) - 2 * log_post(p_map) + log_post(p_map - delta)) / delta^2\np_sd <- sqrt(-1 / d2)\n\ncat(sprintf(\"MAP (mÃ©dia a posteriori): %.2f\\n\", p_map))\ncat(sprintf(\"Desvio padrÃ£o (aprox. quadrÃ¡tica): %.2f\\n\", p_sd))\ncat(sprintf(\"Intervalo 89%%: [%.2f, %.2f]\\n\",\n    qnorm(0.055, p_map, p_sd),\n    qnorm(0.945, p_map, p_sd)))\n```\n:::\n\n\n\n\n```\nMAP (mÃ©dia a posteriori): 0.67\nDesvio padrÃ£o (aprox. quadrÃ¡tica): 0.16\nIntervalo 89%: [0.42, 0.92]\n```\n\nVocÃª pode ler essa aproximaÃ§Ã£o como: Supondo que a distribuiÃ§Ã£o a posteriori Ã© gaussiana, ela Ã© maximizada em 0,67 e seu desvio padrÃ£o Ã© 0,16.\n\nComo jÃ¡ conhecemos a distribuiÃ§Ã£o a posteriori, vamos comparar para ver quÃ£o boa Ã© a aproximaÃ§Ã£o. Usaremos a abordagem analÃ­tica, que usa `dbeta`, para obter exatamente a resposta certa, sem aproximaÃ§Ãµes:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# DistribuiÃ§Ã£o a posteriori analÃ­tica (exata)\nW <- 6\nL <- 3\ncurve( dbeta(x, W+1, L+1), from=0, to=1,\n       xlab=\"p\", ylab=\"densidade\", col=\"blue\", lwd=2)\n\n# AproximaÃ§Ã£o quadrÃ¡tica\ncurve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE, col=\"black\", lwd=2 )\nlegend(\"topleft\", legend=c(\"Posterior exata\", \"Aprox. quadrÃ¡tica\"),\n       col=c(\"blue\",\"black\"), lty=c(1,2), lwd=2)\n```\n:::\n\n\n\n\n![](cap-02-small-worlds-large-worlds-pt/_page_25_Figure_2.jpeg)\n\nFigura 2.8. PrecisÃ£o da aproximaÃ§Ã£o quadrÃ¡tica. Em cada grÃ¡fico, a distribuiÃ§Ã£o a posteriori exata Ã© plotada em azul, e a aproximaÃ§Ã£o quadrÃ¡tica Ã© plotada como a curva preta. Esquerda: Os dados de lanÃ§amento do globo com n = 9 lanÃ§amentos e w = 6 Ã¡guas. Meio: O dobro da quantidade de dados, com a mesma fraÃ§Ã£o de Ã¡gua, n = 18 e w = 12. Direita: Quatro vezes mais dados, n = 36 e w = 24.\n\nConforme a quantidade de dados aumenta, a aproximaÃ§Ã£o quadrÃ¡tica melhora. Esse fenÃ´meno, em que a aproximaÃ§Ã£o quadrÃ¡tica melhora com a quantidade de dados, Ã© muito comum.\n\n### Markov chain Monte Carlo {-}\n\nHÃ¡ muitos tipos importantes de modelos, como modelos multinÃ­vel (efeitos mistos), para os quais nem a aproximaÃ§Ã£o por grade nem a aproximaÃ§Ã£o quadrÃ¡tica Ã© sempre satisfatÃ³ria. Tais modelos podem ter centenas ou milhares ou dezenas de milhares de parÃ¢metros. A aproximaÃ§Ã£o por grade rotineiramente falha aqui, porque simplesmente demora demais.\n\nComo resultado, vÃ¡rias tÃ©cnicas contra-intuitivas de ajuste de modelos surgiram. A mais popular destas Ã© **Markov Chain Monte Carlo** (MCMC), que Ã© uma famÃ­lia de motores de condicionamento capazes de lidar com modelos altamente complexos.\n\nO desafio conceitual com MCMC reside em sua estratÃ©gia altamente nÃ£o Ã³bvia. Em vez de tentar calcular ou aproximar a distribuiÃ§Ã£o a posteriori diretamente, tÃ©cnicas MCMC meramente sorteiam amostras da distribuiÃ§Ã£o a posteriori. VocÃª termina com uma coleÃ§Ã£o de valores de parÃ¢metros, e as frequÃªncias desses valores correspondem Ã s plausibilidades a posteriori. VocÃª pode entÃ£o construir uma imagem da distribuiÃ§Ã£o a posteriori a partir do histograma dessas amostras.\n\n> **Pensando Mais um Pouco: Monte Carlo e o lanÃ§amento do globo.** Uma cadeia de Markov funcional para o modelo de lanÃ§amento do globo nÃ£o requer muito cÃ³digo. O seguinte cÃ³digo R serÃ¡ suficiente:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_samples <- 1000\np <- rep( NA , n_samples )\np[1] <- 0.5\nW <- 6\nL <- 3\nfor ( i in 2:n_samples ) {\n    p_new <- rnorm( 1 , p[i-1] , 0.1 )\n    if ( p_new < 0 ) p_new <- abs( p_new )\n    if ( p_new > 1 ) p_new <- 2 - p_new\n    q0 <- dbinom( W , W+L , p[i-1] )\n    q1 <- dbinom( W , W+L , p_new )\n    p[i] <- ifelse( runif(1) < q1/q0 , p_new , p[i-1] )\n}\n```\n:::\n\n\n\n\nOs valores em p sÃ£o amostras da distribuiÃ§Ã£o a posteriori. Para comparar com a distribuiÃ§Ã£o a posteriori analÃ­tica:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualizar a distribuiÃ§Ã£o das amostras MCMC\nplot(density(p), xlim=c(0,1),\n     main=\"MCMC vs. Posterior analÃ­tica\",\n     xlab=\"p\", ylab=\"densidade\")\n# Sobrepor a posterior exata\ncurve( dbeta( x , W+1 , L+1 ) , lty=2 , add=TRUE, col=\"blue\", lwd=2 )\nlegend(\"topleft\", legend=c(\"MCMC\", \"Exata\"),\n       col=c(\"black\",\"blue\"), lty=c(1,2))\n```\n:::\n\n\n\n\n## Resumo\n\nEste capÃ­tulo introduziu a mecÃ¢nica conceitual da anÃ¡lise bayesiana de dados. O alvo da inferÃªncia na inferÃªncia bayesiana Ã© uma distribuiÃ§Ã£o de probabilidade a posteriori. Probabilidades a posteriori declaram os nÃºmeros relativos de maneiras que cada causa conjecturada dos dados poderia ter produzido os dados. Esses nÃºmeros relativos indicam plausibilidades das diferentes conjecturas. Essas plausibilidades sÃ£o atualizadas Ã  luz das observaÃ§Ãµes, um processo conhecido como atualizaÃ§Ã£o bayesiana.\n\nMais mecanicamente, um modelo bayesiano Ã© um composto de variÃ¡veis e definiÃ§Ãµes distribucionais para essas variÃ¡veis. A probabilidade dos dados, frequentemente chamada de verossimilhanÃ§a, fornece a plausibilidade de uma observaÃ§Ã£o (dados), dado um valor fixo para os parÃ¢metros. A distribuiÃ§Ã£o a priori fornece a plausibilidade de cada valor possÃ­vel dos parÃ¢metros, antes de considerar os dados. As regras da probabilidade nos dizem que a maneira lÃ³gica de calcular as plausibilidades, apÃ³s considerar os dados, Ã© usar o teorema de Bayes. Isso resulta na distribuiÃ§Ã£o a posteriori.\n\nNa prÃ¡tica, modelos bayesianos sÃ£o ajustados aos dados usando tÃ©cnicas numÃ©ricas, como aproximaÃ§Ã£o por grade, aproximaÃ§Ã£o quadrÃ¡tica e Markov chain Monte Carlo. Cada mÃ©todo impÃµe diferentes compromissos.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}