{
  "hash": "c59d874b2b0a63ce89868b0adacabded",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Prática em R\"\nsubtitle: \"Quantificando a incerteza: do lançamento do globo à distribuição posterior\"\nauthor:\n  - \"Prof. Fabio Cop (*fcferreira@unifesp.br*)\"\n  - \"Instituto do Mar - Unifesp\"\ndate: today\nlang: pt-BR\nlanguage:\n  title-block-author-single: \"\"\n  title-block-author-plural: \"\"\nformat:\n  html:\n    toc: true\n    toc-title: \"Conteúdo\"\n    toc-depth: 2\n    number-sections: true\n    embed-resources: true\n    code-fold: false\n    code-tools: true\n  pdf:\n    documentclass: article\n    papersize: a4\n    geometry:\n      - margin=2.5cm\n    toc: true\n    toc-title: \"Conteúdo\"\n    toc-depth: 2\n    number-sections: true\n    colorlinks: true\n    include-in-header:\n      text: |\n        \\usepackage{authblk}\n---\n\n{{< pagebreak >}}\n\n\n\n\n\n\n\n\n\n\n::: {.callout-note appearance=\"minimal\"}\n**Curso:** Bacharelado Interdisciplinar em Ciências do Mar\n**Unidade Curricular (UC):** Probabilidade e Estatística\n**Atividade:** Prática no Laboratório de Informática\n**Duração:** 30 minutos\n:::\n\n::: {.callout-important appearance=\"minimal\" title=\"Instruções\"}\n\n1. **Copie e execute o código**\n2. **Observe** os resultados que aparecem\n3. **Responda** às perguntas no documento que você vai entregar\n4. **Entrega:** Acesse o Moodle e adicione suas respostas às perguntas abaixo\n5. **Prazo:** Final da aula de hoje\n:::\n\n# O Experimento do Globo\n\nImagine que jogamos um globo para o alto várias vezes e, cada vez que o pegamos, registramos se o dedo indicador tocou **água (A)** ou **terra (T)**. O objetivo é estimar a proporção de água na superfície da Terra a partir desses dados.\n\n### *Código* {-}\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Registrar os resultados de 9 lançamentos do globo\nresultados <- c(\"A\", \"T\", \"A\", \"A\", \"T\", \"A\", \"T\", \"A\", \"A\")\n\n# Contar o total, a quantidade de água e de terra\nn_total <- length(resultados)\nn_agua  <- sum(resultados == \"A\")\nn_terra <- sum(resultados == \"T\")\n\n# Exibir os resultados\ncat(\"Total de lançamentos:\", n_total, \"\\n\")\ncat(\"Número de A (água):  \", n_agua,  \"\\n\")\ncat(\"Número de T (terra): \", n_terra, \"\\n\")\ncat(\"Proporção observada de água:\", round(n_agua / n_total, 2), \"\\n\")\n```\n:::\n\n\n\n\n\n\n::: {.callout-tip appearance=\"minimal\" title=\"O que observar\"}\n\n- O vetor `resultados` resume os 9 lançamentos do globo.\n- A proporção observada de água é o número de A's dividido pelo total.\n- Esta proporção é nossa estimativa inicial — mas o quanto podemos confiar nela com apenas 9 lançamentos?\n\n:::\n\n::: {.callout-important appearance=\"default\" icon=\"false\"}\n\n### **PERGUNTA 1** {-}\n\na) Qual foi a proporção observada de água nos 9 lançamentos?\n\nb) Se repetíssemos o experimento com 9 novos lançamentos, você esperaria obter exatamente a mesma proporção? Por quê?\n\nc) O que aconteceria com a incerteza sobre a proporção real de água se realizássemos 90 ou 900 lançamentos?\n\n:::\n\n# Contagem de Caminhos — O Jardim de Probabilidades\n\nA probabilidade pode ser entendida como uma medida da plausibilidade relativa de cada valor possível de $p$ (proporção de água), dadas as observações. Vamos calcular a verossimilhança — o quão compatível cada candidato a $p$ é com os dados — usando a distribuição binomial.\n\n### *Código* {-}\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definir cinco candidatos para o valor de p\ncandidatos_p <- c(0, 0.25, 0.5, 0.75, 1.0)\n\n# Dados observados: 6 águas em 9 lançamentos\nn_agua_obs  <- 6\nn_lancamentos <- 9\n\n# Calcular a verossimilhança de cada candidato\n# dbinom: probabilidade binomial de obter n_agua_obs sucessos em n_lancamentos tentativas\nverossimilhanca <- dbinom(n_agua_obs, size = n_lancamentos, prob = candidatos_p)\n\n# Plausibilidade relativa (normalizada)\nplaus_relativa <- verossimilhanca / sum(verossimilhanca)\n\n# Organizar em tabela\nresultado <- data.frame(\n  p                  = candidatos_p,\n  verossimilhanca    = round(verossimilhanca, 4),\n  plaus_relativa     = round(plaus_relativa, 4)\n)\n\nprint(resultado)\n```\n:::\n\n\n\n\n\n\n::: {.callout-tip appearance=\"minimal\" title=\"O que observar\"}\n\n- A coluna `verossimilhanca` mostra o quão provável é observar 6 águas em 9 lançamentos, para cada valor de $p$.\n- A coluna `plaus_relativa` normaliza esses valores para somarem 1 — é a plausibilidade relativa.\n- Os candidatos $p = 0$ e $p = 1.0$ têm verossimilhança zero. Por quê?\n\n:::\n\n::: {.callout-important appearance=\"default\" icon=\"false\"}\n\n### **PERGUNTA 2** {-}\n\na) Qual dos cinco candidatos tem maior plausibilidade relativa? Esse resultado faz sentido intuitivamente?\n\nb) Por que $p = 0$ e $p = 1$ têm verossimilhança igual a zero com esses dados?\n\nc) Com apenas cinco candidatos, conseguimos representar toda a incerteza sobre $p$? O que seria necessário para uma representação mais completa?\n\n:::\n\n# Grid Approximation — Distribuição Posterior\n\nEm vez de considerar apenas cinco candidatos, podemos avaliar 100 valores igualmente espaçados entre 0 e 1. Esse método — a **grid approximation** — nos fornece uma aproximação da distribuição posterior completa de $p$.\n\n### *Código* {-}\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Definir o grid de valores possíveis para p (100 pontos entre 0 e 1)\np_grid <- seq(from = 0, to = 1, length.out = 100)\n\n# Prior uniforme: antes de ver os dados, todos os valores de p são igualmente plausíveis\nprior <- rep(1, 100)\n\n# Verossimilhança: P(6 águas em 9 lançamentos | p) para cada ponto do grid\nlikelihood <- dbinom(6, size = 9, prob = p_grid)\n\n# Posterior não normalizada: produto do prior pela verossimilhança\nposterior_nao_norm <- likelihood * prior\n\n# Normalizar para que a área total sob a curva seja 1\nposterior <- posterior_nao_norm / sum(posterior_nao_norm)\n\n# Valor de p com maior plausibilidade (MAP: Maximum A Posteriori)\np_map <- p_grid[which.max(posterior)]\n\n# Visualizar a distribuição posterior\nplot(p_grid, posterior,\n     type = \"l\", lwd = 2,\n     col  = \"#1a9988\",\n     xlab = \"Proporção de água (p)\",\n     ylab = \"Plausibilidade posterior\",\n     main = paste0(\"Distribuição Posterior\\n6 águas em 9 lançamentos\"))\n\n# Marcar o pico da distribuição (MAP)\nabline(v = p_map, lty = 2, col = \"orange\", lwd = 2)\ntext(p_map + 0.02, max(posterior) * 0.9,\n     paste0(\"MAP = \", round(p_map, 2)),\n     col = \"orange\", adj = 0)\n```\n:::\n\n\n\n\n\n\n::: {.callout-tip appearance=\"minimal\" title=\"O que observar\"}\n\n- A curva verde representa a **distribuição posterior**: a plausibilidade de cada valor de $p$ após considerar os dados.\n- A linha laranja tracejada marca o valor de $p$ com maior plausibilidade posterior (MAP).\n- A curva não é pontual — ela expressa a incerteza sobre o valor real de $p$.\n\n:::\n\n::: {.callout-important appearance=\"default\" icon=\"false\"}\n\n### **PERGUNTA 3** {-}\n\na) Qual é o valor aproximado do MAP (pico da distribuição posterior)?\n\nb) A distribuição posterior está concentrada num único valor de $p$, ou há uma faixa de valores plausíveis? O que isso indica sobre nossa incerteza?\n\nc) Com base na curva, quais valores de $p$ têm muito baixa plausibilidade? Isso faz sentido dado o que observamos?\n\n:::\n\n# Atualização Bayesiana — Efeito de Mais Dados\n\nUma das propriedades fundamentais da inferência bayesiana é que a distribuição posterior se torna mais estreita (mais concentrada) à medida que coletamos mais dados. Vamos visualizar esse processo.\n\n### *Código* {-}\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Grid de p (mesmo para todos os painéis)\np_grid <- seq(from = 0, to = 1, length.out = 100)\nprior  <- rep(1, 100)\n\n# Comparar a posterior com diferentes tamanhos de amostra\n# Mantemos a mesma proporção observada de água: 2/3\ntamanhos <- c(3, 9, 27)\n\npar(mfrow = c(1, 3))  # três painéis lado a lado\n\nfor (n in tamanhos) {\n  w        <- round(n * 2 / 3)  # número de águas (2/3 de n)\n  lik      <- dbinom(w, size = n, prob = p_grid)\n  post     <- (lik * prior) / sum(lik * prior)\n  p_map_n  <- p_grid[which.max(post)]\n\n  plot(p_grid, post,\n       type = \"l\", lwd = 2, col = \"#1a9988\",\n       main = paste0(w, \" águas em \", n, \" lançamentos\"),\n       xlab = \"p\", ylab = \"Posterior\",\n       ylim = c(0, max(post) * 1.15))\n\n  abline(v = p_map_n, lty = 2, col = \"orange\", lwd = 2)\n}\n\npar(mfrow = c(1, 1))\n```\n:::\n\n\n\n\n\n\n::: {.callout-tip appearance=\"minimal\" title=\"O que observar\"}\n\n- Os três gráficos mostram a mesma proporção observada (2/3 de água), mas com tamanhos de amostra diferentes.\n- Observe como a curva vai ficando **mais estreita e mais alta** com mais dados.\n- A localização do pico (MAP) se mantém aproximadamente estável, mas a incerteza ao redor dele diminui.\n\n:::\n\n::: {.callout-important appearance=\"default\" icon=\"false\"}\n\n### **PERGUNTA 4** {-}\n\na) O valor do MAP (pico da distribuição) muda muito entre os três painéis?\n\nb) O que acontece com a **largura** da distribuição posterior conforme o tamanho da amostra aumenta? O que isso significa na prática?\n\nc) Com $n = 27$, você estaria mais confiante sobre o valor real de $p$ do que com $n = 3$? Por quê?\n\n:::\n\n# Efeito do Prior — O Papel do Conhecimento Prévio\n\nA distribuição posterior é o produto da verossimilhança pelo prior. Quando o prior é uniforme (todos os valores igualmente plausíveis), a posterior é determinada apenas pelos dados. Mas quando temos conhecimento prévio, o prior pode influenciar a inferência — especialmente com poucos dados.\n\n### *Código* {-}\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Dados: 6 águas em 9 lançamentos\np_grid <- seq(from = 0, to = 1, length.out = 100)\n\n# Prior 1: Uniforme — sem conhecimento prévio\nprior_uniforme <- rep(1, 100)\n\n# Prior 2: Escalonado — favorece levemente valores intermediários\nprior_moderado <- sqrt(p_grid * (1 - p_grid))\nprior_moderado <- prior_moderado / sum(prior_moderado)\n\n# Prior 3: Informativo — concentrado em torno de p = 0.7\nprior_informativo <- dnorm(p_grid, mean = 0.7, sd = 0.1)\nprior_informativo <- prior_informativo / sum(prior_informativo)\n\n# Verossimilhança (mesma para todos)\nlikelihood <- dbinom(6, size = 9, prob = p_grid)\n\n# Calcular as três posterioris\npost1 <- (likelihood * prior_uniforme)  / sum(likelihood * prior_uniforme)\npost2 <- (likelihood * prior_moderado)  / sum(likelihood * prior_moderado)\npost3 <- (likelihood * prior_informativo) / sum(likelihood * prior_informativo)\n\n# Visualizar\npar(mfrow = c(3, 1), mar = c(4, 4, 2, 1))\n\nplot(p_grid, post1, type = \"l\", lwd = 2, col = \"#1a9988\",\n     main = \"Prior Uniforme\", xlab = \"p\", ylab = \"Posterior\",\n     ylim = c(0, max(c(post1, post2, post3)) * 1.1))\nabline(v = p_grid[which.max(post1)], lty = 2, col = \"orange\")\n\nplot(p_grid, post2, type = \"l\", lwd = 2, col = \"#2c5f7c\",\n     main = \"Prior Moderado (favorece valores intermediários)\",\n     xlab = \"p\", ylab = \"Posterior\",\n     ylim = c(0, max(c(post1, post2, post3)) * 1.1))\nabline(v = p_grid[which.max(post2)], lty = 2, col = \"orange\")\n\nplot(p_grid, post3, type = \"l\", lwd = 2, col = \"#e6a073\",\n     main = \"Prior Informativo (concentrado em p = 0.7)\",\n     xlab = \"p\", ylab = \"Posterior\",\n     ylim = c(0, max(c(post1, post2, post3)) * 1.1))\nabline(v = p_grid[which.max(post3)], lty = 2, col = \"orange\")\n\npar(mfrow = c(1, 1))\n```\n:::\n\n\n\n\n\n\n::: {.callout-tip appearance=\"minimal\" title=\"O que observar\"}\n\n- Os três gráficos diferem apenas no prior — a verossimilhança (dados) é a mesma.\n- Com o prior uniforme, a posterior reflete apenas os dados.\n- Com o prior informativo, a posterior é \"puxada\" na direção do prior.\n- A influência do prior diminui conforme o tamanho da amostra aumenta.\n\n:::\n\n::: {.callout-important appearance=\"default\" icon=\"false\"}\n\n### **PERGUNTA 5** {-}\n\na) O MAP muda entre os três cenários? Em qual deles a diferença é mais perceptível?\n\nb) Quando faria sentido usar um prior informativo na prática? Dê um exemplo.\n\nc) O que aconteceria com as diferenças entre as três posterioris se tivéssemos 100 lançamentos em vez de 9?\n\n:::\n\n# Recapitulando as Etapas de Hoje\n\nConceitos fundamentais praticados neste laboratório:\n\n1. **Experimento binomial**: Modelar dados de presença/ausência como lançamentos independentes com probabilidade $p$.\n2. **Verossimilhança**: Medir a compatibilidade de um valor de $p$ com os dados usando a distribuição binomial (`dbinom()`).\n3. **Grid approximation**: Calcular a distribuição posterior para um conjunto denso de valores de $p$, multiplicando prior por verossimilhança e normalizando.\n4. **Atualização bayesiana**: Compreender como mais dados concentram a distribuição posterior ao redor do valor verdadeiro.\n5. **Prior**: Reconhecer o papel do conhecimento prévio na forma da distribuição posterior e como sua influência diminui com o aumento do tamanho amostral.\n",
    "supporting": [
      "lab-02-quantifying-uncertainty_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}