[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "5290 - PROBABILIDADE E ESTAT√çSTICA",
    "section": "",
    "text": "üìÑ Calend√°rio Acad√™mico 2026 Unifesp (PDF)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSEMANA\nDATA\nTEMA\nATIVIDADE\nLEITURAPR√âVIA\nSLIDES\nLAB.INFORM√ÅTICA\n\n\n\n\n1\n05/03\nIntrodu√ß√£o √† infer√™ncia bayesiana e ao conceito de modelo\nConstru√ß√£o de modelos mentais e atualiza√ß√£o de cren√ßas a partir de evid√™ncias\nüìñ\nüìΩÔ∏è\nüíª\n\n\n2\n12/03\nVari√°veis aleat√≥rias e distribui√ß√µes de probabilidade\nSimula√ß√£o computacional de processos aleat√≥rios e explora√ß√£o de distribui√ß√µes\nüìñ\nüìΩÔ∏è\nüíª\n\n\n3\n19/03\nModelos de probabilidade para dados discretos\nImplementa√ß√£o e an√°lise do modelo binomial por simula√ß√£o\nüìñ\nüìΩÔ∏è\nüíª\n\n\n4\n26/03\nModelos de probabilidade para dados cont√≠nuos e distribui√ß√µes a priori\nEspecifica√ß√£o e simula√ß√£o de modelos normais com diferentes prioris\nüìñ\nüìΩÔ∏è\nüíª\n\n\n5\n02/04\nProva 1\nProva m√∫ltipla escolha: avalia√ß√£o dos conceitos fundamentais de infer√™ncia bayesiana e modelos probabil√≠sticos\n\n\n\n\n\n6\n09/04\nEstrutura e interpreta√ß√£o do modelo linear bayesiano\nSimula√ß√£o de dados e an√°lise dos componentes determin√≠stico e estoc√°stico do modelo\nüìñ\nüìΩÔ∏è\nüíª\n\n\n7\n16/04\nExplora√ß√£o e visualiza√ß√£o de dados\nConstru√ß√£o de gr√°ficos e an√°lise explorat√≥ria para identificar padr√µes e rela√ß√µes\nüìñ\nüìΩÔ∏è\nüíª\n\n\n8\n23/04\nEstima√ß√£o de par√¢metros em modelos bayesianos\nAjuste do modelo de regress√£o linear e an√°lise da distribui√ß√£o posterior\nüìñ\nüìΩÔ∏è\nüíª\n\n\n9\n30/04\nInterpreta√ß√£o de coeficientes em regress√£o m√∫ltipla\nAjuste e compara√ß√£o de modelos com m√∫ltiplos preditores\nüìñ\nüìΩÔ∏è\nüíª\n\n\n10\n07/05\nMulticolinearidade e depend√™ncia entre preditores\nDiagn√≥stico e avalia√ß√£o dos efeitos da colinearidade nos par√¢metros estimados\nüìñ\nüìΩÔ∏è\nüíª\n\n\n11\n14/05\nModelagem de rela√ß√µes n√£o lineares\nAjuste e compara√ß√£o de modelos polinomiais\nüìñ\nüìΩÔ∏è\nüíª\n\n\n12\n21/05\nInclus√£o de vari√°veis categ√≥ricas em modelos lineares\nCodifica√ß√£o e interpreta√ß√£o de efeitos categ√≥ricos e intera√ß√µes\nüìñ\nüìΩÔ∏è\nüíª\n\n\n13\n28/05\nProva 2\nProva m√∫ltipla escolha: avalia√ß√£o dos conceitos de regress√£o, infer√™ncia e compara√ß√£o de modelos\n\n\n\n\n\n-\n04/06\nFeriado (Corpus Christi)\n\n\n\n\n\n\n14\n11/06\nModelos bayesianos para dados bin√°rios\nAjuste, interpreta√ß√£o e predi√ß√£o com o modelo binomial\nüìñ\nüìΩÔ∏è\nüíª\n\n\n15\n18/06\nModelos bayesianos para dados de contagem\nAjuste e avalia√ß√£o do modelo de Poisson\nüìñ\nüìΩÔ∏è\nüíª\n\n\n16\n25/06\nApresenta√ß√£o do trabalho final\nApresenta√ß√£o oral e discuss√£o dos trabalhos finais\n\n\n\n\n\n17\n02/07\nApresenta√ß√£o do trabalho final\nApresenta√ß√£o oral e discuss√£o dos trabalhos finais\n\n\n\n\n\n-\n09/07\nFeriado (Revolu√ß√£o Constitucionalista)",
    "crumbs": [
      "Informa√ß√µes do curso",
      "Cronograma"
    ]
  },
  {
    "objectID": "course-info/bibliography.html",
    "href": "course-info/bibliography.html",
    "title": "Bibliografia e Links √öteis",
    "section": "",
    "text": "A bibliografia e os links √∫teis ser√£o atualizados em breve.",
    "crumbs": [
      "Informa√ß√µes do curso",
      "Bibliografia e Links √öteis"
    ]
  },
  {
    "objectID": "content/pre-reading/pread-01-golem-de-praga.html",
    "href": "content/pre-reading/pread-01-golem-de-praga.html",
    "title": "O Golem de Praga",
    "section": "",
    "text": "NotaSobre este material\n\n\n\nTradu√ß√£o adaptada do livro Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2¬™ ed.) de Richard McElreath. Os recursos originais do autor, v√≠deos das aulas, c√≥digos e materiais complementares, est√£o dispon√≠veis em https://xcelab.net/rm/ e https://github.com/rmcelreath/stat_rethinking_2026.",
    "crumbs": [
      "Leitura Pr√©via",
      "Aula 1 - O Golem de Praga"
    ]
  },
  {
    "objectID": "content/pre-reading/pread-01-golem-de-praga.html#golems-estat√≠sticos",
    "href": "content/pre-reading/pread-01-golem-de-praga.html#golems-estat√≠sticos",
    "title": "O Golem de Praga",
    "section": "1.1. Golems estat√≠sticos",
    "text": "1.1. Golems estat√≠sticos\nCientistas tamb√©m criam golems. Nossos golems raramente t√™m forma f√≠sica, mas eles tamb√©m s√£o frequentemente feitos de argila, vivendo em sil√≠cio como c√≥digo de computador. Esses golems s√£o modelos estat√≠sticos. Mas esses golems t√™m efeitos reais no mundo, por meio das predi√ß√µes que fazem e das intui√ß√µes que desafiam ou inspiram. Uma preocupa√ß√£o com a ‚Äúverdade‚Äù vivifica esses modelos, mas assim como um golem ou um rob√¥ moderno, os modelos estat√≠sticos n√£o s√£o verdadeiros nem falsos, nem profetas nem charlat√£es. Em vez disso, s√£o constru√ß√µes projetadas para algum prop√≥sito. Essas constru√ß√µes s√£o incrivelmente poderosas, executando diligentemente seus c√°lculos programados.\n\nFigura 1.1. Exemplo de √°rvore de decis√£o, ou fluxograma, para selecionar um procedimento estat√≠stico apropriado. Come√ßando pelo topo, o usu√°rio responde a uma s√©rie de perguntas sobre medi√ß√£o e inten√ß√£o, chegando eventualmente ao nome de um procedimento. Muitas dessas √°rvores de decis√£o s√£o poss√≠veis.\n√Äs vezes, sua l√≥gica inflex√≠vel revela implica√ß√µes previamente ocultas para seus projetistas. Essas implica√ß√µes podem ser descobertas inestim√°veis. Ou podem produzir comportamentos tolos e perigosos. Em vez de anjos idealizados da raz√£o, os modelos estat√≠sticos s√£o rob√¥s de argila poderosos, sem inten√ß√£o pr√≥pria, trope√ßando de acordo com as instru√ß√µes m√≠opes que incorporam. Assim como o golem do Rabino Judah, os golems da ci√™ncia s√£o sabiamente vistos com admira√ß√£o e apreens√£o ao mesmo tempo. N√≥s absolutamente precisamos us√°-los, mas faz√™-lo sempre implica algum risco.\nExistem muitos tipos de modelos estat√≠sticos. Sempre que algu√©m emprega mesmo um procedimento estat√≠stico simples, como um teste t cl√°ssico, essa pessoa est√° lan√ßando m√£o de um pequeno golem que obedientemente executar√° um c√°lculo exato, realizando-o da mesma maneira (quase) todas as vezes, sem reclamar. Praticamente todos os ramos da ci√™ncia dependem dos sentidos dos golems estat√≠sticos. Em muitos casos, j√° n√£o √© mais poss√≠vel sequer medir fen√¥menos de interesse sem fazer uso de um modelo. Para medir a for√ßa da sele√ß√£o natural, ou a velocidade de um neutrino, ou o n√∫mero de esp√©cies na Amaz√¥nia, precisamos usar modelos. O golem √© uma pr√≥tese, fazendo as medi√ß√µes por n√≥s, realizando c√°lculos impressionantes, encontrando padr√µes onde nenhum √© √≥bvio.\nNo entanto, n√£o h√° sabedoria no golem. Ele n√£o discerne quando o contexto √© inadequado para suas respostas. Ele apenas conhece seu pr√≥prio procedimento, nada mais. Ele simplesmente faz o que lhe √© dito.\nE assim permanece um triunfo da ci√™ncia estat√≠stica o fato de que hoje existem tantos golems diversos, cada um √∫til em um contexto particular. Visto dessa forma, a estat√≠stica n√£o √© nem matem√°tica nem ci√™ncia, mas sim um ramo da engenharia. E, como na engenharia, um conjunto comum de princ√≠pios de projeto e restri√ß√µes produz uma grande diversidade de aplica√ß√µes especializadas.\nEssa diversidade de aplica√ß√µes ajuda a explicar por que os cursos introdut√≥rios de estat√≠stica s√£o t√£o frequentemente confusos para os iniciantes. Em vez de um √∫nico m√©todo para construir, refinar e criticar modelos estat√≠sticos, os alunos recebem um zool√≥gico de golems pr√©-constru√≠dos conhecidos como ‚Äútestes‚Äù. Cada teste tem um prop√≥sito espec√≠fico. √Årvores de decis√£o, como a da Figura 1.1, s√£o comuns. Ao responder uma s√©rie de perguntas sequenciais, os usu√°rios escolhem o procedimento ‚Äúcorreto‚Äù para suas circunst√¢ncias de pesquisa.\nInfelizmente, enquanto estat√≠sticos experientes compreendem a unidade desses procedimentos, estudantes e pesquisadores raramente o fazem. Cursos avan√ßados de estat√≠stica enfatizam princ√≠pios de engenharia, mas a maioria dos cientistas nunca chega t√£o longe. Ensinar estat√≠stica dessa forma √© um pouco como ensinar engenharia de tr√°s para frente, come√ßando com a constru√ß√£o de pontes e terminando com a f√≠sica b√°sica. Assim, estudantes e muitos cientistas tendem a usar gr√°ficos como a Figura 1.1 sem pensar muito em sua estrutura subjacente, sem muita consci√™ncia dos modelos que cada procedimento incorpora, e sem qualquer arcabou√ßo para ajud√°-los a fazer os compromissos inevit√°veis exigidos pela pesquisa real. A culpa n√£o √© deles.\nPara alguns, a caixa de ferramentas de golems pr√©-fabricados √© tudo de que jamais precisar√£o. Contanto que permane√ßam dentro de contextos bem testados, usando apenas alguns procedimentos diferentes em tarefas apropriadas, muita boa ci√™ncia pode ser realizada. Isso √© semelhante a como encanadores podem fazer muito trabalho √∫til sem saber muito sobre din√¢mica dos fluidos. Problemas s√©rios come√ßam quando os acad√™micos passam a conduzir pesquisa inovadora, empurrando as fronteiras de suas especialidades. √â como se obtiv√©ssemos nossos engenheiros hidr√°ulicos promovendo encanadores.\nPor que os testes n√£o s√£o suficientes para a pesquisa? Os procedimentos cl√°ssicos da estat√≠stica introdut√≥ria tendem a ser inflex√≠veis e fr√°geis. Por inflex√≠veis, quero dizer que eles t√™m maneiras muito limitadas de se adaptar a contextos de pesquisa √∫nicos. Por fr√°geis, quero dizer que eles falham de maneiras imprevis√≠veis quando aplicados a novos contextos. Isso importa, porque nas fronteiras da maioria das ci√™ncias, raramente fica claro qual procedimento √© apropriado. Nenhum dos golems tradicionais foi avaliado em cen√°rios de pesquisa in√©ditos, e por isso pode ser dif√≠cil escolher um e depois entender como ele se comporta. Um bom exemplo √© o teste exato de Fisher, que se aplica (exatamente) a um contexto emp√≠rico extremamente restrito, mas √© usado regularmente sempre que as contagens nas c√©lulas s√£o pequenas. Eu pessoalmente li centenas de usos do teste exato de Fisher em peri√≥dicos cient√≠ficos, mas, fora o uso original de Fisher, nunca vi esse teste ser usado de maneira apropriada. Mesmo um procedimento como a regress√£o linear ordin√°ria, que √© bastante flex√≠vel de muitas maneiras, sendo capaz de codificar uma grande diversidade de hip√≥teses interessantes, √© √†s vezes fr√°gil. Por exemplo, se houver erro de medi√ß√£o substancial nas vari√°veis preditoras, o procedimento pode falhar de maneiras espetaculares. Mas, mais importante, √© quase sempre poss√≠vel fazer melhor do que a regress√£o linear ordin√°ria, em grande parte por causa de um fen√¥meno conhecido como overfitting.\nA quest√£o n√£o √© que as ferramentas estat√≠sticas sejam especializadas. √â claro que s√£o. A quest√£o √© que as ferramentas cl√°ssicas n√£o s√£o diversas o suficiente para lidar com muitas perguntas de pesquisa comuns. Toda √°rea ativa da ci√™ncia lida com dificuldades √∫nicas de medi√ß√£o e interpreta√ß√£o, e conversa com teorias idiossincr√°ticas em um dialeto mal compreendido por outros cientistas de outras tribos. Especialistas em estat√≠stica de fora da disciplina podem ajudar, mas s√£o limitados pela falta de flu√™ncia nas preocupa√ß√µes emp√≠ricas e te√≥ricas da disciplina.\nAl√©m disso, nenhuma ferramenta estat√≠stica faz nada por conta pr√≥pria para abordar o problema b√°sico de inferir causas a partir da evid√™ncia. Os golems estat√≠sticos n√£o compreendem causa e efeito. Eles compreendem apenas associa√ß√£o. Sem nossa orienta√ß√£o e ceticismo, golems pr√©-fabricados podem n√£o fazer nada de √∫til. Pior, eles podem destruir Praga.\nO que os pesquisadores precisam √© de alguma teoria unificada de engenharia de golems, um conjunto de princ√≠pios para projetar, construir e refinar procedimentos estat√≠sticos de prop√≥sito espec√≠fico. Todo ramo importante da filosofia estat√≠stica possui tal teoria unificada. Mas a teoria nunca √© ensinada em cursos introdut√≥rios ‚Äî e frequentemente nem mesmo em cursos avan√ßados. Portanto, h√° benef√≠cios em repensar a infer√™ncia estat√≠stica como um conjunto de estrat√©gias, em vez de um conjunto de ferramentas prontas.",
    "crumbs": [
      "Leitura Pr√©via",
      "Aula 1 - O Golem de Praga"
    ]
  },
  {
    "objectID": "content/pre-reading/pread-01-golem-de-praga.html#repensando-a-estat√≠stica",
    "href": "content/pre-reading/pread-01-golem-de-praga.html#repensando-a-estat√≠stica",
    "title": "O Golem de Praga",
    "section": "1.2. Repensando a estat√≠stica",
    "text": "1.2. Repensando a estat√≠stica\nMuita coisa pode dar errado com a infer√™ncia estat√≠stica, e essa √© uma raz√£o pela qual os iniciantes ficam t√£o ansiosos a respeito dela. Quando o arcabou√ßo consiste em escolher um teste pronto de um fluxograma, a ansiedade pode crescer √† medida que a pessoa se preocupa em escolher o teste ‚Äúcorreto‚Äù. Os estat√≠sticos, por sua vez, podem sentir prazer em repreender os cientistas, tornando a batalha psicol√≥gica ainda pior.\nMas a ansiedade pode ser cultivada em sabedoria. Essa √© a raz√£o pela qual este cap√≠tulo insiste em trabalhar com as engrenagens computacionais de cada golem. Se voc√™ n√£o entende como o golem processa a informa√ß√£o, ent√£o n√£o pode interpretar a sa√≠da do golem. Isso exige conhecer o modelo estat√≠stico em maior detalhe do que √© costumeiro, e exige fazer os c√°lculos da maneira dif√≠cil, pelo menos at√© que voc√™ seja s√°bio o suficiente para usar as solu√ß√µes de apertar-um-bot√£o.\nExistem tamb√©m obst√°culos conceituais, obst√°culos relacionados a como os acad√™micos definem objetivos estat√≠sticos e interpretam resultados estat√≠sticos. Compreender qualquer golem individual n√£o √© suficiente nesses casos. Em vez disso, precisamos de alguma epistemologia estat√≠stica, uma aprecia√ß√£o de como os modelos estat√≠sticos se relacionam com as hip√≥teses e os mecanismos naturais de interesse. Afinal, o que devemos fazer com essas pequenas m√°quinas computacionais?\nO maior obst√°culo que encontro entre estudantes e colegas √© a cren√ßa t√°cita de que o objetivo apropriado da infer√™ncia estat√≠stica √© testar hip√≥teses nulas. Esse √© o objetivo correto, pensa-se, porque Karl Popper argumentou que a ci√™ncia avan√ßa falsificando hip√≥teses. Karl Popper (1902‚Äì1994) √© possivelmente o fil√≥sofo da ci√™ncia mais influente, pelo menos entre os cientistas. Ele argumentou de maneira persuasiva que a ci√™ncia funciona melhor desenvolvendo hip√≥teses que s√£o, em princ√≠pio, falsific√°veis. Buscar evid√™ncias que possam envergonhar nossas ideias √© um padr√£o normativo, e um ao qual a maioria dos acad√™micos ‚Äî quer se descrevam como cientistas ou n√£o ‚Äî subscreve. Ent√£o talvez os procedimentos estat√≠sticos devam falsificar hip√≥teses, se desejamos ser bons cientistas estat√≠sticos.\nMas o exposto acima √© um tipo de popperismo popular, uma filosofia informal da ci√™ncia comum entre cientistas, mas n√£o entre fil√≥sofos da ci√™ncia. A ci√™ncia n√£o √© descrita pelo padr√£o de falsifica√ß√£o, e Popper reconheceu isso. De fato, a falsifica√ß√£o dedutiva √© imposs√≠vel em quase todos os contextos cient√≠ficos. Nesta se√ß√£o, reviso duas raz√µes para essa impossibilidade.\n\nHip√≥teses n√£o s√£o modelos. As rela√ß√µes entre hip√≥teses e diferentes tipos de modelos s√£o complexas. Muitos modelos correspondem √† mesma hip√≥tese, e muitas hip√≥teses correspondem a um √∫nico modelo. Isso torna a falsifica√ß√£o estrita imposs√≠vel.\nA medi√ß√£o importa. Mesmo quando pensamos que os dados falsificam um modelo, outro observador debater√° nossos m√©todos e medidas. Eles n√£o confiam nos dados. √Äs vezes, eles est√£o certos.\n\nPor ambas as raz√µes, a falsifica√ß√£o dedutiva nunca funciona. O m√©todo cient√≠fico n√£o pode ser reduzido a um procedimento estat√≠stico, e portanto nossos m√©todos estat√≠sticos n√£o devem fingir que pode. A evid√™ncia estat√≠stica √© parte da bagun√ßa que √© a ci√™ncia, com todo o seu combate, ego√≠smo e coer√ß√£o m√∫tua. Se voc√™ acredita, como eu, que a ci√™ncia frequentemente funciona, ent√£o aprender que ela n√£o funciona pela via da falsifica√ß√£o n√£o deveria mudar sua opini√£o. Mas pode ajud√°-lo a fazer ci√™ncia melhor, porque abrir√° seus olhos para muitas fun√ß√µes legitimamente √∫teis dos golems estat√≠sticos.\n\nRepensando: O NHST √© falsificacionista? O teste de signific√¢ncia da hip√≥tese nula, NHST (Null Hypothesis Significance Testing), √© frequentemente identificado com a filosofia de ci√™ncia falsificacionista, ou popperiana. No entanto, geralmente o NHST √© usado para falsificar uma hip√≥tese nula, n√£o a hip√≥tese de pesquisa propriamente dita. Portanto, a falsifica√ß√£o est√° sendo feita em algo diferente do modelo explicativo. Isso parece o inverso da filosofia de Karl Popper.\n\n\n1.2.1. Hip√≥teses n√£o s√£o modelos\nQuando tentamos falsificar uma hip√≥tese, precisamos trabalhar com algum tipo de modelo. Mesmo quando a tentativa n√£o √© explicitamente estat√≠stica, sempre h√° um modelo t√°cito de medi√ß√£o, de evid√™ncia, que operacionaliza a hip√≥tese. Todos os modelos s√£o falsos, ent√£o o que significa falsificar um modelo? Uma consequ√™ncia da necessidade de trabalhar com modelos √© que n√£o √© mais poss√≠vel deduzir que uma hip√≥tese √© falsa apenas porque rejeitamos um modelo derivado dela.\nVamos explorar essa consequ√™ncia no contexto de um exemplo da biologia de popula√ß√µes (Figura 1.2). A partir da d√©cada de 1960, bi√≥logos evolucionistas tornaram-se interessados na proposta de que a maioria das mudan√ßas evolutivas na frequ√™ncia g√™nica √© causada n√£o pela sele√ß√£o natural, mas sim por muta√ß√£o e deriva. Ningu√©m realmente duvidava que a sele√ß√£o natural fosse respons√°vel pelo design funcional. Este era um debate sobre sequ√™ncias gen√©ticas. Assim come√ßaram v√°rias d√©cadas produtivas de combate acad√™mico sobre modelos ‚Äúneutros‚Äù de evolu√ß√£o molecular. Esse combate √© mais fortemente associado a Motoo Kimura (1924‚Äì1994), que foi talvez o mais forte defensor dos modelos neutros. Mas muitos outros geneticistas populacionais participaram. Com o passar do tempo, disciplinas relacionadas, como ecologia de comunidades e antropologia, experimentaram (ou est√£o atualmente experimentando) suas pr√≥prias vers√µes do debate da neutralidade.\nVamos usar o esquema da Figura 1.2 para explorar conex√µes entre hip√≥teses motivadoras e diferentes modelos, no contexto do debate sobre evolu√ß√£o neutra. √Ä esquerda, h√° duas hip√≥teses informais estereotipadas: Ou a evolu√ß√£o √© ‚Äúneutra‚Äù (\\(H_0\\)) ou a sele√ß√£o natural importa de alguma forma (\\(H_1\\)). Essas hip√≥teses t√™m fronteiras vagas, porque come√ßam como conjecturas verbais, n√£o como modelos precisos. Existem milhares de processos detalhados poss√≠veis que podem ser descritos como ‚Äúneutros‚Äù, dependendo das escolhas sobre, por exemplo, estrutura populacional, n√∫mero de s√≠tios, n√∫mero de alelos em cada s√≠tio, taxas de muta√ß√£o e recombina√ß√£o.\nUma vez que tenhamos feito essas escolhas, temos a coluna do meio na Figura 1.2, modelos de processo detalhados de evolu√ß√£o. \\(P_0^A\\) e \\(P_0^B\\) diferem em que um assume que o tamanho e a estrutura da popula√ß√£o foram constantes por tempo suficiente para que a distribui√ß√£o dos alelos atinja um estado estacion√°rio. O outro imagina, em vez disso, que o tamanho da popula√ß√£o flutua ao longo do tempo, o que pode ser verdadeiro mesmo quando n√£o h√° diferen√ßa seletiva entre os alelos. A hip√≥tese ‚Äúa sele√ß√£o importa‚Äù, \\(H_1\\), corresponde igualmente a muitos modelos de processo diferentes. Mostrei dois grandes protagonistas: um modelo no qual a sele√ß√£o sempre favorece certos alelos e outro no qual a sele√ß√£o flutua ao longo do tempo, favorecendo alelos diferentes.\nUma caracter√≠stica importante desses modelos de processo √© que eles expressam estrutura causal. Diferentes modelos de processo formalizam diferentes rela√ß√µes de causa e efeito. Quer sejam analisados matematicamente ou por simula√ß√£o, a dire√ß√£o do tempo em um modelo significa que certas coisas causam outras, mas n√£o o inverso. Voc√™ pode usar tais modelos para realizar experimentos e sondar suas implica√ß√µes causais. √Äs vezes, essas sondagens revelam, antes mesmo de recorrermos √† infer√™ncia estat√≠stica, que o modelo n√£o consegue explicar um fen√¥meno de interesse.\n\nFigura 1.2. Rela√ß√µes entre hip√≥teses (esquerda), modelos de processo detalhados (centro) e modelos estat√≠sticos (direita), ilustrados pelo exemplo de modelos ‚Äúneutros‚Äù de evolu√ß√£o. As hip√≥teses (H) s√£o tipicamente vagas, e por isso correspondem a mais de um modelo de processo (P). Avalia√ß√µes estat√≠sticas de hip√≥teses raramente abordam modelos de processo diretamente. Em vez disso, elas dependem de modelos estat√≠sticos (M), todos os quais refletem apenas alguns aspectos dos modelos de processo. Como resultado, as rela√ß√µes s√£o m√∫ltiplas em ambas as dire√ß√µes: Hip√≥teses n√£o implicam modelos √∫nicos, e modelos n√£o implicam hip√≥teses √∫nicas. Esse fato complica enormemente a infer√™ncia estat√≠stica.\nPara desafiar modelos de processo com dados, eles precisam ser transformados em modelos estat√≠sticos. Infelizmente, os modelos estat√≠sticos n√£o incorporam rela√ß√µes causais espec√≠ficas. Um modelo estat√≠stico expressa associa√ß√µes entre vari√°veis. Como resultado, muitos modelos de processo diferentes podem ser consistentes com qualquer modelo estat√≠stico individual.\nComo obtemos um modelo estat√≠stico a partir de um modelo causal? Uma maneira √© derivar a distribui√ß√£o de frequ√™ncia esperada de alguma quantidade ‚Äî uma ‚Äúestat√≠stica‚Äù ‚Äî do modelo causal. Por exemplo, uma estat√≠stica comum nesse contexto √© a distribui√ß√£o de frequ√™ncia (histograma) da frequ√™ncia de diferentes variantes gen√©ticas (alelos). Alguns alelos s√£o raros, aparecendo em apenas poucos indiv√≠duos. Outros s√£o muito comuns, aparecendo em muitos indiv√≠duos na popula√ß√£o. Um resultado famoso em gen√©tica de popula√ß√µes √© que um modelo como \\(P_0^A\\) produz uma distribui√ß√£o de lei de pot√™ncia das frequ√™ncias al√©licas. E assim esse fato produz um modelo estat√≠stico, \\(M_{II}\\), que prediz uma lei de pot√™ncia nos dados. Em contraste, o modelo de processo de sele√ß√£o constante \\(P_1^A\\) prediz algo bastante diferente, \\(M_{III}\\).\nInfelizmente, outros modelos de sele√ß√£o (\\(P_1^B\\)) implicam o mesmo modelo estat√≠stico, \\(M_{II}\\), que o modelo neutro. Eles tamb√©m produzem leis de pot√™ncia. Assim, chegamos √† li√ß√£o desconfort√°vel:\n\nQualquer modelo estat√≠stico (M) dado pode corresponder a mais de um modelo de processo (P).\nQualquer hip√≥tese (H) dada pode corresponder a mais de um modelo de processo (P).\nQualquer modelo estat√≠stico (M) dado pode corresponder a mais de uma hip√≥tese (H).\n\nAgora veja o que acontece quando comparamos os modelos estat√≠sticos com os dados. A abordagem cl√°ssica √© tomar o modelo ‚Äúneutro‚Äù como hip√≥tese nula. Se os dados n√£o forem suficientemente semelhantes √† expectativa sob a hip√≥tese nula, ent√£o dizemos que ‚Äúrejeitamos‚Äù a hip√≥tese nula. Suponha que seguimos a hist√≥ria desse assunto e tomamos \\(P_0^A\\) como nossa hip√≥tese nula. Isso implica dados correspondentes a \\(M_{II}\\). Mas como o mesmo modelo estat√≠stico corresponde a um modelo de sele√ß√£o \\(P_1^B\\), n√£o fica nada claro o que devemos concluir ao rejeitar ou aceitar a hip√≥tese nula. O modelo nulo n√£o √© √∫nico a nenhum modelo de processo nem hip√≥tese. Se rejeitarmos a hip√≥tese nula, n√£o podemos realmente concluir que a sele√ß√£o importa, porque existem outros modelos neutros que predizem distribui√ß√µes diferentes de alelos. E se falharmos em rejeitar a hip√≥tese nula, n√£o podemos realmente concluir que a evolu√ß√£o √© neutra, porque alguns modelos de sele√ß√£o esperam a mesma distribui√ß√£o de frequ√™ncia.\nIsso √© um enorme inc√¥modo. Uma vez que temos o diagrama na Figura 1.2, √© f√°cil ver o problema. Mas poucos de n√≥s t√™m essa sorte. Enquanto a gen√©tica de popula√ß√µes reconheceu essa quest√£o, acad√™micos de outras disciplinas continuam a testar distribui√ß√µes de frequ√™ncia contra expectativas de lei de pot√™ncia, argumentando at√© que existe apenas um modelo neutro. Mesmo que houvesse apenas um modelo neutro, existem tantos modelos n√£o-neutros que imitam as predi√ß√µes da neutralidade, que nem rejeitar nem falhar em rejeitar o modelo nulo carrega muito poder inferencial.\nEnt√£o, o que pode ser feito? Bem, se voc√™ tem m√∫ltiplos modelos de processo, muito pode ser feito. Se descobrimos que todos os modelos de processo de interesse fazem predi√ß√µes muito semelhantes, ent√£o sabemos que devemos buscar uma descri√ß√£o diferente da evid√™ncia, uma descri√ß√£o sob a qual os processos pare√ßam diferentes. Por exemplo, enquanto \\(P_0^A\\) e \\(P_1^B\\) fazem predi√ß√µes de lei de pot√™ncia muito semelhantes para a distribui√ß√£o de frequ√™ncia dos alelos, eles fazem predi√ß√µes muito dissimilares para a distribui√ß√£o de mudan√ßas na frequ√™ncia al√©lica ao longo do tempo. Compare explicitamente as predi√ß√µes de mais de um modelo, e voc√™ pode se poupar de alguns tipos comuns de tolice.\nOs modelos estat√≠sticos podem ser confundidos de outras maneiras tamb√©m, como a confus√£o causada por vari√°veis n√£o observadas e vi√©s de amostragem. Os modelos de processo nos permitem projetar modelos estat√≠sticos com esses problemas em mente. O modelo estat√≠stico sozinho n√£o √© suficiente.\n\nRepensando: Entropia e identifica√ß√£o de modelos. Uma raz√£o pela qual os modelos estat√≠sticos rotineiramente correspondem a muitos modelos de processo detalhados diferentes √© que eles dependem de distribui√ß√µes como a normal, a binomial, a de Poisson e outras. Essas distribui√ß√µes s√£o membros de uma fam√≠lia, a fam√≠lia exponencial. A natureza ama os membros dessa fam√≠lia. A natureza os ama porque a natureza ama a entropia, e todas as distribui√ß√µes da fam√≠lia exponencial s√£o distribui√ß√µes de entropia m√°xima. Tirar a personifica√ß√£o natural dessa explica√ß√£o est√° al√©m do escopo deste cap√≠tulo. A implica√ß√£o pr√°tica √© que n√£o se pode inferir mais sobre o processo evolutivo a partir de uma lei de pot√™ncia do que se pode inferir sobre o processo de desenvolvimento a partir do fato de que a altura √© normalmente distribu√≠da. Esse fato deveria nos tornar humildes em rela√ß√£o ao que os modelos de regress√£o t√≠picos ‚Äî a carne deste material ‚Äî podem nos ensinar sobre processos mecan√≠sticos. Por outro lado, a natureza de entropia m√°xima dessas distribui√ß√µes significa que podemos us√°-las para fazer trabalho estat√≠stico √∫til, mesmo quando n√£o conseguimos identificar o processo subjacente. N√£o apenas n√£o podemos identific√°-lo, como tamb√©m n√£o precisamos.\n\n\n\n1.2.2. A medi√ß√£o importa\nA l√≥gica da falsifica√ß√£o √© muito simples. Temos uma hip√≥tese H, e mostramos que ela implica alguma observa√ß√£o D. Ent√£o procuramos D. Se n√£o a encontramos, devemos concluir que H √© falsa. Os l√≥gicos chamam esse tipo de racioc√≠nio de modus tollens, que √© uma abrevia√ß√£o em latim para ‚Äúo m√©todo da destrui√ß√£o‚Äù. Em contraste, encontrar D n√£o nos diz nada de certo sobre H, porque outras hip√≥teses tamb√©m podem predizer D.\nUma f√°bula cient√≠fica convincente que emprega o modus tollens diz respeito √† cor dos cisnes. Antes de descobrir a Austr√°lia, todos os cisnes que qualquer europeu j√° havia visto tinham penas brancas. Isso levou √† cren√ßa de que todos os cisnes s√£o brancos. Vamos chamar isso de hip√≥tese formal:\n\\(H_0\\): Todos os cisnes s√£o brancos.\nQuando os europeus chegaram √† Austr√°lia, no entanto, encontraram cisnes com penas negras. Essa evid√™ncia pareceu provar instantaneamente que \\(H_0\\) era falsa. De fato, nem todos os cisnes s√£o brancos. Alguns s√£o certamente negros, de acordo com todos os observadores. O insight crucial aqui √© que, antes de viajar √† Austr√°lia, nenhuma quantidade de observa√ß√µes de cisnes brancos poderia provar que \\(H_0\\) √© verdadeira. No entanto, bastou uma √∫nica observa√ß√£o de um cisne negro para prov√°-la falsa.\nEssa √© uma hist√≥ria sedutora. Se podemos acreditar que hip√≥teses cient√≠ficas importantes podem ser formuladas nessa forma, ent√£o temos um m√©todo poderoso para melhorar a precis√£o de nossas teorias: procurar evid√™ncias que desconfirmem nossas hip√≥teses. Sempre que encontramos um cisne negro, \\(H_0\\) deve ser falsa. Progresso!\nBuscar evid√™ncias desconfirmadoras √© importante, mas isso n√£o pode ser t√£o poderoso quanto a hist√≥ria do cisne faz parecer. Al√©m dos problemas de correspond√™ncia entre hip√≥teses e modelos, discutidos na se√ß√£o anterior, a maioria dos problemas que os cientistas enfrentam n√£o √© t√£o logicamente discreta. Em vez disso, mais frequentemente enfrentamos dois problemas simult√¢neos que tornam a f√°bula do cisne n√£o-representativa. Primeiro, as observa√ß√µes s√£o propensas a erros, especialmente nas fronteiras do conhecimento cient√≠fico. Segundo, a maioria das hip√≥teses √© quantitativa, dizendo respeito a graus de exist√™ncia, em vez de discreta, dizendo respeito √† presen√ßa ou aus√™ncia total. Vamos considerar brevemente cada um desses problemas.\n1.2.2.1. Erro de observa√ß√£o. Todos os observadores concordar√£o, na maioria das condi√ß√µes, que um cisne √© preto ou branco. H√° poucos tons intermedi√°rios, e os olhos da maioria dos observadores funcionam de maneira suficientemente similar para que haja pouco ou nenhum desacordo sobre quais cisnes s√£o brancos e quais s√£o pretos. Mas esse tipo de exemplo raramente √© encontrado na ci√™ncia, pelo menos em campos maduros. Em vez disso, rotineiramente confrontamos contextos nos quais n√£o temos certeza se detectamos um resultado desconfirmador. Nas fronteiras do conhecimento cient√≠fico, a capacidade de medir um fen√¥meno hipot√©tico est√° frequentemente em quest√£o tanto quanto o pr√≥prio fen√¥meno.\nAqui est√£o dois exemplos.\nEm 2005, uma equipe de ornit√≥logos de Cornell afirmou ter evid√™ncias de um indiv√≠duo de Pica-pau-bico-de-marfim (Campephilus principalis), uma esp√©cie considerada extinta. A hip√≥tese impl√≠cita aqui √©:\n\\(H_0\\): O Pica-pau-bico-de-marfim est√° extinto.\nBastaria uma √∫nica observa√ß√£o para falsificar essa hip√≥tese. No entanto, muitos duvidaram da evid√™ncia. Apesar de extensos esfor√ßos de busca e uma recompensa em dinheiro de US$ 50.000 por informa√ß√µes que levassem a um esp√©cime vivo, nenhuma evid√™ncia que satisfizesse todas as partes surgiu at√© o momento (at√© 2015). Mesmo que boas evid√™ncias f√≠sicas eventualmente surjam, esse epis√≥dio deveria servir como contraponto √† hist√≥ria do cisne. Encontrar casos desconfirmadores √© complicado pelas dificuldades de observa√ß√£o. Cisnes negros nem sempre s√£o realmente cisnes negros, e √†s vezes cisnes brancos s√£o na verdade cisnes negros. Existem confirma√ß√µes equivocadas (falsos positivos) e desconfirma√ß√µes equivocadas (falsos negativos). Contra esse pano de fundo de dificuldades de medi√ß√£o, cientistas que j√° acreditam que o Pica-pau-bico-de-marfim est√° extinto sempre ser√£o desconfiados de uma suposta falsifica√ß√£o. Aqueles que acreditam que ele ainda est√° vivo tender√£o a contar a evid√™ncia mais vaga como falsifica√ß√£o.\nOutro exemplo, este da f√≠sica, foca na detec√ß√£o de neutrinos mais r√°pidos que a luz (FTL). Em setembro de 2011, uma equipe grande e respeitada de f√≠sicos anunciou a detec√ß√£o de neutrinos ‚Äî part√≠culas subat√¥micas pequenas e neutras capazes de passar f√°cil e inofensivamente pela maioria da mat√©ria ‚Äî que chegaram da Su√≠√ßa √† It√°lia em um tempo ligeiramente mais r√°pido do que a velocidade da luz. Segundo Einstein, neutrinos n√£o podem viajar mais r√°pido que a velocidade da luz. Ent√£o isso parece ser uma falsifica√ß√£o da relatividade especial. Se assim fosse, viraria a f√≠sica de cabe√ßa para baixo.\nA rea√ß√£o dominante da comunidade f√≠sica n√£o foi ‚ÄúEinstein estava errado!‚Äù, mas sim ‚ÄúComo a equipe errou a medi√ß√£o?‚Äù A equipe que fez a medi√ß√£o teve a mesma rea√ß√£o, e pediu a outros que verificassem seus c√°lculos e tentassem replicar o resultado.\nO que poderia dar errado na medi√ß√£o? Voc√™ poderia pensar que medir a velocidade √© uma simples quest√£o de dividir a dist√¢ncia pelo tempo. √â, na escala e energia em que vivemos. Mas com uma part√≠cula fundamental como um neutrino, se voc√™ mede quando ele inicia sua jornada, voc√™ interrompe a jornada. A part√≠cula √© consumida pela medi√ß√£o. Portanto, abordagens mais sutis s√£o necess√°rias. A diferen√ßa detectada em rela√ß√£o √† velocidade da luz, al√©m disso, √© bastante pequena, e portanto at√© a lat√™ncia do tempo que leva para um sinal viajar de um detector a uma sala de controle pode ser ordens de magnitude maior. E como a ‚Äúmedi√ß√£o‚Äù, neste caso, √© realmente uma estimativa de um modelo estat√≠stico, todas as suposi√ß√µes do modelo s√£o agora suspeitas. Em 2013, a comunidade f√≠sica era un√¢nime em que o resultado do neutrino FTL era erro de medi√ß√£o. Eles encontraram o erro t√©cnico, que envolvia um cabo mal conectado. Al√©m disso, neutrinos cronometrados a partir de eventos de supernova s√£o consistentes com Einstein, e essas dist√¢ncias s√£o muito maiores e portanto revelariam diferen√ßas de velocidade muito melhor.\nEm ambos os dramas, do pica-pau e do neutrino, o dilema central √© se a falsifica√ß√£o √© real ou esp√∫ria. A medi√ß√£o √© complicada em ambos os casos, mas de maneiras bastante diferentes, tornando tanto a detec√ß√£o verdadeira quanto a detec√ß√£o falsa plaus√≠veis. O pr√≥prio Popper estava ciente dessa limita√ß√£o inerente √† medi√ß√£o, e essa pode ser uma raz√£o pela qual o pr√≥prio Popper via a ci√™ncia como sendo mais ampla que a falsifica√ß√£o. Mas a natureza probabil√≠stica da evid√™ncia raramente aparece quando os cientistas praticantes discutem a filosofia e a pr√°tica da falsifica√ß√£o. Minha leitura da hist√≥ria da ci√™ncia √© que esses tipos de problemas de medi√ß√£o s√£o a norma, n√£o a exce√ß√£o.\n1.2.2.2. Hip√≥teses cont√≠nuas. Outro problema para a hist√≥ria do cisne √© que a maioria das hip√≥teses cient√≠ficas interessantes n√£o √© do tipo ‚Äútodos os cisnes s√£o brancos‚Äù, mas sim do tipo:\n\\(H_0\\): 80% dos cisnes s√£o brancos.\nOu talvez:\n\\(H_0\\): Cisnes negros s√£o raros.\nAgora, o que devemos concluir, ap√≥s observar um cisne negro? A hip√≥tese nula n√£o diz que cisnes negros n√£o existem, mas sim que eles t√™m alguma frequ√™ncia. A tarefa aqui n√£o √© refutar ou provar uma hip√≥tese desse tipo, mas sim estimar e explicar a distribui√ß√£o da colora√ß√£o dos cisnes com a maior precis√£o poss√≠vel. Mesmo quando n√£o h√° erro de medi√ß√£o de qualquer tipo, esse problema nos impedir√° de aplicar a hist√≥ria do modus tollens do cisne √† nossa ci√™ncia.\nVoc√™ poderia objetar que a hip√≥tese acima simplesmente n√£o √© uma boa hip√≥tese cient√≠fica, porque n√£o √© f√°cil de refutar. Mas se for esse o caso, ent√£o a maioria das quest√µes importantes sobre o mundo n√£o s√£o boas hip√≥teses cient√≠ficas. Nesse caso, devemos concluir que a defini√ß√£o de ‚Äúboa hip√≥tese‚Äù n√£o est√° nos fazendo muito bem. Agora, quase todos concordam que √© uma boa pr√°tica construir experimentos e observa√ß√µes que possam diferenciar hip√≥teses concorrentes. Mas em muitos casos, a compara√ß√£o deve ser probabil√≠stica, uma quest√£o de grau, n√£o de tipo.\n\n\n1.2.3. A falsifica√ß√£o √© consensual\nA comunidade cient√≠fica de fato passa a considerar algumas hip√≥teses como falsas. A teoria cal√≥rica do calor e o modelo geoc√™ntrico do universo j√° n√£o s√£o ensinados em cursos de ci√™ncias, a menos que seja para ensinar como foram falsificados. E a evid√™ncia frequentemente ‚Äî mas nem sempre ‚Äî tem algo a ver com tal falsifica√ß√£o.\nMas a falsifica√ß√£o √© sempre consensual, n√£o l√≥gica. √Ä luz dos problemas reais de erro de medi√ß√£o e da natureza cont√≠nua dos fen√¥menos naturais, as comunidades cient√≠ficas argumentam em dire√ß√£o a um consenso sobre o significado das evid√™ncias. Esses argumentos podem ser confusos. Depois do fato, alguns livros-texto distorcem a hist√≥ria de modo que pare√ßa falsifica√ß√£o l√≥gica. Tal revisionismo hist√≥rico pode prejudicar a todos. Pode prejudicar os cientistas, ao tornar imposs√≠vel que seu pr√≥prio trabalho esteja √† altura das lendas que os precedem. Pode tornar a ci√™ncia um alvo f√°cil, ao promover um modelo de epistemologia cient√≠fica facilmente atac√°vel. E pode prejudicar o p√∫blico, ao exagerar a definitividade do conhecimento cient√≠fico.",
    "crumbs": [
      "Leitura Pr√©via",
      "Aula 1 - O Golem de Praga"
    ]
  },
  {
    "objectID": "content/pre-reading/pread-01-golem-de-praga.html#ferramentas-para-engenharia-de-golems",
    "href": "content/pre-reading/pread-01-golem-de-praga.html#ferramentas-para-engenharia-de-golems",
    "title": "O Golem de Praga",
    "section": "1.3. Ferramentas para engenharia de golems",
    "text": "1.3. Ferramentas para engenharia de golems\nEnt√£o, se tentar imitar a falsifica√ß√£o n√£o √© uma abordagem geralmente √∫til para m√©todos estat√≠sticos, o que devemos fazer? Devemos modelar. Modelos podem ser transformados em procedimentos de teste ‚Äî todos os testes estat√≠sticos s√£o tamb√©m modelos ‚Äî mas tamb√©m podem ser usados para projetar, prever e argumentar. Fazer pesquisa se beneficia da capacidade de produzir e manipular modelos, tanto porque os problemas cient√≠ficos s√£o mais gerais do que ‚Äútestar‚Äù quanto porque os golems prontos que voc√™ talvez tenha encontrado em cursos introdut√≥rios de estat√≠stica s√£o mal adaptados a muitos contextos de pesquisa. Voc√™ pode nem saber qual modelo estat√≠stico usar, a menos que tenha um modelo generativo adicionalmente.\nSe voc√™ quer reduzir suas chances de destruir Praga, ent√£o algum conhecimento de engenharia de golems √© necess√°rio. N√£o se engane: voc√™ acabar√° destruindo Praga eventualmente. Mas se for um bom engenheiro de golems, pelo menos notar√° a destrui√ß√£o. E como saber√° muito sobre como seu golem funciona, ter√° boas chances de descobrir o que deu errado. Ent√£o seu pr√≥ximo golem n√£o ser√° t√£o ruim. Sem o treinamento em engenharia, voc√™ estar√° sempre √† merc√™ de outra pessoa.\nQueremos usar nossos modelos para v√°rios prop√≥sitos distintos: projetar investiga√ß√µes, extrair informa√ß√µes dos dados e fazer predi√ß√µes. Neste cap√≠tulo, apresentamos ferramentas que ajudam com cada prop√≥sito. Essas ferramentas s√£o:\n\nAn√°lise bayesiana de dados\nCompara√ß√£o de modelos\nModelos multin√≠vel\nModelos causais gr√°ficos\n\nEssas ferramentas s√£o profundamente relacionadas entre si, ent√£o faz sentido ensin√°-las juntas. A compreens√£o dessas ferramentas vem, como sempre, somente com a implementa√ß√£o ‚Äî voc√™ n√£o pode compreender a engenharia de golems at√© pratic√°-la. E assim este material foca principalmente em c√≥digo, em como fazer as coisas. Mas no restante deste cap√≠tulo, forne√ßo introdu√ß√µes a essas ferramentas.\n\n1.3.1. An√°lise bayesiana de dados\nSupondo que voc√™ tenha alguns dados, como deveria us√°-los para aprender sobre o mundo? N√£o h√° uma resposta unicamente correta para essa pergunta. Muitas abordagens, tanto formais quanto heur√≠sticas, podem ser eficazes. Mas uma das respostas mais eficazes e gerais √© usar a an√°lise bayesiana de dados. A an√°lise bayesiana de dados toma uma quest√£o na forma de um modelo e usa a l√≥gica para produzir uma resposta na forma de distribui√ß√µes de probabilidade.\nEm termos modestos, a an√°lise bayesiana de dados √© nada mais do que contar o n√∫mero de maneiras como os dados poderiam acontecer, de acordo com nossas suposi√ß√µes. Coisas que podem acontecer de mais maneiras s√£o mais plaus√≠veis. A teoria da probabilidade √© relevante porque a probabilidade √© simplesmente um c√°lculo para contar. Isso nos permite usar a teoria da probabilidade como uma forma geral de representar plausibilidade, seja em refer√™ncia a eventos cont√°veis no mundo ou a construtos te√≥ricos como par√¢metros. O restante segue logicamente. Uma vez que definimos o modelo estat√≠stico, a an√°lise bayesiana de dados imp√µe uma maneira puramente l√≥gica de processar os dados para produzir infer√™ncia.\nPor agora, ser√° √∫til ter outra abordagem para comparar. A probabilidade bayesiana √© uma abordagem muito geral para a probabilidade, e inclui como caso especial outra abordagem importante, a abordagem frequentista. A abordagem frequentista requer que todas as probabilidades sejam definidas pela conex√£o com as frequ√™ncias de eventos em amostras muito grandes. Isso leva a incerteza frequentista a ser baseada em reamostragem imagin√°ria dos dados ‚Äî se repet√≠ssemos a medi√ß√£o muitas e muitas vezes, acabar√≠amos coletando uma lista de valores que ter√° algum padr√£o. Isso significa tamb√©m que par√¢metros e modelos n√£o podem ter distribui√ß√µes de probabilidade, apenas medi√ß√µes podem. A distribui√ß√£o dessas medi√ß√µes √© chamada de distribui√ß√£o amostral. Essa reamostragem nunca √© feita, e em geral nem faz sentido ‚Äî √© absurdo considerar a amostragem repetida da diversifica√ß√£o de p√°ssaros canoros nos Andes. Como Sir Ronald Fisher, um dos mais importantes estat√≠sticos frequentistas do s√©culo XX, colocou:\n\n[‚Ä¶] as √∫nicas popula√ß√µes que podem ser referenciadas em um teste de signific√¢ncia n√£o t√™m realidade objetiva, sendo exclusivamente produto da imagina√ß√£o do estat√≠stico [‚Ä¶]\n\nMas em muitos contextos, como experimentos controlados em estufas, √© um dispositivo √∫til para descrever a incerteza. Qualquer que seja o contexto, √© apenas parte do modelo, uma suposi√ß√£o sobre como os dados se pareceriam sob reamostragem. √â t√£o fantasiosa quanto a jogada bayesiana de usar a probabilidade para descrever todos os tipos de incerteza, seja emp√≠rica ou epistemol√≥gica.\nMas essas diferentes atitudes em rela√ß√£o √† probabilidade imp√µem diferentes compromissos. Considere este exemplo simples em que a diferen√ßa entre probabilidade bayesiana e frequentista importa. No ano de 1610, Galileu apontou um telesc√≥pio primitivo para o c√©u noturno e se tornou o primeiro humano a ver os an√©is de Saturno. Bem, ele provavelmente viu um borr√£o, com alguns borr√µes menores ligados a ele (Figura 1.3). Como o telesc√≥pio era primitivo, ele n√£o conseguia realmente focar a imagem muito bem. Saturno sempre aparecia borrado. Esse √© um problema estat√≠stico, de certa forma. H√° incerteza sobre a forma do planeta, mas note que nenhuma da incerteza √© resultado de varia√ß√£o em medi√ß√µes repetidas. Poder√≠amos olhar pelo telesc√≥pio mil vezes, e ele sempre dar√° a mesma imagem borrada (para qualquer posi√ß√£o dada da Terra e de Saturno). Portanto, a distribui√ß√£o amostral de qualquer medi√ß√£o √© constante, porque a medi√ß√£o √© determin√≠stica ‚Äî n√£o h√° nada de ‚Äúaleat√≥rio‚Äù nela. A infer√™ncia estat√≠stica frequentista tem muita dificuldade em come√ßar aqui. Em contraste, a infer√™ncia bayesiana prossegue normalmente, porque o ‚Äúru√≠do‚Äù determin√≠stico ainda pode ser modelado usando probabilidade, desde que n√£o identifiquemos probabilidade com frequ√™ncia. Como resultado, o campo de reconstru√ß√£o e processamento de imagens √© dominado por algoritmos bayesianos.\nEm procedimentos estat√≠sticos mais rotineiros, como a regress√£o linear, essa diferen√ßa nos conceitos de probabilidade tem menos efeito. No entanto, √© importante perceber que mesmo quando um procedimento bayesiano e um procedimento frequentista d√£o exatamente a mesma resposta, nossos golems bayesianos n√£o est√£o justificando suas infer√™ncias com reamostragem imagin√°ria repetida. Mais geralmente, os golems bayesianos tratam a ‚Äúaleatoriedade‚Äù como uma propriedade da informa√ß√£o, n√£o do mundo. Nada no mundo real ‚Äî excetuando interpreta√ß√µes controversas da f√≠sica qu√¢ntica ‚Äî √© realmente aleat√≥rio. Presumivelmente, se tiv√©ssemos mais informa√ß√£o, poder√≠amos predizer tudo exatamente. Simplesmente usamos a aleatoriedade para descrever nossa incerteza diante do conhecimento incompleto. Da perspectiva do nosso golem, o lan√ßamento da moeda √© ‚Äúaleat√≥rio‚Äù, mas na verdade √© o golem que √© aleat√≥rio, n√£o a moeda.\n\nFigura 1.3. Saturno, muito parecido com o que Galileu deve ter visto. A verdadeira forma √© incerta, mas n√£o por causa de qualquer varia√ß√£o amostral. A teoria da probabilidade ainda pode ajudar.\nNote que a descri√ß√£o precedente n√£o invoca as ‚Äúcren√ßas‚Äù ou opini√µes subjetivas de ningu√©m. A an√°lise bayesiana de dados √© apenas um procedimento l√≥gico para processar informa√ß√£o. H√° uma tradi√ß√£o de usar esse procedimento como uma descri√ß√£o normativa de cren√ßa racional, uma tradi√ß√£o chamada Bayesianismo. Mas este cap√≠tulo n√£o descreve nem defende isso. Na verdade, o argumento aqui √© que nenhuma abordagem estat√≠stica, bayesiana ou n√£o, √© por si s√≥ suficiente.\n\nRepensando: A probabilidade n√£o √© unit√°ria. Ser√° desconfort√°vel para alguns leitores sugerir que h√° mais de uma maneira de definir ‚Äúprobabilidade‚Äù. Conceitos matem√°ticos n√£o s√£o unicamente corretos? N√£o s√£o. Uma vez que se adota algum conjunto de premissas, ou axiomas, tudo segue logicamente em sistemas matem√°ticos. Mas os axiomas est√£o abertos ao debate e √† interpreta√ß√£o. Portanto, n√£o h√° apenas probabilidade ‚Äúbayesiana‚Äù e ‚Äúfrequentista‚Äù, mas h√° diferentes vers√µes de probabilidade bayesiana tamb√©m, apoiando-se em diferentes argumentos para justificar a abordagem. Em textos bayesianos mais avan√ßados, voc√™ encontrar√° nomes como Bruno de Finetti, Richard T. Cox e Leonard ‚ÄúJimmie‚Äù Savage. Cada uma dessas figuras est√° associada a uma concep√ß√£o um tanto diferente da probabilidade bayesiana. H√° outros. Este material segue principalmente a interpreta√ß√£o ‚Äúl√≥gica‚Äù de Cox (ou Laplace-Jeffreys-Cox-Jaynes).\nComo diferentes interpreta√ß√µes da teoria da probabilidade podem prosperar? Por si mesmas, as entidades matem√°ticas n√£o necessariamente ‚Äúsignificam‚Äù algo, no sentido de implica√ß√£o no mundo real. O que significa tomar a raiz quadrada de um n√∫mero negativo? O que significa tomar um limite quando algo se aproxima do infinito? Estes s√£o conceitos essenciais e rotineiros, mas seus significados dependem do contexto e do analista, das cren√ßas sobre qu√£o bem a abstra√ß√£o representa a realidade. A matem√°tica n√£o acessa o mundo real diretamente. Portanto, responder a tais perguntas permanece um projeto controverso e divertido, em todos os ramos da matem√°tica aplicada. Assim, embora todos subscrevam os mesmos axiomas de probabilidade, nem todos concordam em todos os contextos sobre como interpretar a probabilidade.\n\nAntes de prosseguir para descrever as pr√≥ximas duas ferramentas, vale enfatizar uma vantagem da an√°lise bayesiana de dados, pelo menos quando os acad√™micos est√£o aprendendo modelagem estat√≠stica. Este livro inteiro poderia ser reescrito para remover qualquer men√ß√£o a ‚Äúbayesiano‚Äù. Em alguns lugares, ficaria mais f√°cil. Em outros, ficaria muito mais dif√≠cil. Mas tendo ensinado estat√≠stica aplicada das duas maneiras, descobri que o arcabou√ßo bayesiano apresenta uma vantagem pedag√≥gica distinta: muitas pessoas o acham mais intuitivo. Talvez a melhor evid√™ncia para isso seja que muitos cientistas interpretam resultados n√£o-bayesianos em termos bayesianos, por exemplo interpretando valores-p ordin√°rios como probabilidades posteriori bayesianas e intervalos de confian√ßa n√£o-bayesianos como bayesianos (conceitos que ser√£o abordados ao longo do curso). At√© instrutores de estat√≠stica cometem esses erros. Nesse sentido, ent√£o, os modelos bayesianos levam a interpreta√ß√µes mais intuitivas, aquelas que os cientistas tendem a projetar nos resultados estat√≠sticos. O padr√£o oposto de erro ‚Äî interpretar uma probabilidade a posteriori como um valor-p ‚Äî parece acontecer apenas raramente.\nNada disso garante que an√°lises bayesianas ser√£o mais corretas do que an√°lises n√£o-bayesianas. Significa apenas que as intui√ß√µes do cientista estar√£o menos comumente em desacordo com a l√≥gica real do arcabou√ßo. Isso simplifica alguns dos aspectos do ensino de modelagem estat√≠stica.\n\nRepensando: Um pouco de hist√≥ria. A infer√™ncia estat√≠stica bayesiana √© muito mais antiga que as ferramentas t√≠picas da estat√≠stica introdut√≥ria, a maioria das quais foi desenvolvida no in√≠cio do s√©culo XX. Vers√µes da abordagem bayesiana foram aplicadas ao trabalho cient√≠fico no final dos anos 1700 e repetidamente no s√©culo XIX. Mas ap√≥s a Primeira Guerra Mundial, estat√≠sticos anti-bayesianos, como Sir Ronald Fisher, conseguiram marginalizar a abordagem. Tudo o que Fisher disse sobre a an√°lise bayesiana (ent√£o chamada de probabilidade inversa) em seu influente manual de 1925 foi:\n[‚Ä¶] a teoria da probabilidade inversa √© fundada sobre um erro, e deve ser inteiramente rejeitada.\nA an√°lise bayesiana de dados tornou-se cada vez mais aceita dentro da estat√≠stica durante a segunda metade do s√©culo XX, porque se provou n√£o estar fundada sobre um erro. Toda filosofia √† parte, ela funcionava. A partir da d√©cada de 1990, novas abordagens computacionais levaram a um r√°pido crescimento na aplica√ß√£o de m√©todos bayesianos. Os m√©todos bayesianos permanecem computacionalmente caros, no entanto. E assim, √† medida que os conjuntos de dados aumentaram em escala ‚Äî milh√µes de linhas s√£o comuns em an√°lise gen√¥mica, por exemplo ‚Äî alternativas ou aproxima√ß√µes √† infer√™ncia bayesiana permanecem importantes, e provavelmente sempre ser√£o.\n\n\n\n1.3.2. Compara√ß√£o de modelos e predi√ß√£o\nA an√°lise bayesiana de dados fornece uma maneira para os modelos aprenderem com os dados. Mas quando h√° mais de um modelo plaus√≠vel ‚Äî e na maioria dos campos maduros deveria haver ‚Äî como devemos escolher entre eles? Uma resposta √© preferir modelos que fazem boas predi√ß√µes. Essa resposta cria muitas perguntas novas, j√° que saber qual modelo far√° as melhores predi√ß√µes parece exigir conhecer o futuro. Examinaremos profundamente duas ferramentas relacionadas, nenhuma das quais conhece o futuro: valida√ß√£o cruzada e crit√©rios de informa√ß√£o. Essas ferramentas visam nos permitir comparar modelos com base na acur√°cia preditiva esperada.\nComparar modelos pela acur√°cia preditiva pode ser √∫til por si s√≥. E ser√° ainda mais √∫til porque leva √† descoberta de um fato surpreendente: Modelos complexos frequentemente fazem predi√ß√µes piores do que modelos mais simples. O paradoxo prim√°rio da predi√ß√£o √© o overfitting: Ajustar √© f√°cil; predizer √© dif√≠cil. Dados futuros n√£o ser√£o exatamente como dados passados, e portanto qualquer modelo que n√£o esteja ciente desse fato tende a fazer predi√ß√µes piores do que poderia. E modelos mais complexos tendem a ter mais overfitting do que os simples ‚Äî quanto mais esperto o golem, mais tolas suas predi√ß√µes. Portanto, se desejamos fazer boas predi√ß√µes, n√£o podemos julgar nossos modelos simplesmente por qu√£o bem eles se ajustam aos nossos dados.\nA valida√ß√£o cruzada e os crit√©rios de informa√ß√£o nos ajudam de tr√™s maneiras relacionadas. Primeiro, eles fornecem expectativas √∫teis de acur√°cia preditiva, em vez de meramente ajuste √† amostra. Portanto, comparam modelos onde importa. Segundo, eles nos d√£o uma estimativa da tend√™ncia de um modelo a sofrer overfitting nos dados. Isso nos ajudar√° a entender como modelos e dados interagem, o que por sua vez nos ajuda a projetar modelos melhores. Retomaremos esse ponto na pr√≥xima se√ß√£o. Terceiro, a valida√ß√£o cruzada e os crit√©rios de informa√ß√£o podem nos ajudar a identificar observa√ß√µes altamente influentes.\nA an√°lise bayesiana de dados tem sido trabalhada por s√©culos. Os crit√©rios de informa√ß√£o s√£o comparativamente muito jovens e o campo est√° evoluindo rapidamente. Muitos estat√≠sticos nunca usaram crit√©rios de informa√ß√£o em um problema aplicado, e n√£o h√° consenso sobre quais m√©tricas s√£o melhores e como melhor us√°-las. Ainda assim, os crit√©rios de informa√ß√£o j√° s√£o de uso frequente nas ci√™ncias, aparecendo em publica√ß√µes proeminentes e figurando em debates proeminentes. Seu poder √© frequentemente exagerado, e teremos cuidado em notar o que eles n√£o podem fazer, assim como o que podem.\n\nRepensando: O Neandertal em voc√™. Mesmo modelos simples precisam de alternativas. Em 2010, um rascunho do genoma de um Neandertal demonstrou mais sequ√™ncias de DNA em comum com humanos contempor√¢neos n√£o-africanos do que com africanos. Essa descoberta √© consistente com cruzamento entre Neandertais e humanos modernos, √† medida que estes se dispersaram da √Åfrica. No entanto, simplesmente encontrar DNA em comum entre europeus modernos e Neandertais n√£o √© suficiente para demonstrar cruzamento. Tamb√©m √© consistente com estrutura antiga no continente africano. Em resumo, se antigos habitantes do nordeste da √Åfrica tinham sequ√™ncias de DNA √∫nicas, ent√£o tanto Neandertais quanto europeus modernos poderiam possuir essas sequ√™ncias de um ancestral comum, em vez de cruzamento direto. Portanto, mesmo no caso aparentemente simples de estimar se Neandertais e humanos modernos compartilham DNA √∫nico, h√° mais de uma explica√ß√£o baseada em processos. A compara√ß√£o de modelos √© necess√°ria.\n\n\n\n1.3.3. Modelos multin√≠vel\nEm uma narrativa ap√≥crifa da cosmologia hindu, diz-se que a Terra repousa sobre as costas de um grande elefante, que por sua vez est√° de p√© sobre as costas de uma enorme tartaruga. Quando perguntado sobre o que a tartaruga est√°, diz-se que um guru responde: ‚Äús√£o tartarugas at√© o fim‚Äù.\nOs modelos estat√≠sticos n√£o cont√™m tartarugas, mas cont√™m par√¢metros. E os par√¢metros apoiam a infer√™ncia. Sobre o que os pr√≥prios par√¢metros se apoiam? √Äs vezes, em alguns dos modelos mais poderosos, s√£o par√¢metros at√© o fim. O que isso significa √© que qualquer par√¢metro particular pode ser utilmente considerado como um espa√ßo reservado para um modelo ausente. Dado algum modelo de como o par√¢metro obt√©m seu valor, √© simples o suficiente inserir o novo modelo dentro do antigo. Isso resulta em um modelo com m√∫ltiplos n√≠veis de incerteza, cada um alimentando o pr√≥ximo ‚Äî um modelo multin√≠vel.\nModelos multin√≠vel ‚Äî tamb√©m conhecidos como modelos hier√°rquicos, de efeitos aleat√≥rios, de efeitos vari√°veis, ou de efeitos mistos ‚Äî est√£o se tornando de rigueur nas ci√™ncias biol√≥gicas e sociais. Campos t√£o diversos quanto testagem educacional e filogen√©tica bacteriana agora dependem de modelos multin√≠vel rotineiros para processar dados. Assim como a an√°lise bayesiana de dados, a modelagem multin√≠vel n√£o √© particularmente nova, mas s√≥ est√° dispon√≠vel em computadores de mesa h√° algumas d√©cadas. E como tais modelos t√™m uma representa√ß√£o bayesiana natural, eles cresceram de m√£os dadas com a an√°lise bayesiana de dados.\nEstaremos interessados em modelos multin√≠vel principalmente porque eles nos ajudam a lidar com o overfitting. A valida√ß√£o cruzada e os crit√©rios de informa√ß√£o medem o risco de overfitting e nos ajudam a reconhec√™-lo. Mas os modelos multin√≠vel realmente fazem algo a respeito. O que eles fazem √© explorar um truque estat√≠stico surpreendente conhecido como pooling parcial, que agrupa informa√ß√µes entre unidades nos dados para produzir estimativas melhores para todas as unidades. Os detalhes ser√£o abordados ao longo do curso.\nO pooling parcial √© a tecnologia-chave, e os contextos em que ele √© apropriado s√£o diversos. Aqui est√£o quatro exemplos comuns.\n\nPara ajustar estimativas para amostragem repetida. Quando mais de uma observa√ß√£o surge do mesmo indiv√≠duo, local ou tempo, ent√£o modelos tradicionais de n√≠vel √∫nico podem nos enganar.\nPara ajustar estimativas para desequil√≠brio na amostragem. Quando alguns indiv√≠duos, locais ou tempos s√£o amostrados mais que outros, tamb√©m podemos ser enganados por modelos de n√≠vel √∫nico.\nPara estudar varia√ß√£o. Se nossas perguntas de pesquisa incluem varia√ß√£o entre indiv√≠duos ou outros grupos dentro dos dados, ent√£o modelos multin√≠vel s√£o uma grande ajuda, porque modelam a varia√ß√£o explicitamente.\nPara evitar a m√©dia. Frequentemente, acad√™micos calculam a m√©dia de alguns dados para construir vari√°veis para uma an√°lise de regress√£o. Isso pode ser perigoso, porque calcular a m√©dia remove varia√ß√£o. Portanto, fabrica falsa confian√ßa. Modelos multin√≠vel nos permitem preservar a incerteza nos valores originais, antes da m√©dia, enquanto ainda usamos a m√©dia para fazer predi√ß√µes.\n\nTodos os quatro se aplicam a contextos nos quais o pesquisador reconhece agrupamentos ou grupos de medi√ß√µes que podem diferir entre si. Esses agrupamentos ou grupos podem ser indiv√≠duos como diferentes estudantes, locais como diferentes cidades, ou tempos como diferentes anos. Como cada agrupamento pode muito bem ter uma tend√™ncia m√©dia diferente ou responder de maneira diferente a qualquer tratamento, dados agrupados frequentemente se beneficiam de serem modelados por um golem que espera tal varia√ß√£o.\nMas o escopo da modelagem multin√≠vel √© muito maior do que esses exemplos. Tipos diversos de modelos acabam sendo multin√≠vel: modelos para dados ausentes (imputa√ß√£o), erro de medi√ß√£o, an√°lise fatorial, alguns modelos de s√©ries temporais, tipos de regress√£o espacial e de redes, e regress√µes filogen√©ticas ‚Äî todos s√£o aplica√ß√µes especiais da estrat√©gia multin√≠vel. Captar o conceito de modelagem multin√≠vel pode levar a uma mudan√ßa de perspectiva. De repente, modelos de n√≠vel √∫nico acabam parecendo meros componentes de modelos multin√≠vel. A estrat√©gia multin√≠vel fornece um princ√≠pio de engenharia para nos ajudar a introduzir esses componentes em uma an√°lise particular, exatamente onde pensamos que precisamos deles.\nQuero convencer o leitor de algo que parece irracional: a regress√£o multin√≠vel merece ser a forma padr√£o de regress√£o. Artigos que n√£o usam modelos multin√≠vel deveriam justificar por que n√£o usam uma abordagem multin√≠vel. Certamente alguns dados e contextos n√£o precisam do tratamento multin√≠vel. Mas a maioria dos estudos contempor√¢neos nas ci√™ncias sociais e naturais, sejam experimentais ou n√£o, se beneficiaria dele. Talvez a raz√£o mais importante seja que mesmo tratamentos bem controlados interagem com aspectos n√£o medidos dos indiv√≠duos, grupos ou popula√ß√µes estudados. Isso leva √† varia√ß√£o nos efeitos do tratamento, na qual indiv√≠duos ou grupos variam em como respondem √† mesma circunst√¢ncia. Modelos multin√≠vel tentam quantificar a extens√£o dessa varia√ß√£o, bem como identificar quais unidades nos dados responderam de quais maneiras.\nEsses benef√≠cios n√£o v√™m de gra√ßa, no entanto. Ajustar e interpretar modelos multin√≠vel pode ser consideravelmente mais dif√≠cil do que ajustar e interpretar um modelo de regress√£o tradicional.\nNa pr√°tica, muitos pesquisadores simplesmente confiam em seu software caixa-preta e interpretam a regress√£o multin√≠vel exatamente como a regress√£o de n√≠vel √∫nico. Com o tempo, isso mudar√°. Houve uma √©poca na estat√≠stica aplicada em que at√© a regress√£o m√∫ltipla ordin√°ria era considerada de ponta, algo para apenas especialistas mexerem. Em vez disso, cientistas usavam muitos procedimentos simples, como testes t. Agora, quase todos usam ferramentas multivariadas. O mesmo acontecer√° eventualmente com os modelos multin√≠vel. A cultura acad√™mica e o curr√≠culo ainda t√™m algum alcance a fazer.\n\nRepensando: Previs√£o multin√≠vel de elei√ß√µes. Uma das aplica√ß√µes mais antigas da modelagem multin√≠vel √© prever os resultados de elei√ß√µes democr√°ticas. No in√≠cio da d√©cada de 1960, John Tukey (1915‚Äì2000) come√ßou a trabalhar para a National Broadcasting Company (NBC) nos Estados Unidos, desenvolvendo modelos de previs√£o eleitoral em tempo real que podiam explorar tipos diversos de dados: pesquisas, elei√ß√µes passadas, resultados parciais e resultados completos de distritos relacionados. Os modelos usavam um arcabou√ßo multin√≠vel semelhante ao que ser√° apresentado mais adiante no curso. Tukey desenvolveu e usou tais modelos para a NBC at√© 1978. A previs√£o eleitoral contempor√¢nea e a agrega√ß√£o de pesquisas permanecem um t√≥pico ativo para a modelagem multin√≠vel.\n\n\n\n1.3.4. Modelos causais gr√°ficos\nQuando o vento sopra, os galhos balan√ßam. Se voc√™ √© humano, interpreta imediatamente essa declara√ß√£o como causal: o vento faz os galhos se moverem. Mas tudo o que vemos √© uma associa√ß√£o estat√≠stica. Apenas pelos dados, poderia ser tamb√©m que os galhos balan√ßando fazem o vento. Essa conclus√£o parece tola, porque voc√™ sabe que √°rvores n√£o balan√ßam seus pr√≥prios galhos. Um modelo estat√≠stico √© um incr√≠vel motor de associa√ß√£o. Ele torna poss√≠vel detectar associa√ß√µes entre causas e seus efeitos. Mas um modelo estat√≠stico nunca √© suficiente para inferir causa, porque o modelo estat√≠stico n√£o faz distin√ß√£o entre o vento causando os galhos a balan√ßar e os galhos causando o vento a soprar. Fatos fora dos dados s√£o necess√°rios para decidir qual explica√ß√£o √© correta.\nA valida√ß√£o cruzada e os crit√©rios de informa√ß√£o tentam adivinhar a acur√°cia preditiva. Quando os introduzi acima, descrevi o overfitting como o paradoxo prim√°rio na predi√ß√£o. Agora nos voltamos para um paradoxo secund√°rio na predi√ß√£o: Modelos que s√£o causalmente incorretos podem fazer predi√ß√µes melhores do que aqueles que s√£o causalmente corretos. Como resultado, focar na predi√ß√£o pode nos enganar sistematicamente. E embora voc√™ possa ter ouvido que experimentos controlados randomizados permitem infer√™ncia causal, esses riscos se aplicam a experimentos randomizados tamb√©m. Ningu√©m est√° seguro.\nChamarei isso de problema de identifica√ß√£o e o distinguirei cuidadosamente do problema de predi√ß√£o bruta. Considere dois significados diferentes de ‚Äúpredi√ß√£o‚Äù. O mais simples se aplica quando somos observadores externos simplesmente tentando adivinhar o que acontecer√° em seguida. Nesse caso, ferramentas como a valida√ß√£o cruzada s√£o muito √∫teis. Mas essas ferramentas recomendar√£o alegremente modelos que cont√™m vari√°veis de confus√£o e sugerem rela√ß√µes causais incorretas. Por qu√™? Rela√ß√µes confundidas s√£o associa√ß√µes reais, e elas podem melhorar a predi√ß√£o. Afinal, se voc√™ olhar para fora e vir galhos balan√ßando, isso realmente prediz vento. A predi√ß√£o bem-sucedida n√£o requer identifica√ß√£o causal correta. Na verdade, as predi√ß√µes podem na realidade melhorar quando usamos um modelo que √© causalmente enganoso.\nMas o que acontece quando intervenimos no mundo? Agora tudo muda. Agora devemos considerar um segundo significado de ‚Äúpredi√ß√£o‚Äù: O que acontecer√° quando intervirmos no mundo. Suponha que recrutemos muitas pessoas para subir nas √°rvores e balan√ßar os galhos. Isso far√° vento? N√£o muito. Frequentemente, o objetivo da modelagem estat√≠stica √© produzir compreens√£o que leve a generaliza√ß√£o e aplica√ß√£o. Nesse caso, precisamos de mais do que apenas boas predi√ß√µes, na aus√™ncia de interven√ß√£o. Tamb√©m precisamos de uma compreens√£o causal precisa. Mas comparar modelos com base na acur√°cia preditiva ‚Äî ou valores-p ou qualquer outra coisa ‚Äî n√£o necessariamente a produzir√°.\nEnt√£o, o que pode ser feito? O que √© necess√°rio √© um modelo causal que possa ser usado para projetar um ou mais modelos estat√≠sticos com o prop√≥sito de identifica√ß√£o causal. Como mencionei no exemplo da evolu√ß√£o molecular neutra anteriormente neste cap√≠tulo, um modelo cient√≠fico completo cont√©m mais informa√ß√£o do que um modelo estat√≠stico derivado dele. E essa informa√ß√£o adicional cont√©m implica√ß√µes causais. A maioria dos cientistas faz uso informal dessas implica√ß√µes. Mas tamb√©m √© poss√≠vel fazer uso formal delas, demonstrando logicamente quando uma estimativa identifica uma rela√ß√£o causal. Esses m√©todos formais datam da primeira metade do s√©culo XX, mas foram mais recentemente estendidos ao estudo da medi√ß√£o, do design experimental e da capacidade de generalizar (ou transportar) resultados entre amostras.\nE a boa not√≠cia √© que mesmo quando voc√™ n√£o tem um modelo causal completo, mas apenas um modelo heur√≠stico indicando quais vari√°veis influenciam causalmente outras, voc√™ ainda pode fazer uso dessas ferramentas l√≥gicas. Essa √© a estrat√©gia que usaremos neste material. Usaremos um modelo causal gr√°fico para representar uma hip√≥tese causal. O modelo causal gr√°fico mais simples √© um grafo ac√≠clico direcionado, geralmente chamado de DAG (Directed Acyclic Graph). DAGs s√£o heur√≠sticos ‚Äî eles n√£o s√£o modelos estat√≠sticos detalhados. Mas eles nos permitem deduzir quais modelos estat√≠sticos podem fornecer infer√™ncias causais v√°lidas, assumindo que o DAG √© verdadeiro.\nMas de onde vem o pr√≥prio DAG? A terr√≠vel verdade sobre a infer√™ncia estat√≠stica √© que sua validade depende de informa√ß√£o fora dos dados. Precisamos de um modelo causal com o qual projetar tanto a coleta de dados quanto a estrutura de nossos modelos estat√≠sticos. Mas a constru√ß√£o de modelos causais n√£o √© uma empreitada puramente estat√≠stica, e a an√°lise estat√≠stica nunca pode verificar todas as nossas suposi√ß√µes. Nunca haver√° um golem que aceite dados puros e retorne um modelo confi√°vel das rela√ß√µes causais entre as vari√°veis. Vamos simplesmente ter que continuar fazendo ci√™ncia.\n\nRepensando: Salada causal. A infer√™ncia causal requer um modelo causal que √© separado do modelo estat√≠stico. Os dados n√£o s√£o suficientes. Toda filosofia concorda pelo menos nesse ponto. As respostas, no entanto, s√£o diversas. A resposta mais conservadora √© declarar ‚Äúcausalidade‚Äù como sendo um doce mental imposs√≠vel de provar, como debater a natureza da vida ap√≥s a morte. Um pouco menos conservador √© insistir que a causa s√≥ pode ser inferida sob condi√ß√µes estritas de randomiza√ß√£o e controle experimental. Isso seria muito limitante. Muitas perguntas cient√≠ficas nunca podem ser estudadas experimentalmente ‚Äî a evolu√ß√£o humana, por exemplo. Muitas outras poderiam, em princ√≠pio, ser estudadas experimentalmente, mas seria anti√©tico faz√™-lo. E muitos experimentos s√£o na verdade apenas tentativas de controle ‚Äî os pacientes nem sempre tomam sua medica√ß√£o.\nMas a abordagem que domina em muitas partes da biologia e das ci√™ncias sociais √©, em vez disso, a salada causal. A salada causal significa atirar v√°rias vari√°veis de ‚Äúcontrole‚Äù dentro de um modelo estat√≠stico, observar mudan√ßas nas estimativas e ent√£o contar uma hist√≥ria sobre causalidade. A salada causal parece fundada na no√ß√£o de que apenas vari√°veis omitidas podem nos enganar sobre causalidade. Mas vari√°veis inclu√≠das podem nos confundir com igual facilidade. Ao fazer uma salada causal, um modelo que faz boas predi√ß√µes pode ainda enganar sobre causalidade. Se usarmos o modelo para planejar uma interven√ß√£o, ele errar√° tudo.",
    "crumbs": [
      "Leitura Pr√©via",
      "Aula 1 - O Golem de Praga"
    ]
  },
  {
    "objectID": "content/pre-reading/pread-01-golem-de-praga.html#resumo",
    "href": "content/pre-reading/pread-01-golem-de-praga.html#resumo",
    "title": "O Golem de Praga",
    "section": "1.4. Resumo",
    "text": "1.4. Resumo\nEste primeiro cap√≠tulo argumentou por um repensar da filosofia estat√≠stica e cient√≠fica popular. Em vez de escolher entre v√°rias ferramentas caixa-preta para testar hip√≥teses nulas, devemos aprender a construir e analisar m√∫ltiplos modelos n√£o-nulos de fen√¥menos naturais. Para apoiar esse objetivo, o cap√≠tulo introduziu a infer√™ncia bayesiana, a compara√ß√£o de modelos, os modelos multin√≠vel e os modelos causais gr√°ficos.",
    "crumbs": [
      "Leitura Pr√©via",
      "Aula 1 - O Golem de Praga"
    ]
  },
  {
    "objectID": "content/computer-lab/lab-01-contrasting-hypotheses.html#calculando-as-frequ√™ncias",
    "href": "content/computer-lab/lab-01-contrasting-hypotheses.html#calculando-as-frequ√™ncias",
    "title": "Pr√°tica em R",
    "section": "2.1 Calculando as Frequ√™ncias",
    "text": "2.1 Calculando as Frequ√™ncias\n\nC√≥digo\n\n# Contar quantas vezes cada face apareceu\nfreq_mental &lt;- table(factor(mental, levels = 1:6))\nfreq_fisico &lt;- table(factor(fisico, levels = 1:6))\n\n# Mostrar as contagens\nprint(\"Frequ√™ncias absolutas - Dado Mental:\")\nfreq_mental\n\nprint(\"Frequ√™ncias absolutas - Dado F√≠sico:\")\nfreq_fisico\n\n# Calcular as propor√ß√µes (dividir pelo total)\nprop_mental &lt;- freq_mental / n_mental\nprop_fisico &lt;- freq_fisico / n_fisico\n\nprint(\"Propor√ß√µes - Dado Mental:\")\nround(prop_mental, 3)\n\nprint(\"Propor√ß√µes - Dado F√≠sico:\")\nround(prop_fisico, 3)\n\n\n\n\n\n\n\nDicaO que observar\n\n\n\n\nAs frequ√™ncias absolutas mostram quantas vezes cada face (1, 2, 3, 4, 5, 6) apareceu.\nAs propor√ß√µes mostram a porcentagem de cada face (valores entre 0 e 1).\nCompare mentalmente: alguma face apareceu muito mais que as outras?",
    "crumbs": [
      "Lab. Inform√°tica",
      "Aula 1 - Contrastando Hip√≥teses"
    ]
  },
  {
    "objectID": "content/computer-lab/lab-01-contrasting-hypotheses.html#visualizando-os-dados-com-gr√°ficos",
    "href": "content/computer-lab/lab-01-contrasting-hypotheses.html#visualizando-os-dados-com-gr√°ficos",
    "title": "Pr√°tica em R",
    "section": "2.2 Visualizando os Dados com Gr√°ficos",
    "text": "2.2 Visualizando os Dados com Gr√°ficos\n\nC√≥digo\n\n# Configurar para mostrar dois gr√°ficos lado a lado\npar(mfrow = c(1, 2))\n\n# Gr√°fico do dado f√≠sico\nbarplot(prop_fisico, \n        col = \"seagreen\", \n        main = \"Dado F√≠sico\",\n        xlab = \"Face\", \n        ylab = \"Propor√ß√£o\", \n        ylim = c(0, 0.35))\nabline(h = 1/6, lty = 2, col = \"red\", lwd = 2)\n\n# Gr√°fico do dado mental\nbarplot(prop_mental, \n        col = \"steelblue\", \n        main = \"Dado Mental\",\n        xlab = \"Face\", \n        ylab = \"Propor√ß√£o\", \n        ylim = c(0, 0.35))\nabline(h = 1/6, lty = 2, col = \"red\", lwd = 2)\n\n\n\n\n\n\n\nDicaO que observar\n\n\n\n\nVoc√™ deve ver dois gr√°ficos de barras lado a lado.\nA linha vermelha tracejada marca 1/6 = 0.167 (o esperado se o dado fosse uniforme).\nCompare os dois gr√°ficos: qual deles parece mais pr√≥ximo da linha vermelha?\n\n\n\n\n\n\n\n\n\nImportantePERGUNTA 1\n\n\n\nOlhando para os dois gr√°ficos:\n\nO dado f√≠sico parece seguir uma distribui√ß√£o uniforme (todas as faces com propor√ß√£o pr√≥xima de 1/6)? Justifique.\nO dado mental parece seguir uma distribui√ß√£o uniforme? Quais faces aparecem mais ou menos que o esperado?",
    "crumbs": [
      "Lab. Inform√°tica",
      "Aula 1 - Contrastando Hip√≥teses"
    ]
  },
  {
    "objectID": "content/computer-lab/lab-01-contrasting-hypotheses.html#calculando-as-verossimilhan√ßas",
    "href": "content/computer-lab/lab-01-contrasting-hypotheses.html#calculando-as-verossimilhan√ßas",
    "title": "Pr√°tica em R",
    "section": "2.3 Calculando as Verossimilhan√ßas",
    "text": "2.3 Calculando as Verossimilhan√ßas\n\nC√≥digo\n\n# Definir as probabilidades de cada modelo\np_h0 &lt;- rep(1/6, 6)  # H‚ÇÄ: todas as faces com prob = 1/6\np_h1 &lt;- c(1, 2, 4, 4, 2, 1) / 14  # H‚ÇÅ: vi√©s central\n\n# Ver as probabilidades de H‚ÇÅ\nprint(\"Probabilidades do modelo H‚ÇÅ:\")\nround(p_h1, 3)\n\n# Calcular log-verossimilhan√ßa de H‚ÇÄ para o dado f√≠sico\nloglik_H0_fisico &lt;- sum(freq_fisico * log(p_h0))\n\n# Calcular log-verossimilhan√ßa de H‚ÇÅ para o dado f√≠sico\nloglik_H1_fisico &lt;- sum(freq_fisico * log(p_h1))\n\n# Calcular log-verossimilhan√ßa de H‚ÇÄ para o dado mental\nloglik_H0_mental &lt;- sum(freq_mental * log(p_h0))\n\n# Calcular log-verossimilhan√ßa de H‚ÇÅ para o dado mental\nloglik_H1_mental &lt;- sum(freq_mental * log(p_h1))\n\n# Mostrar os resultados\nprint(\"=== DADO F√çSICO ===\")\nprint(paste(\"Log-verossimilhan√ßa H‚ÇÄ:\", round(loglik_H0_fisico, 2)))\nprint(paste(\"Log-verossimilhan√ßa H‚ÇÅ:\", round(loglik_H1_fisico, 2)))\n\nprint(\"=== DADO MENTAL ===\")\nprint(paste(\"Log-verossimilhan√ßa H‚ÇÄ:\", round(loglik_H0_mental, 2)))\nprint(paste(\"Log-verossimilhan√ßa H‚ÇÅ:\", round(loglik_H1_mental, 2)))\n\n\n\n\n\n\n\nDicaO que observar\n\n\n\n\nVoc√™ v√™ os valores de log-verossimilhan√ßa (n√∫meros negativos).\nValores menos negativos = maior verossimilhan√ßa = modelo mais compat√≠vel com os dados.\nCompare H‚ÇÄ vs H‚ÇÅ para cada experimento.",
    "crumbs": [
      "Lab. Inform√°tica",
      "Aula 1 - Contrastando Hip√≥teses"
    ]
  },
  {
    "objectID": "content/computer-lab/lab-01-contrasting-hypotheses.html#comparando-modelos-com-raz√£o-de-verossimilhan√ßas",
    "href": "content/computer-lab/lab-01-contrasting-hypotheses.html#comparando-modelos-com-raz√£o-de-verossimilhan√ßas",
    "title": "Pr√°tica em R",
    "section": "2.4 Comparando Modelos com Raz√£o de Verossimilhan√ßas",
    "text": "2.4 Comparando Modelos com Raz√£o de Verossimilhan√ßas\n\nC√≥digo\n\n# Calcular a raz√£o H‚ÇÅ/H‚ÇÄ para cada experimento\nrazao_fisico &lt;- exp(loglik_H1_fisico - loglik_H0_fisico)\nrazao_mental &lt;- exp(loglik_H1_mental - loglik_H0_mental)\n\nprint(\"=== RAZ√ÉO DE VEROSSIMILHAN√áAS (H‚ÇÅ/H‚ÇÄ) ===\")\nprint(paste(\"Dado F√≠sico:\", round(razao_fisico, 2)))\nprint(paste(\"Dado Mental:\", round(razao_mental, 2)))\n\n\n\n\n\n\n\nDicaO que observar\n\n\n\n\nA raz√£o de verossimilhan√ßas compara os dois modelos.\nSe a raz√£o &gt; 1: H‚ÇÅ √© mais veross√≠mil que H‚ÇÄ.\nSe a raz√£o &lt; 1: H‚ÇÄ √© mais veross√≠mil que H‚ÇÅ.\nQuanto maior o n√∫mero, mais forte √© a evid√™ncia.\n\n\n\n\n\n\n\n\n\nImportantePERGUNTA 2\n\n\n\n\nPara o dado f√≠sico, qual hip√≥tese (H‚ÇÄ ou H‚ÇÅ) √© mais compat√≠vel com os dados? Por qu√™?\nPara o dado mental, qual hip√≥tese √© mais compat√≠vel? A diferen√ßa √© grande?",
    "crumbs": [
      "Lab. Inform√°tica",
      "Aula 1 - Contrastando Hip√≥teses"
    ]
  },
  {
    "objectID": "content/computer-lab/lab-01-contrasting-hypotheses.html#teste-a-independ√™ncia-de-h‚ÇÄ-dos-dados",
    "href": "content/computer-lab/lab-01-contrasting-hypotheses.html#teste-a-independ√™ncia-de-h‚ÇÄ-dos-dados",
    "title": "Pr√°tica em R",
    "section": "2.5 Teste a Independ√™ncia de H‚ÇÄ dos Dados",
    "text": "2.5 Teste a Independ√™ncia de H‚ÇÄ dos Dados\n\nC√≥digo\n\n# Vamos criar dados fict√≠cios diferentes, mas com o MESMO total\ndados_equilibrados &lt;- c(rep(1, 8), rep(2, 9), rep(3, 8), \n                        rep(4, 9), rep(5, 8), rep(6, 8))\n\ndados_extremos &lt;- c(rep(1, 25), rep(2, 0), rep(3, 0), \n                    rep(4, 0), rep(5, 0), rep(6, 25))\n\n# Ambos t√™m n = 50 observa√ß√µes\nn_teste &lt;- 50\n\n# Calcular verossimilhan√ßa de H‚ÇÄ para os dois casos\nfreq_eq &lt;- table(factor(dados_equilibrados, levels = 1:6))\nfreq_ex &lt;- table(factor(dados_extremos, levels = 1:6))\n\nloglik_H0_equilibrado &lt;- sum(freq_eq * log(p_h0))\nloglik_H0_extremo &lt;- sum(freq_ex * log(p_h0))\n\nprint(\"=== TESTE: H‚ÇÄ √â CEGO AO PADR√ÉO? ===\")\nprint(paste(\"H‚ÇÄ para dados equilibrados:\", round(loglik_H0_equilibrado, 2)))\nprint(paste(\"H‚ÇÄ para dados extremos:\", round(loglik_H0_extremo, 2)))\nprint(paste(\"S√£o iguais?\", \n            round(loglik_H0_equilibrado, 2) == round(loglik_H0_extremo, 2)))\n\n\n\n\n\n\n\nDicaO que observar\n\n\n\n\nOs dois conjuntos de dados s√£o completamente diferentes.\nMas a verossimilhan√ßa de H‚ÇÄ √© exatamente a mesma.\nIsso confirma que H‚ÇÄ s√≥ depende do total de observa√ß√µes, n√£o do padr√£o.\n\n\n\n\n\n\n\n\n\nImportantePERGUNTA 3\n\n\n\nCom base neste teste, explique por que precisamos de pelo menos duas hip√≥teses para avaliar modelos. O que aconteceria se s√≥ tiv√©ssemos H‚ÇÄ?",
    "crumbs": [
      "Lab. Inform√°tica",
      "Aula 1 - Contrastando Hip√≥teses"
    ]
  },
  {
    "objectID": "content/computer-lab/lab-01-contrasting-hypotheses.html#simulando-sob-h‚ÇÄ",
    "href": "content/computer-lab/lab-01-contrasting-hypotheses.html#simulando-sob-h‚ÇÄ",
    "title": "Pr√°tica em R",
    "section": "3.1 Simulando sob H‚ÇÄ",
    "text": "3.1 Simulando sob H‚ÇÄ\n\nC√≥digo\n\n# N√∫mero de simula√ß√µes\nn_sim &lt;- 1000\n\n# Vetor para guardar as raz√µes de verossimilhan√ßa\nrazoes_simuladas &lt;- numeric(n_sim)\n\n# Loop: para cada simula√ß√£o...\nfor (i in 1:n_sim) {\n  # Simular uma turma sob H‚ÇÄ (dado justo)\n  amostra_sim &lt;- sample(1:6, n_mental, replace = TRUE, prob = p_h0)\n  \n  # Calcular frequ√™ncias\n  freq_sim &lt;- table(factor(amostra_sim, levels = 1:6))\n  \n  # Calcular log-verossimilhan√ßas\n  loglik_H0_sim &lt;- sum(freq_sim * log(p_h0))\n  loglik_H1_sim &lt;- sum(freq_sim * log(p_h1))\n  \n  # Guardar a raz√£o\n  razoes_simuladas[i] &lt;- exp(loglik_H1_sim - loglik_H0_sim)\n}\n\nprint(\"Simula√ß√£o conclu√≠da!\")\nprint(paste(\"M√©dia das raz√µes simuladas:\", round(mean(razoes_simuladas), 2)))\nprint(paste(\"Desvio padr√£o:\", round(sd(razoes_simuladas), 2)))\n\n\n\n\n\n\n\nDicaO que observar\n\n\n\n\nO R simulou 1000 turmas onde todos os dados v√™m de um dado justo (H‚ÇÄ).\nPara cada turma simulada, calculamos a raz√£o H‚ÇÅ/H‚ÇÄ.\nA m√©dia nos diz qual raz√£o √© ‚Äút√≠pica‚Äù quando H‚ÇÄ √© verdadeiro.",
    "crumbs": [
      "Lab. Inform√°tica",
      "Aula 1 - Contrastando Hip√≥teses"
    ]
  },
  {
    "objectID": "content/computer-lab/lab-01-contrasting-hypotheses.html#visualizando-as-simula√ß√µes",
    "href": "content/computer-lab/lab-01-contrasting-hypotheses.html#visualizando-as-simula√ß√µes",
    "title": "Pr√°tica em R",
    "section": "3.2 Visualizando as Simula√ß√µes",
    "text": "3.2 Visualizando as Simula√ß√µes\n\nC√≥digo\n\n# Fazer o histograma das raz√µes simuladas\nhist(razoes_simuladas, \n     breaks = 30, \n     col = \"lightblue\", \n     main = \"Distribui√ß√£o de H‚ÇÅ/H‚ÇÄ sob simula√ß√µes de H‚ÇÄ\",\n     xlab = \"Raz√£o de Verossimilhan√ßa (H‚ÇÅ/H‚ÇÄ)\",\n     ylab = \"Frequ√™ncia\")\n\n# Marcar onde caiu o dado f√≠sico\nabline(v = razao_fisico, col = \"green\", lwd = 3, lty = 2)\ntext(razao_fisico, 100, \"Dado F√≠sico\", pos = 4, col = \"green\")\n\n# Marcar onde caiu o dado mental\nabline(v = razao_mental, col = \"red\", lwd = 3, lty = 2)\ntext(razao_mental, 120, \"Dado Mental\", pos = 4, col = \"red\")\n\n# Marcar a linha de 1 (onde H‚ÇÄ e H‚ÇÅ t√™m mesma verossimilhan√ßa)\nabline(v = 1, col = \"black\", lwd = 2)\n\n\n\n\n\n\n\nDicaO que observar\n\n\n\n\nO histograma azul mostra as raz√µes quando geramos dados de um dado justo.\nA linha verde marca onde caiu o dado f√≠sico da nossa turma.\nA linha vermelha marca onde caiu o dado mental da nossa turma.\nA linha preta marca raz√£o = 1 (empate entre H‚ÇÄ e H‚ÇÅ).\n\n\n\n\n\n\n\n\n\nImportantePERGUNTA 4\n\n\n\n\nO valor do dado f√≠sico est√° dentro da regi√£o t√≠pica das simula√ß√µes sob H‚ÇÄ? O que isso significa?\nO valor do dado mental est√° dentro ou fora da regi√£o t√≠pica? O que isso indica sobre a necessidade de H‚ÇÅ?\nBaseado neste histograma, voc√™ diria que os dados do dado mental foram gerados por um processo uniforme (H‚ÇÄ)?",
    "crumbs": [
      "Lab. Inform√°tica",
      "Aula 1 - Contrastando Hip√≥teses"
    ]
  },
  {
    "objectID": "content/computer-lab/lab-01-contrasting-hypotheses.html#a-priori-da-turma",
    "href": "content/computer-lab/lab-01-contrasting-hypotheses.html#a-priori-da-turma",
    "title": "Pr√°tica em R",
    "section": "4.1 A Priori da Turma",
    "text": "4.1 A Priori da Turma\n\nC√≥digo\n\n# Inserir os valores REAIS da vota√ß√£o da turma\n# (substituir pelos n√∫meros do quadro)\nn_turma &lt;- 50\nvotos_H0 &lt;- 32  # Quantos votaram em H‚ÇÄ\nvotos_H1 &lt;- 18  # Quantos votaram em H‚ÇÅ\n\n# Calcular a priori\nprior_turma &lt;- c(H0 = votos_H0 / n_turma, H1 = votos_H1 / n_turma)\n\nprint(\"Priori da Turma:\")\nround(prior_turma, 2)",
    "crumbs": [
      "Lab. Inform√°tica",
      "Aula 1 - Contrastando Hip√≥teses"
    ]
  },
  {
    "objectID": "content/computer-lab/lab-01-contrasting-hypotheses.html#calculando-a-posteriori-com-diferentes-prioris",
    "href": "content/computer-lab/lab-01-contrasting-hypotheses.html#calculando-a-posteriori-com-diferentes-prioris",
    "title": "Pr√°tica em R",
    "section": "4.2 Calculando a Posteriori com Diferentes Prioris",
    "text": "4.2 Calculando a Posteriori com Diferentes Prioris\n\nC√≥digo\n\n# Fun√ß√£o auxiliar para calcular posteriori\ncalcular_posteriori &lt;- function(prior, loglik_H0, loglik_H1) {\n  lik &lt;- c(H0 = exp(loglik_H0), H1 = exp(loglik_H1))\n  post &lt;- prior * lik\n  post &lt;- post / sum(post)\n  return(post)\n}\n\n# Posteriori com priori da turma\npost_turma_mental &lt;- calcular_posteriori(prior_turma, \n                                         loglik_H0_mental, \n                                         loglik_H1_mental)\n\n# Posteriori com priori 50/50 (sem prefer√™ncia)\nprior_neutro &lt;- c(H0 = 0.5, H1 = 0.5)\npost_neutro_mental &lt;- calcular_posteriori(prior_neutro, \n                                          loglik_H0_mental, \n                                          loglik_H1_mental)\n\n# Posteriori com priori 90/10 (forte prefer√™ncia por H‚ÇÄ)\nprior_forte_H0 &lt;- c(H0 = 0.9, H1 = 0.1)\npost_forte_H0_mental &lt;- calcular_posteriori(prior_forte_H0, \n                                            loglik_H0_mental, \n                                            loglik_H1_mental)\n\n# Posteriori com priori 10/90 (forte prefer√™ncia por H‚ÇÅ)\nprior_forte_H1 &lt;- c(H0 = 0.1, H1 = 0.9)\npost_forte_H1_mental &lt;- calcular_posteriori(prior_forte_H1, \n                                            loglik_H0_mental, \n                                            loglik_H1_mental)\n\n# Mostrar resultados\nprint(\"=== PRIORI DA TURMA ===\")\nprint(round(prior_turma, 3))\nprint(\"Posteriori:\")\nprint(round(post_turma_mental, 3))\n\nprint(\"=== PRIORI NEUTRO (50/50) ===\")\nprint(round(prior_neutro, 3))\nprint(\"Posteriori:\")\nprint(round(post_neutro_mental, 3))\n\nprint(\"=== PRIORI FORTE EM H‚ÇÄ (90/10) ===\")\nprint(round(prior_forte_H0, 3))\nprint(\"Posteriori:\")\nprint(round(post_forte_H0_mental, 3))\n\nprint(\"=== PRIORI FORTE EM H‚ÇÅ (10/90) ===\")\nprint(round(prior_forte_H1, 3))\nprint(\"Posteriori:\")\nprint(round(post_forte_H1_mental, 3))",
    "crumbs": [
      "Lab. Inform√°tica",
      "Aula 1 - Contrastando Hip√≥teses"
    ]
  },
  {
    "objectID": "content/computer-lab/lab-01-contrasting-hypotheses.html#visualizando-a-atualiza√ß√£o-bayesiana",
    "href": "content/computer-lab/lab-01-contrasting-hypotheses.html#visualizando-a-atualiza√ß√£o-bayesiana",
    "title": "Pr√°tica em R",
    "section": "4.3 Visualizando a Atualiza√ß√£o Bayesiana",
    "text": "4.3 Visualizando a Atualiza√ß√£o Bayesiana\n\nC√≥digo\n\n# Criar uma figura com 4 pain√©is\npar(mfrow = c(2, 2))\n\n# Painel 1: Priori e Posteriori da Turma\nbarplot(rbind(prior_turma, post_turma_mental), \n        beside = TRUE, \n        col = c(\"grey70\", \"salmon\"),\n        main = \"Priori da Turma\",\n        ylab = \"Probabilidade\",\n        ylim = c(0, 1),\n        legend.text = c(\"Priori\", \"Posteriori\"))\n\n# Painel 2: Priori e Posteriori Neutro\nbarplot(rbind(prior_neutro, post_neutro_mental), \n        beside = TRUE, \n        col = c(\"grey70\", \"salmon\"),\n        main = \"Priori Neutro (50/50)\",\n        ylab = \"Probabilidade\",\n        ylim = c(0, 1),\n        legend.text = c(\"Priori\", \"Posteriori\"))\n\n# Painel 3: Priori e Posteriori Forte em H‚ÇÄ\nbarplot(rbind(prior_forte_H0, post_forte_H0_mental), \n        beside = TRUE, \n        col = c(\"grey70\", \"salmon\"),\n        main = \"Priori Forte em H‚ÇÄ (90/10)\",\n        ylab = \"Probabilidade\",\n        ylim = c(0, 1),\n        legend.text = c(\"Priori\", \"Posteriori\"))\n\n# Painel 4: Priori e Posteriori Forte em H‚ÇÅ\nbarplot(rbind(prior_forte_H1, post_forte_H1_mental), \n        beside = TRUE, \n        col = c(\"grey70\", \"salmon\"),\n        main = \"Priori Forte em H‚ÇÅ (10/90)\",\n        ylab = \"Probabilidade\",\n        ylim = c(0, 1),\n        legend.text = c(\"Priori\", \"Posteriori\"))\n\n\n\n\n\n\n\nDicaO que observar\n\n\n\n\nQuatro gr√°ficos mostrando como diferentes prioris levam a diferentes posterioris.\nEm cada gr√°fico, as barras cinzas s√£o a priori (antes dos dados).\nAs barras salm√£o s√£o a posteriori (depois dos dados).\nObserve como a evid√™ncia dos dados ‚Äúpuxa‚Äù a cren√ßa em dire√ß√£o a H‚ÇÅ.\n\n\n\n\n\n\n\n\n\nImportantePERGUNTA 5\n\n\n\n\nEm qual dos quatro cen√°rios a priori teve maior influ√™ncia na posteriori? Por qu√™?\nEm qual cen√°rio a priori teve menor influ√™ncia? O que isso nos ensina sobre quando a priori importa mais ou menos?\nMesmo com uma priori muito forte em H‚ÇÄ (90/10), a posteriori mudou em dire√ß√£o a H‚ÇÅ? O que isso indica sobre a for√ßa da evid√™ncia nos dados do dado mental?",
    "crumbs": [
      "Lab. Inform√°tica",
      "Aula 1 - Contrastando Hip√≥teses"
    ]
  },
  {
    "objectID": "content/computer-lab/lab-02-quantifying-uncertainty.html",
    "href": "content/computer-lab/lab-02-quantifying-uncertainty.html",
    "title": "Pr√°tica em R",
    "section": "",
    "text": "Curso: Bacharelado Interdisciplinar em Ci√™ncias do Mar\nUnidade Curricular (UC): Probabilidade e Estat√≠stica\nAtividade: Pr√°tica no Laborat√≥rio de Inform√°tica\n\n\n\n\n\n\n\n\n\nImportanteInstru√ß√µes\n\n\n\n\nCopie e execute o c√≥digo\n\nObserve os resultados que aparecem\n\nResponda √†s perguntas no documento que voc√™ vai entregar\n\nEntrega: Acesse o Moodle e adicione suas respostas √†s perguntas abaixo\n\nPrazo: Final da aula de hoje\n\n\n\n\n\n1 O Experimento do Globo\nImagine que jogamos um globo para o alto v√°rias vezes e, cada vez que o pegamos, registramos se o dedo indicador tocou √°gua (A) ou terra (T). O objetivo √© estimar a propor√ß√£o de √°gua na superf√≠cie da Terra a partir desses dados.\n\nC√≥digo\n\n# Registrar os resultados de 9 lan√ßamentos do globo\nresultados &lt;- c(\"A\", \"T\", \"A\", \"A\", \"T\", \"A\", \"T\", \"A\", \"A\")\n\n# Contar o total, a quantidade de √°gua e de terra\nn_total &lt;- length(resultados)\nn_agua  &lt;- sum(resultados == \"A\")\nn_terra &lt;- sum(resultados == \"T\")\n\n# Exibir os resultados\ncat(\"Total de lan√ßamentos:\", n_total, \"\\n\")\ncat(\"N√∫mero de A (√°gua):  \", n_agua,  \"\\n\")\ncat(\"N√∫mero de T (terra): \", n_terra, \"\\n\")\ncat(\"Propor√ß√£o observada de √°gua:\", round(n_agua / n_total, 2), \"\\n\")\n\n\n\n\n\n\n\nDicaO que observar\n\n\n\n\nO vetor resultados resume os 9 lan√ßamentos do globo.\nA propor√ß√£o observada de √°gua √© o n√∫mero de A‚Äôs dividido pelo total.\nEsta propor√ß√£o √© nossa estimativa inicial ‚Äî mas o quanto podemos confiar nela com apenas 9 lan√ßamentos?\n\n\n\n\n\n\n\n\n\nImportantePERGUNTA 1\n\n\n\n\nQual foi a propor√ß√£o observada de √°gua nos 9 lan√ßamentos?\nSe repet√≠ssemos o experimento com 9 novos lan√ßamentos, voc√™ esperaria obter exatamente a mesma propor√ß√£o? Por qu√™?\nO que aconteceria com a incerteza sobre a propor√ß√£o real de √°gua se realiz√°ssemos 90 ou 900 lan√ßamentos?\n\n\n\n\n\n\n2 Contagem de Caminhos ‚Äî O Jardim de Probabilidades\nA probabilidade pode ser entendida como uma medida da plausibilidade relativa de cada valor poss√≠vel de \\(p\\) (propor√ß√£o de √°gua), dadas as observa√ß√µes. Vamos calcular a verossimilhan√ßa ‚Äî o qu√£o compat√≠vel cada candidato a \\(p\\) √© com os dados ‚Äî usando a distribui√ß√£o binomial.\n\nC√≥digo\n\n# Definir cinco candidatos para o valor de p\ncandidatos_p &lt;- c(0, 0.25, 0.5, 0.75, 1.0)\n\n# Dados observados: 6 √°guas em 9 lan√ßamentos\nn_agua_obs  &lt;- 6\nn_lancamentos &lt;- 9\n\n# Calcular a verossimilhan√ßa de cada candidato\n# dbinom: probabilidade binomial de obter n_agua_obs sucessos em n_lancamentos tentativas\nverossimilhanca &lt;- dbinom(n_agua_obs, size = n_lancamentos, prob = candidatos_p)\n\n# Plausibilidade relativa (normalizada)\nplaus_relativa &lt;- verossimilhanca / sum(verossimilhanca)\n\n# Organizar em tabela\nresultado &lt;- data.frame(\n  p                  = candidatos_p,\n  verossimilhanca    = round(verossimilhanca, 4),\n  plaus_relativa     = round(plaus_relativa, 4)\n)\n\nprint(resultado)\n\n\n\n\n\n\n\nDicaO que observar\n\n\n\n\nA coluna verossimilhanca mostra o qu√£o prov√°vel √© observar 6 √°guas em 9 lan√ßamentos, para cada valor de \\(p\\).\nA coluna plaus_relativa normaliza esses valores para somarem 1 ‚Äî √© a plausibilidade relativa.\nOs candidatos \\(p = 0\\) e \\(p = 1.0\\) t√™m verossimilhan√ßa zero. Por qu√™?\n\n\n\n\n\n\n\n\n\nImportantePERGUNTA 2\n\n\n\n\nQual dos cinco candidatos tem maior plausibilidade relativa? Esse resultado faz sentido intuitivamente?\nPor que \\(p = 0\\) e \\(p = 1\\) t√™m verossimilhan√ßa igual a zero com esses dados?\nCom apenas cinco candidatos, conseguimos representar toda a incerteza sobre \\(p\\)? O que seria necess√°rio para uma representa√ß√£o mais completa?\n\n\n\n\n\n\n3 Grid Approximation ‚Äî Distribui√ß√£o Posterior\nEm vez de considerar apenas cinco candidatos, podemos avaliar 100 valores igualmente espa√ßados entre 0 e 1. Esse m√©todo ‚Äî a grid approximation ‚Äî nos fornece uma aproxima√ß√£o da distribui√ß√£o posterior completa de \\(p\\).\n\nC√≥digo\n\n# Definir o grid de valores poss√≠veis para p (100 pontos entre 0 e 1)\np_grid &lt;- seq(from = 0, to = 1, length.out = 100)\n\n# Prior uniforme: antes de ver os dados, todos os valores de p s√£o igualmente plaus√≠veis\nprior &lt;- rep(1, 100)\n\n# Verossimilhan√ßa: P(6 √°guas em 9 lan√ßamentos | p) para cada ponto do grid\nlikelihood &lt;- dbinom(6, size = 9, prob = p_grid)\n\n# Posterior n√£o normalizada: produto do prior pela verossimilhan√ßa\nposterior_nao_norm &lt;- likelihood * prior\n\n# Normalizar para que a √°rea total sob a curva seja 1\nposterior &lt;- posterior_nao_norm / sum(posterior_nao_norm)\n\n# Valor de p com maior plausibilidade (MAP: Maximum A Posteriori)\np_map &lt;- p_grid[which.max(posterior)]\n\n# Visualizar a distribui√ß√£o posterior\nplot(p_grid, posterior,\n     type = \"l\", lwd = 2,\n     col  = \"#1a9988\",\n     xlab = \"Propor√ß√£o de √°gua (p)\",\n     ylab = \"Plausibilidade posterior\",\n     main = paste0(\"Distribui√ß√£o Posterior\\n6 √°guas em 9 lan√ßamentos\"))\n\n# Marcar o pico da distribui√ß√£o (MAP)\nabline(v = p_map, lty = 2, col = \"orange\", lwd = 2)\ntext(p_map + 0.02, max(posterior) * 0.9,\n     paste0(\"MAP = \", round(p_map, 2)),\n     col = \"orange\", adj = 0)\n\n\n\n\n\n\n\nDicaO que observar\n\n\n\n\nA curva verde representa a distribui√ß√£o posterior: a plausibilidade de cada valor de \\(p\\) ap√≥s considerar os dados.\nA linha laranja tracejada marca o valor de \\(p\\) com maior plausibilidade posterior (MAP).\nA curva n√£o √© pontual ‚Äî ela expressa a incerteza sobre o valor real de \\(p\\).\n\n\n\n\n\n\n\n\n\nImportantePERGUNTA 3\n\n\n\n\nQual √© o valor aproximado do MAP (pico da distribui√ß√£o posterior)?\nA distribui√ß√£o posterior est√° concentrada num √∫nico valor de \\(p\\), ou h√° uma faixa de valores plaus√≠veis? O que isso indica sobre nossa incerteza?\nCom base na curva, quais valores de \\(p\\) t√™m muito baixa plausibilidade? Isso faz sentido dado o que observamos?\n\n\n\n\n\n\n4 Atualiza√ß√£o Bayesiana ‚Äî Efeito de Mais Dados\nUma das propriedades fundamentais da infer√™ncia bayesiana √© que a distribui√ß√£o posterior se torna mais estreita (mais concentrada) √† medida que coletamos mais dados. Vamos visualizar esse processo.\n\nC√≥digo\n\n# Grid de p (mesmo para todos os pain√©is)\np_grid &lt;- seq(from = 0, to = 1, length.out = 100)\nprior  &lt;- rep(1, 100)\n\n# Comparar a posterior com diferentes tamanhos de amostra\n# Mantemos a mesma propor√ß√£o observada de √°gua: 2/3\ntamanhos &lt;- c(3, 9, 27)\n\npar(mfrow = c(1, 3))  # tr√™s pain√©is lado a lado\n\nfor (n in tamanhos) {\n  w        &lt;- round(n * 2 / 3)  # n√∫mero de √°guas (2/3 de n)\n  lik      &lt;- dbinom(w, size = n, prob = p_grid)\n  post     &lt;- (lik * prior) / sum(lik * prior)\n  p_map_n  &lt;- p_grid[which.max(post)]\n\n  plot(p_grid, post,\n       type = \"l\", lwd = 2, col = \"#1a9988\",\n       main = paste0(w, \" √°guas em \", n, \" lan√ßamentos\"),\n       xlab = \"p\", ylab = \"Posterior\",\n       ylim = c(0, max(post) * 1.15))\n\n  abline(v = p_map_n, lty = 2, col = \"orange\", lwd = 2)\n}\n\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\nDicaO que observar\n\n\n\n\nOs tr√™s gr√°ficos mostram a mesma propor√ß√£o observada (2/3 de √°gua), mas com tamanhos de amostra diferentes.\nObserve como a curva vai ficando mais estreita e mais alta com mais dados.\nA localiza√ß√£o do pico (MAP) se mant√©m aproximadamente est√°vel, mas a incerteza ao redor dele diminui.\n\n\n\n\n\n\n\n\n\nImportantePERGUNTA 4\n\n\n\n\nO valor do MAP (pico da distribui√ß√£o) muda muito entre os tr√™s pain√©is?\nO que acontece com a largura da distribui√ß√£o posterior conforme o tamanho da amostra aumenta? O que isso significa na pr√°tica?\nCom \\(n = 27\\), voc√™ estaria mais confiante sobre o valor real de \\(p\\) do que com \\(n = 3\\)? Por qu√™?\n\n\n\n\n\n\n5 Efeito do Prior ‚Äî O Papel do Conhecimento Pr√©vio\nA distribui√ß√£o posterior √© o produto da verossimilhan√ßa pelo prior. Quando o prior √© uniforme (todos os valores igualmente plaus√≠veis), a posterior √© determinada apenas pelos dados. Mas quando temos conhecimento pr√©vio, o prior pode influenciar a infer√™ncia ‚Äî especialmente com poucos dados.\n\nC√≥digo\n\n# Dados: 6 √°guas em 9 lan√ßamentos\np_grid &lt;- seq(from = 0, to = 1, length.out = 100)\n\n# Prior 1: Uniforme ‚Äî sem conhecimento pr√©vio\nprior_uniforme &lt;- rep(1, 100)\n\n# Prior 2: Escalonado ‚Äî favorece levemente valores intermedi√°rios\nprior_moderado &lt;- sqrt(p_grid * (1 - p_grid))\nprior_moderado &lt;- prior_moderado / sum(prior_moderado)\n\n# Prior 3: Informativo ‚Äî concentrado em torno de p = 0.7\nprior_informativo &lt;- dnorm(p_grid, mean = 0.7, sd = 0.1)\nprior_informativo &lt;- prior_informativo / sum(prior_informativo)\n\n# Verossimilhan√ßa (mesma para todos)\nlikelihood &lt;- dbinom(6, size = 9, prob = p_grid)\n\n# Calcular as tr√™s posterioris\npost1 &lt;- (likelihood * prior_uniforme)  / sum(likelihood * prior_uniforme)\npost2 &lt;- (likelihood * prior_moderado)  / sum(likelihood * prior_moderado)\npost3 &lt;- (likelihood * prior_informativo) / sum(likelihood * prior_informativo)\n\n# Visualizar\npar(mfrow = c(3, 1), mar = c(4, 4, 2, 1))\n\nplot(p_grid, post1, type = \"l\", lwd = 2, col = \"#1a9988\",\n     main = \"Prior Uniforme\", xlab = \"p\", ylab = \"Posterior\",\n     ylim = c(0, max(c(post1, post2, post3)) * 1.1))\nabline(v = p_grid[which.max(post1)], lty = 2, col = \"orange\")\n\nplot(p_grid, post2, type = \"l\", lwd = 2, col = \"#2c5f7c\",\n     main = \"Prior Moderado (favorece valores intermedi√°rios)\",\n     xlab = \"p\", ylab = \"Posterior\",\n     ylim = c(0, max(c(post1, post2, post3)) * 1.1))\nabline(v = p_grid[which.max(post2)], lty = 2, col = \"orange\")\n\nplot(p_grid, post3, type = \"l\", lwd = 2, col = \"#e6a073\",\n     main = \"Prior Informativo (concentrado em p = 0.7)\",\n     xlab = \"p\", ylab = \"Posterior\",\n     ylim = c(0, max(c(post1, post2, post3)) * 1.1))\nabline(v = p_grid[which.max(post3)], lty = 2, col = \"orange\")\n\npar(mfrow = c(1, 1))\n\n\n\n\n\n\n\nDicaO que observar\n\n\n\n\nOs tr√™s gr√°ficos diferem apenas no prior ‚Äî a verossimilhan√ßa (dados) √© a mesma.\nCom o prior uniforme, a posterior reflete apenas os dados.\nCom o prior informativo, a posterior √© ‚Äúpuxada‚Äù na dire√ß√£o do prior.\nA influ√™ncia do prior diminui conforme o tamanho da amostra aumenta.\n\n\n\n\n\n\n\n\n\nImportantePERGUNTA 5\n\n\n\n\nO MAP muda entre os tr√™s cen√°rios? Em qual deles a diferen√ßa √© mais percept√≠vel?\nQuando faria sentido usar um prior informativo na pr√°tica? D√™ um exemplo.\nO que aconteceria com as diferen√ßas entre as tr√™s posterioris se tiv√©ssemos 100 lan√ßamentos em vez de 9?\n\n\n\n\n\n\n6 Recapitulando as Etapas de Hoje\nConceitos fundamentais praticados neste laborat√≥rio:\n\nExperimento binomial: Modelar dados de presen√ßa/aus√™ncia como lan√ßamentos independentes com probabilidade \\(p\\).\nVerossimilhan√ßa: Medir a compatibilidade de um valor de \\(p\\) com os dados usando a distribui√ß√£o binomial (dbinom()).\nGrid approximation: Calcular a distribui√ß√£o posterior para um conjunto denso de valores de \\(p\\), multiplicando prior por verossimilhan√ßa e normalizando.\nAtualiza√ß√£o bayesiana: Compreender como mais dados concentram a distribui√ß√£o posterior ao redor do valor verdadeiro.\nPrior: Reconhecer o papel do conhecimento pr√©vio na forma da distribui√ß√£o posterior e como sua influ√™ncia diminui com o aumento do tamanho amostral.",
    "crumbs": [
      "Lab. Inform√°tica",
      "Aula 2 - Quantificando a Incerteza"
    ]
  },
  {
    "objectID": "content/pre-reading/pread-02-mundos-pequenos-mundos-grandes.html",
    "href": "content/pre-reading/pread-02-mundos-pequenos-mundos-grandes.html",
    "title": "Mundos Pequenos e Mundos Grandes",
    "section": "",
    "text": "NotaSobre este material\n\n\n\nTradu√ß√£o adaptada do livro Statistical Rethinking: A Bayesian Course with Examples in R and Stan (2¬™ ed.) de Richard McElreath. Os recursos originais do autor, v√≠deos das aulas, c√≥digos e materiais complementares, est√£o dispon√≠veis em https://xcelab.net/rm/ e https://github.com/rmcelreath/stat_rethinking_2026.\nQuando Cristoforo Colombo (Crist√≥v√£o Colombo) navegou infamemente para o oeste no ano de 1492, ele acreditava que a Terra era esf√©rica. Nisso, ele era como a maioria das pessoas instru√≠das de sua √©poca. Ele diferia da maioria, por√©m, ao acreditar que o planeta era muito menor do que realmente √© ‚Äî apenas 30.000 km ao redor de seu equador, em vez dos 40.000 km reais (Figura 2.1). Esse foi um dos erros mais consequentes da hist√≥ria europeia. Se Colombo tivesse acreditado que a Terra tinha 40.000 km de circunfer√™ncia, ele teria raciocinado corretamente que sua frota n√£o poderia carregar comida e √°gua pot√°vel suficientes para completar uma viagem inteiramente para o oeste at√© a √Åsia. Mas com 30.000 km de circunfer√™ncia, a √Åsia estaria um pouco a oeste da costa da Calif√≥rnia. Era poss√≠vel carregar suprimentos suficientes para chegar t√£o longe. Encorajado em parte por sua estimativa n√£o convencional, Colombo zarpou, eventualmente aportando nas Bahamas.\nColombo fez uma predi√ß√£o baseada em sua vis√£o de que o mundo era pequeno. Mas como ele vivia em um mundo grande, aspectos da predi√ß√£o estavam errados. No seu caso, o erro foi sortudo. Seu modelo de mundo pequeno estava errado de uma maneira inesperada: havia muita terra no caminho. Se ele tivesse errado da maneira esperada, com nada al√©m de oceano entre a Europa e a √Åsia, ele e toda a sua expedi√ß√£o teriam ficado sem suprimentos muito antes de alcan√ßar as √çndias Orientais.\nOs mundos pequeno e grande de Colombo oferecem um contraste entre modelo e realidade. Toda modelagem estat√≠stica possui esses mesmos dois enquadramentos: o mundo pequeno do modelo em si e o mundo grande no qual esperamos aplicar o modelo. Navegar entre esses dois mundos permanece um desafio central da modelagem estat√≠stica. O desafio √© agravado quando se esquece a distin√ß√£o.\nO mundo pequeno √© o mundo l√≥gico autocontido do modelo. Dentro do mundo pequeno, todas as possibilidades s√£o nomeadas. N√£o h√° surpresas puras, como a exist√™ncia de um enorme continente entre a Europa e a √Åsia. Dentro do mundo pequeno do modelo, √© importante ser capaz de verificar a l√≥gica do modelo, assegurando que ele funciona conforme esperado sob suposi√ß√µes favor√°veis. Modelos bayesianos t√™m algumas vantagens nesse aspecto, pois possuem reivindica√ß√µes razo√°veis de otimalidade: nenhum modelo alternativo poderia fazer melhor uso da informa√ß√£o nos dados e apoiar melhores decis√µes, assumindo que o mundo pequeno √© uma descri√ß√£o precisa do mundo real.\nO mundo grande √© o contexto mais amplo no qual se aplica um modelo. No mundo grande, podem existir eventos que n√£o foram imaginados no mundo pequeno. Al√©m disso, o modelo √© sempre uma representa√ß√£o incompleta do mundo grande, e portanto cometer√° erros, mesmo que todos os tipos de eventos tenham sido devidamente nomeados. A consist√™ncia l√≥gica de um modelo no mundo pequeno n√£o √© garantia de que ele ser√° √≥timo no mundo grande. Mas certamente √© um conforto reconfortante.\nFigura 2.1. Ilustra√ß√£o do globo de Martin Behaim de 1492, mostrando o mundo pequeno que Colombo antecipava. A Europa est√° no lado direito. A √Åsia est√° √† esquerda. A grande ilha rotulada ‚ÄúCipangu‚Äù √© o Jap√£o.\nNeste cap√≠tulo, voc√™ come√ßar√° a construir modelos bayesianos. A maneira como modelos bayesianos aprendem a partir de evid√™ncias √© indiscutivelmente √≥tima no mundo pequeno. Quando suas suposi√ß√µes se aproximam da realidade, eles tamb√©m t√™m bom desempenho no mundo grande. Mas o desempenho no mundo grande precisa ser demonstrado, e n√£o deduzido logicamente. Transitar entre esses dois mundos permite que tanto m√©todos formais, como a infer√™ncia bayesiana, quanto m√©todos informais, como a revis√£o por pares, desempenhem um papel indispens√°vel.\nEste cap√≠tulo foca no mundo pequeno. Ele explica a teoria da probabilidade em sua forma essencial: contando as maneiras como as coisas podem acontecer. A infer√™ncia bayesiana surge automaticamente dessa perspectiva. Em seguida, o cap√≠tulo apresenta os componentes estilizados de um modelo estat√≠stico bayesiano, um modelo para aprender a partir de dados. Depois, mostra como animar o modelo para produzir estimativas.",
    "crumbs": [
      "Leitura Pr√©via",
      "Aula 2 - Mundos Pequenos e Mundos Grandes"
    ]
  },
  {
    "objectID": "content/pre-reading/pread-02-mundos-pequenos-mundos-grandes.html#o-jardim-dos-dados-bifurcantes",
    "href": "content/pre-reading/pread-02-mundos-pequenos-mundos-grandes.html#o-jardim-dos-dados-bifurcantes",
    "title": "Mundos Pequenos e Mundos Grandes",
    "section": "1 O jardim dos dados bifurcantes",
    "text": "1 O jardim dos dados bifurcantes\nNosso objetivo nesta se√ß√£o ser√° construir a infer√™ncia bayesiana a partir de origens humildes, para que n√£o haja supersti√ß√£o a respeito dela. A infer√™ncia bayesiana √© realmente apenas contagem e compara√ß√£o de possibilidades. Considere, por analogia, o conto de Jorge Luis Borges, ‚ÄúO Jardim dos Caminhos que se Bifurcam.‚Äù A hist√≥ria √© sobre um homem que encontra um livro cheio de contradi√ß√µes. Na maioria dos livros, os personagens chegam a pontos da trama e devem decidir entre caminhos alternativos. Uma protagonista pode chegar √† casa de um homem. Ela pode matar o homem, ou ent√£o tomar uma x√≠cara de ch√°. Apenas um desses caminhos √© tomado ‚Äî assassinato ou ch√°. Mas o livro dentro da hist√≥ria de Borges explora todos os caminhos, com cada decis√£o se ramificando para fora em um jardim cada vez mais amplo de caminhos bifurcantes.\nEste √© o mesmo dispositivo que a infer√™ncia bayesiana oferece. Para fazer boas infer√™ncias sobre o que realmente aconteceu, ajuda considerar tudo o que poderia ter acontecido. Uma an√°lise bayesiana √© um jardim de dados bifurcantes, no qual sequ√™ncias alternativas de eventos s√£o cultivadas. √Ä medida que aprendemos sobre o que aconteceu, algumas dessas sequ√™ncias alternativas s√£o podadas. No final, o que resta √© apenas o que √© logicamente consistente com nosso conhecimento.\nEssa abordagem fornece uma classifica√ß√£o quantitativa de hip√≥teses, uma classifica√ß√£o que √© maximamente conservadora, dadas as suposi√ß√µes e os dados que a alimentam. A abordagem n√£o pode garantir uma resposta correta em termos de mundo grande. Mas pode garantir a melhor resposta poss√≠vel, em termos de mundo pequeno, que poderia ser derivada da informa√ß√£o fornecida.\nConsidere o seguinte exemplo did√°tico.\n\nContando possibilidades\nSuponha que haja um saco contendo quatro bolinhas de gude. Essas bolinhas v√™m em duas cores: azul e branca. Sabemos que h√° quatro bolinhas no saco, mas n√£o sabemos quantas s√£o de cada cor. Sabemos que existem cinco possibilidades: (1) [‚ö™‚ö™‚ö™‚ö™], (2) [üîµ‚ö™‚ö™‚ö™], (3) [üîµüîµ‚ö™‚ö™], (4) [üîµüîµüîµ‚ö™], (5) [üîµüîµüîµüîµ]. Essas s√£o as √∫nicas possibilidades consistentes com o que sabemos sobre o conte√∫do do saco. Chame essas cinco possibilidades de conjecturas.\nNosso objetivo √© descobrir qual dessas conjecturas √© mais plaus√≠vel, dada alguma evid√™ncia sobre o conte√∫do do saco. Temos alguma evid√™ncia: uma sequ√™ncia de tr√™s bolinhas √© retirada do saco, uma de cada vez, recolocando a bolinha cada vez e agitando o saco antes de retirar outra bolinha. A sequ√™ncia que emerge √©: üîµ‚ö™üîµ, nessa ordem. Esses s√£o os dados.\nEnt√£o, vamos plantar o jardim e ver como usar os dados para inferir o que est√° no saco. Comecemos considerando apenas a conjectura [üîµ‚ö™‚ö™‚ö™], de que o saco cont√©m uma bolinha azul e tr√™s brancas. Na primeira retirada do saco, uma de quatro coisas poderia acontecer, correspondendo a uma das quatro bolinhas no saco. Assim, podemos visualizar as possibilidades se ramificando:\n\nNote que, embora as tr√™s bolinhas brancas pare√ßam iguais de uma perspectiva de dados ‚Äî afinal, registramos apenas a cor das bolinhas ‚Äî elas s√£o realmente eventos diferentes. Isso √© importante, porque significa que h√° tr√™s vezes mais maneiras de ver ‚ö™ do que de ver üîµ.\nAgora considere o jardim √† medida que obtemos outra retirada do saco. Ele expande o jardim em mais uma camada:\n\nAgora h√° 16 caminhos poss√≠veis atrav√©s do jardim, um para cada par de retiradas. Na segunda retirada do saco, cada um dos caminhos acima se bifurca novamente em quatro caminhos poss√≠veis. Por qu√™?\n\nFigura 2.2. Os 64 caminhos poss√≠veis gerados ao supor que o saco cont√©m uma bolinha azul e tr√™s brancas.\nPorque acreditamos que nossa agita√ß√£o do saco d√° a cada bolinha uma chance justa de ser retirada, independentemente de qual bolinha foi retirada anteriormente. A terceira camada √© constru√≠da da mesma maneira, e o jardim completo √© mostrado na Figura 2.2. H√° \\(4^3 = 64\\) caminhos poss√≠veis no total.\n√Ä medida que consideramos cada retirada do saco, alguns desses caminhos s√£o logicamente eliminados. A primeira retirada resultou em üîµ, lembre-se, ent√£o os tr√™s caminhos brancos na parte inferior do jardim s√£o eliminados imediatamente. Se voc√™ imaginar os dados reais tra√ßando um caminho pelo jardim, eles devem ter passado pelo √∫nico caminho azul perto da origem. A segunda retirada do saco produz ‚ö™, ent√£o tr√™s dos caminhos que se bifurcam a partir da primeira bolinha azul permanecem. Conforme os dados tra√ßam um caminho, sabemos que ele deve ter passado por um desses tr√™s caminhos brancos (depois do primeiro caminho azul), mas n√£o sabemos por qual, porque registramos apenas a cor de cada bolinha. Finalmente, a terceira retirada √© üîµ. Cada um dos tr√™s caminhos restantes na camada intermedi√°ria sustenta um caminho azul, deixando um total de tr√™s maneiras para a sequ√™ncia üîµ‚ö™üîµ aparecer, supondo que o saco cont√©m [üîµ‚ö™‚ö™‚ö™]. A Figura 2.3 mostra o jardim novamente, agora com caminhos logicamente eliminados esmaecidos. N√£o podemos ter certeza de qual desses tr√™s caminhos os dados reais tomaram. Mas, enquanto estivermos considerando apenas a possibilidade de que o saco contenha uma bolinha azul e tr√™s brancas, podemos ter certeza de que os dados tomaram um desses tr√™s caminhos. Esses s√£o os √∫nicos caminhos consistentes tanto com nosso conhecimento sobre o conte√∫do do saco (quatro bolinhas, brancas ou azuis) quanto com os dados (üîµ‚ö™üîµ).\nIsso demonstra que h√° tr√™s (de 64) maneiras para um saco contendo [üîµ‚ö™‚ö™‚ö™] produzir os dados üîµ‚ö™üîµ. N√£o temos como decidir entre essas tr√™s maneiras. O poder inferencial vem de comparar essa contagem com os n√∫meros de maneiras que cada uma das outras conjecturas sobre o conte√∫do do saco poderia produzir os mesmos dados. Por exemplo, considere a conjectura [‚ö™‚ö™‚ö™‚ö™]. H√° zero maneiras para essa conjectura produzir os dados observados, porque mesmo uma √∫nica üîµ √© logicamente incompat√≠vel com ela. A conjectura [üîµüîµüîµüîµ] √© igualmente logicamente incompat√≠vel com os dados. Portanto, podemos eliminar essas duas conjecturas, porque nenhuma fornece sequer um √∫nico caminho consistente com os dados.\nA Figura 2.4 exibe o jardim completo agora, para as tr√™s conjecturas restantes: [üîµ‚ö™‚ö™‚ö™], [üîµüîµ‚ö™‚ö™] e [üîµüîµüîµ‚ö™]. A fatia superior esquerda exibe o mesmo jardim da Figura 2.3. A superior direita mostra o jardim an√°logo para a conjectura de que o saco cont√©m tr√™s bolinhas azuis e uma branca. E a fatia inferior mostra o jardim para duas bolinhas azuis\n\nFigura 2.3. Ap√≥s eliminar caminhos inconsistentes com a sequ√™ncia observada, apenas 3 dos 64 caminhos permanecem.\ne duas brancas. Agora contamos todas as maneiras que cada conjectura poderia produzir os dados observados. Para uma azul e tr√™s brancas, h√° tr√™s maneiras, como j√° contamos. Para duas azuis e duas brancas, h√° oito caminhos que se bifurcam pelo jardim que s√£o logicamente consistentes com a sequ√™ncia observada. Para tr√™s azuis e uma branca, h√° nove caminhos que sobrevivem.\nPara resumir, consideramos cinco conjecturas diferentes sobre o conte√∫do do saco, variando de zero bolinhas azuis a quatro bolinhas azuis. Para cada uma dessas conjecturas, contamos quantas sequ√™ncias, caminhos pelo jardim de dados bifurcantes, poderiam potencialmente produzir os dados observados, üîµ‚ö™üîµ\n\n\n\nConjectura\nManeiras de produzir üîµ‚ö™üîµ\n\n\n\n\n[‚ö™‚ö™‚ö™‚ö™]\n\\(0 \\times 4 \\times 0 = 0\\)\n\n\n[üîµ‚ö™‚ö™‚ö™]\n\\(1 \\times 3 \\times 1 = 3\\)\n\n\n[üîµüîµ‚ö™‚ö™]\n\\(2 \\times 2 \\times 2 = 8\\)\n\n\n[üîµüîµüîµ‚ö™]\n\\(3 \\times 1 \\times 3 = 9\\)\n\n\n[üîµüîµüîµüîµ]\n\\(4 \\times 0 \\times 4 = 0\\)\n\n\n\nNote que o n√∫mero de maneiras de produzir os dados üîµ‚ö™üîµ, para cada conjectura, pode ser calculado contando primeiro o n√∫mero de caminhos em cada ‚Äúanel‚Äù do jardim e depois multiplicando essas contagens. Isso √© apenas um artif√≠cio computacional. Ele nos diz a mesma coisa que a Figura 2.4, mas sem precisar desenhar o jardim. O fato de que os n√∫meros s√£o multiplicados durante o c√°lculo n√£o muda o fato de que isso ainda √© apenas contagem de caminhos logicamente poss√≠veis. Esse ponto surgir√° novamente quando voc√™ encontrar a representa√ß√£o mais formal da infer√™ncia bayesiana.\nEnt√£o, para que servem essas contagens? Ao comparar essas contagens, temos parte de uma solu√ß√£o para uma maneira de classificar a plausibilidade relativa de cada composi√ß√£o conjecturada do saco. Mas √© apenas uma parte de uma solu√ß√£o, porque, para comparar essas contagens, primeiro precisamos decidir de quantas maneiras cada conjectura poderia ela mesma ser realizada. Poder√≠amos argumentar que, quando n√£o temos motivo para supor o contr√°rio, podemos simplesmente considerar cada conjectura igualmente plaus√≠vel e comparar as contagens diretamente. Mas frequentemente temos motivo para supor o contr√°rio.\n\nFigura 2.4. O jardim de dados bifurcantes, mostrando para cada poss√≠vel composi√ß√£o do saco os caminhos bifurcantes que s√£o logicamente compat√≠veis com os dados.\n\nRepensando: Justificativa. Usar contagens de caminhos pelo jardim como medidas de plausibilidade relativa pode ser justificado de diversas maneiras. A justificativa aqui √© l√≥gica: se desejamos raciocinar sobre plausibilidade e permanecer consistentes com a l√≥gica ordin√°ria ‚Äî afirma√ß√µes sobre verdadeiro e falso ‚Äî ent√£o devemos obedecer a este procedimento. H√° diversas outras justificativas que levam ao mesmo procedimento matem√°tico. Independentemente de como voc√™ escolha justific√°-lo filosoficamente, note que ele realmente funciona. Justificativas e filosofia motivam procedimentos, mas s√£o os resultados que importam. As muitas aplica√ß√µes bem-sucedidas no mundo real da infer√™ncia bayesiana podem ser toda a justificativa que voc√™ precisa. Apenas tenha cuidado para n√£o supor que, porque a infer√™ncia bayesiana √© justificada, nenhuma outra abordagem tamb√©m pode ser justificada. Golems v√™m em muitos tipos, e alguns de todos os tipos s√£o √∫teis.\n\n\n\nCombinando outras informa√ß√µes\nPodemos ter informa√ß√µes adicionais sobre a plausibilidade relativa de cada conjectura. Essa informa√ß√£o pode surgir do conhecimento de como o conte√∫do do saco foi gerado. Pode tamb√©m surgir de dados anteriores. Seja qual for a fonte, seria √∫til ter uma maneira de combinar diferentes fontes de informa√ß√£o para atualizar as plausibilidades. Felizmente, h√° uma solu√ß√£o natural: basta multiplicar as contagens.\nPara entender essa solu√ß√£o, suponha que estejamos dispostos a dizer que cada conjectura √© igualmente plaus√≠vel no in√≠cio. Ent√£o, simplesmente comparamos as contagens de maneiras em que cada conjectura √© compat√≠vel com os dados observados. Essa compara√ß√£o sugere que [üîµüîµüîµ‚ö™] √© ligeiramente mais plaus√≠vel que [üîµüîµ‚ö™‚ö™], e ambos s√£o cerca de tr√™s vezes mais plaus√≠veis que [üîµ‚ö™‚ö™‚ö™]. Como essas s√£o nossas contagens iniciais, e vamos atualiz√°-las em seguida, vamos rotul√°-las a priori.\nAgora suponha que retiremos outra bolinha do saco para obter outra observa√ß√£o: üîµ. Agora voc√™ tem duas escolhas. Voc√™ poderia come√ßar tudo de novo, fazendo um jardim com quatro camadas para tra√ßar os caminhos compat√≠veis com a sequ√™ncia de dados üîµ ‚ö™ üîµ üîµ. Ou poderia pegar as contagens anteriores ‚Äî as contagens a priori ‚Äî sobre as conjecturas (0, 3, 8, 9, 0) e simplesmente atualiz√°-las √† luz da nova observa√ß√£o. Acontece que esses dois m√©todos s√£o matematicamente id√™nticos, desde que a nova observa√ß√£o seja logicamente independente das observa√ß√µes anteriores.\nVeja como fazer isso. Primeiro, contamos o n√∫mero de maneiras que cada conjectura poderia produzir a nova observa√ß√£o, üîµ. Depois multiplicamos cada uma dessas novas contagens pelos n√∫meros a priori de maneiras para cada conjectura. Em forma de tabela:\n\n\n\n\n\n\n\n\n\nConjectura\nManeiras de produzir üîµ\nContagens a priori\nNova contagem\n\n\n\n\n[‚ö™‚ö™‚ö™‚ö™]\n0\n0\n\\(0 \\times 0 = 0\\)\n\n\n[üîµ‚ö™‚ö™‚ö™]\n1\n3\n\\(3 \\times 1 = 3\\)\n\n\n[üîµüîµ‚ö™‚ö™]\n2\n8\n\\(8 \\times 2 = 16\\)\n\n\n[üîµüîµüîµ‚ö™]\n3\n9\n\\(9 \\times 3 = 27\\)\n\n\n[üîµüîµüîµüîµ]\n4\n0\n\\(0 \\times 4 = 0\\)\n\n\n\nAs novas contagens na coluna da direita acima resumem toda a evid√™ncia para cada conjectura. √Ä medida que novos dados chegam, e desde que esses dados sejam independentes das observa√ß√µes anteriores, o n√∫mero de maneiras logicamente poss√≠veis para uma conjectura produzir todos os dados at√© aquele ponto pode ser calculado simplesmente multiplicando a nova contagem pela contagem antiga.\nEssa abordagem de atualiza√ß√£o nada mais √© do que afirmar que (1) quando temos informa√ß√£o anterior sugerindo que h√° \\(W_{\\rm prior}\\) maneiras para uma conjectura produzir uma observa√ß√£o anterior \\(D_{\\rm prior}\\) e (2) adquirimos novas observa√ß√µes \\(D_{\\rm new}\\) que a mesma conjectura pode produzir de \\(W_{\\rm new}\\) maneiras, ent√£o (3) o n√∫mero de maneiras que a conjectura pode explicar tanto \\(D_{\\rm prior}\\) quanto \\(D_{\\rm new}\\) √© simplesmente o produto \\(W_{\\rm prior} \\times W_{\\rm new}\\). Por exemplo, na tabela acima, a conjectura [üîµüîµ‚ö™‚ö™] tem \\(W_{\\rm prior} = 8\\) maneiras de produzir \\(D_{\\rm prior} = üîµ‚ö™üîµ\\). Ela tamb√©m tem \\(W_{\\rm new} = 2\\) maneiras de produzir a nova observa√ß√£o \\(D_{\\rm new} = üîµ\\). Portanto, h√° \\(8 \\times 2 = 16\\) maneiras para a conjectura produzir tanto \\(D_{\\rm prior}\\) quanto \\(D_{\\rm new}\\). Por que multiplicar? A multiplica√ß√£o √© apenas um atalho para enumerar e contar todos os caminhos pelo jardim que poderiam produzir todas as observa√ß√µes.\nNeste exemplo, os dados a priori e os novos dados s√£o do mesmo tipo: bolinhas retiradas do saco. Mas, em geral, os dados a priori e os novos dados podem ser de tipos diferentes. Suponha, por exemplo, que algu√©m da f√°brica de bolinhas lhe diga que bolinhas azuis s√£o raras. Ent√£o, para cada saco contendo [üîµüîµüîµ‚ö™], eles fizeram dois sacos contendo [üîµüîµ‚ö™‚ö™] e tr√™s sacos contendo [üîµ‚ö™‚ö™‚ö™]. Eles tamb√©m garantiram que cada saco contivesse pelo menos uma bolinha azul e uma branca. Podemos atualizar nossas contagens novamente:\n\n\n\n\n\n\n\n\n\nConjectura\nContagem a priori\nContagem da f√°brica\nNova contagem\n\n\n\n\n[‚ö™‚ö™‚ö™‚ö™]\n0\n0\n\\(0 \\times 0 = 0\\)\n\n\n[üîµ‚ö™‚ö™‚ö™]\n3\n3\n\\(3 \\times 3 = 9\\)\n\n\n[üîµüîµ‚ö™‚ö™]\n16\n2\n\\(16 \\times 2 = 32\\)\n\n\n[üîµüîµüîµ‚ö™]\n27\n1\n\\(27 \\times 1 = 27\\)\n\n\n[üîµüîµüîµüîµ]\n0\n0\n\\(0 \\times 0 = 0\\)\n\n\n\nAgora a conjectura [üîµüîµ‚ö™‚ö™] √© a mais plaus√≠vel, mas apenas ligeiramente melhor que [üîµüîµüîµ‚ö™].\n\nRepensando: Ignor√¢ncia original. Qual suposi√ß√£o devemos usar quando n√£o h√° informa√ß√£o anterior sobre as conjecturas? A solu√ß√£o mais comum √© atribuir um n√∫mero igual de maneiras em que cada conjectura poderia estar correta, antes de ver quaisquer dados. Isso √© √†s vezes conhecido como o PRINC√çPIO DA INDIFEREN√áA: quando n√£o h√° raz√£o para dizer que uma conjectura √© mais plaus√≠vel que outra, pese todas as conjecturas igualmente.\n\n\n\nDe contagens a probabilidades\n√â √∫til pensar nessa estrat√©gia como aderindo a um princ√≠pio de ignor√¢ncia honesta: quando n√£o sabemos o que causou os dados, causas potenciais que podem produzir os dados de mais maneiras s√£o mais plaus√≠veis. Isso nos leva a contar caminhos pelo jardim de dados bifurcantes.\n√â dif√≠cil usar essas contagens, por√©m, ent√£o quase sempre as padronizamos de uma maneira que as transforma em probabilidades. Por que √© dif√≠cil trabalhar com as contagens? Primeiro, como o valor relativo √© tudo que importa, o tamanho das contagens 3, 8 e 9 n√£o cont√©m informa√ß√£o de valor. Elas poderiam ser igualmente 30, 80 e 90. O significado seria o mesmo. S√£o apenas os valores relativos que importam. Segundo, conforme a quantidade de dados cresce, as contagens crescer√£o muito rapidamente, tornando-se muito grandes e dif√≠ceis de manipular.\nFelizmente, h√° uma maneira matem√°tica de comprimir tudo isso. Especificamente, definimos a plausibilidade atualizada de cada poss√≠vel composi√ß√£o do saco, ap√≥s ver os dados, como:\n\\[ \\texttt{plausibilidade de [üîµ‚ö™‚ö™‚ö™] ap√≥s ver üîµ‚ö™üîµ }\\] \\[\\propto\\] \\[ \\texttt{maneiras que [üîµ‚ö™‚ö™‚ö™] pode produzir üîµ‚ö™üîµ }\\] \\[\\times\\] \\[ \\texttt{plausibilidade a priori de [üîµ‚ö™‚ö™‚ö™] }\\]\nAquele pequeno \\(\\propto\\) significa proporcional a. Queremos comparar a plausibilidade de cada poss√≠vel composi√ß√£o do saco. Ent√£o ser√° √∫til definir p como a propor√ß√£o de bolinhas que s√£o azuis. Para [üîµ‚ö™‚ö™‚ö™], p = 1/4 = 0,25. Tamb√©m defina \\(D_{\\text{new}} = üîµ‚ö™üîµ\\). E agora podemos escrever:\n\nplausibilidade de p ap√≥s \\(D_{\\text{new}} \\propto \\text{maneiras que } p\\) pode produzir \\(D_{\\text{new}} \\times \\text{plausibilidade a priori de } p\\)\n\nO acima apenas significa que, para qualquer valor que p possa assumir, julgamos a plausibilidade desse valor p como proporcional ao n√∫mero de maneiras que ele pode passar pelo jardim de dados bifurcantes.\nFinalmente, constru√≠mos probabilidades padronizando a plausibilidade de modo que a soma das plausibilidades para todas as conjecturas poss√≠veis seja um. Tudo o que voc√™ precisa fazer para padronizar √© somar todos os produtos, um para cada valor que p pode assumir, e depois dividir cada produto pela soma dos produtos:\n\\[\\texttt{plausibilidade de p ap√≥s} D_{\\text{new}} = \\frac{\\text{maneiras que } p \\text{ pode produzir } D_{\\text{new}} \\times \\text{plausibilidade a priori de } p}{\\text{soma dos produtos}}\\]\nUm exemplo trabalhado √© necess√°rio para que isso realmente fa√ßa sentido. Ent√£o considere novamente a tabela de antes, agora atualizada usando nossas defini√ß√µes de p e ‚Äúplausibilidade‚Äù:\n\n\n\n\n\n\n\n\n\nComposi√ß√£o poss√≠vel\np\nManeiras de produzir dados\nPlausibilidade\n\n\n\n\n[‚ö™‚ö™‚ö™‚ö™]\n0\n0\n0\n\n\n[üîµ‚ö™‚ö™‚ö™]\n0,25\n3\n0,15\n\n\n[üîµüîµ‚ö™‚ö™]\n0,5\n8\n0,40\n\n\n[üîµüîµüîµ‚ö™]\n0,75\n9\n0,45\n\n\n[üîµüîµüîµüîµ]\n1\n0\n0\n\n\n\nVoc√™ pode calcular rapidamente essas plausibilidades em R:\n\nways &lt;- c( 0 , 3 , 8 , 9 , 0 )\nways/sum(ways)\n\n[1] 0.00 0.15 0.40 0.45 0.00\nOs valores em ways s√£o os produtos mencionados antes. E sum(ways) √© o denominador ‚Äúsoma dos produtos‚Äù na express√£o perto do topo da p√°gina.\nEssas plausibilidades tamb√©m s√£o probabilidades ‚Äî s√£o n√∫meros reais n√£o negativos (zero ou positivos) que somam um. E todas as coisas matem√°ticas que voc√™ pode fazer com probabilidades tamb√©m pode fazer com esses valores. Especificamente, cada pe√ßa do c√°lculo tem um parceiro direto na teoria da probabilidade aplicada. Esses parceiros t√™m nomes estereotipados, ent√£o vale a pena aprend√™-los, pois voc√™ os ver√° repetidamente.\n\nUm valor conjecturado da propor√ß√£o de bolinhas azuis, p, √© geralmente chamado de valor de PAR√ÇMETRO. √â apenas uma maneira de indexar explica√ß√µes poss√≠veis dos dados.\nO n√∫mero relativo de maneiras que um valor p pode produzir os dados √© geralmente chamado de VEROSSIMILHAN√áA. √â derivada enumerando todas as sequ√™ncias de dados poss√≠veis que poderiam ter acontecido e depois eliminando aquelas sequ√™ncias inconsistentes com os dados.\nA plausibilidade a priori de qualquer p espec√≠fico √© geralmente chamada de PROBABILIDADE A PRIORI.\nA nova plausibilidade atualizada de qualquer p espec√≠fico √© geralmente chamada de PROBABILIDADE A POSTERIORI.\n\n\nRepensando: Aleatoriza√ß√£o. Quando voc√™ embaralha um baralho de cartas ou atribui sujeitos a tratamentos jogando uma moeda, √© comum dizer que o baralho resultante e as atribui√ß√µes de tratamento s√£o aleatorizados. O que significa aleatorizar algo? Significa apenas que processamos a coisa de modo que sabemos quase nada sobre seu arranjo. Embaralhar um baralho de cartas muda nosso estado de conhecimento, de modo que n√£o temos mais informa√ß√£o espec√≠fica sobre a ordena√ß√£o das cartas. Entretanto, o b√¥nus que surge disso √© que, se realmente embaralhamos o suficiente para apagar qualquer conhecimento pr√©vio da ordena√ß√£o, ent√£o a ordem em que as cartas terminam √© muito provavelmente uma das muitas ordena√ß√µes com alta entropia informacional.",
    "crumbs": [
      "Leitura Pr√©via",
      "Aula 2 - Mundos Pequenos e Mundos Grandes"
    ]
  },
  {
    "objectID": "content/pre-reading/pread-02-mundos-pequenos-mundos-grandes.html#construindo-um-modelo",
    "href": "content/pre-reading/pread-02-mundos-pequenos-mundos-grandes.html#construindo-um-modelo",
    "title": "Mundos Pequenos e Mundos Grandes",
    "section": "2 Construindo um modelo",
    "text": "2 Construindo um modelo\nAo trabalhar com probabilidades em vez de contagens brutas, a infer√™ncia bayesiana se torna muito mais f√°cil, mas parece muito mais dif√≠cil. Ent√£o, nesta se√ß√£o, damos sequ√™ncia ao jardim de dados bifurcantes apresentando a forma convencional de um modelo estat√≠stico bayesiano. O exemplo did√°tico que usaremos aqui tem a anatomia de uma an√°lise estat√≠stica t√≠pica, ent√£o √© o estilo ao qual voc√™ se acostumar√°. Mas cada pe√ßa dele pode ser mapeada no jardim de dados bifurcantes. A l√≥gica √© a mesma.\nSuponha que voc√™ tenha um globo terrestre representando nosso planeta, a Terra. Essa vers√£o do mundo √© pequena o suficiente para caber em suas m√£os. Voc√™ tem curiosidade sobre quanta da superf√≠cie √© coberta por √°gua. Voc√™ adota a seguinte estrat√©gia: jogar√° o globo para cima. Quando peg√°-lo, registrar√° se a superf√≠cie sob seu dedo indicador direito √© √°gua ou terra. Ent√£o jogar√° o globo para cima novamente e repetir√° o procedimento. Essa estrat√©gia gera uma sequ√™ncia de amostras da superf√≠cie do globo. As primeiras nove amostras podem parecer com:\n\\[\\text{W L W W W L W L W}\\]\nonde \\(\\text{W}\\) indica √°gua (water) e \\(\\text{L}\\) indica terra (land). Ent√£o, neste exemplo, voc√™ observa seis observa√ß√µes \\(\\text{W}\\) (√°gua) e tr√™s observa√ß√µes \\(\\text{L}\\) (terra). Chame essa sequ√™ncia de observa√ß√µes de dados.\nPara colocar a l√≥gica em movimento, precisamos fazer suposi√ß√µes, e essas suposi√ß√µes constituem o modelo. Projetar um modelo bayesiano simples se beneficia de um ciclo de design com tr√™s etapas.\n\n\nHist√≥ria dos dados: motive o modelo narrando como os dados podem ter surgido.\n\n\nAtualiza√ß√£o: eduque seu modelo alimentando-o com os dados.\n\n\nAvalia√ß√£o: todos os modelos estat√≠sticos requerem supervis√£o, levando possivelmente √† revis√£o do modelo.\n\n\nAs pr√≥ximas se√ß√µes percorrem essas etapas, no contexto da evid√™ncia do lan√ßamento do globo.\n\nUma hist√≥ria dos dados\nA an√°lise bayesiana de dados geralmente significa produzir uma hist√≥ria para como os dados vieram a existir. Essa hist√≥ria pode ser descritiva, especificando associa√ß√µes que podem ser usadas para prever resultados, dadas observa√ß√µes. Ou pode ser causal, uma teoria de como alguns eventos produzem outros eventos. Tipicamente, qualquer hist√≥ria que voc√™ pretenda ser causal tamb√©m pode ser descritiva. Mas muitas hist√≥rias descritivas s√£o dif√≠ceis de interpretar causalmente. Contudo, todas as hist√≥rias de dados s√£o completas, no sentido de que s√£o suficientes para especificar um algoritmo para simular novos dados.\nVoc√™ pode motivar sua hist√≥ria dos dados tentando explicar como cada dado nasce. Isso geralmente significa descrever aspectos da realidade subjacente, bem como o processo de amostragem. A hist√≥ria dos dados neste caso √© simplesmente uma reformula√ß√£o do processo de amostragem:\n\n\nA verdadeira propor√ß√£o de √°gua cobrindo o globo √© \\(p\\).\n\n\nUm √∫nico lan√ßamento do globo tem probabilidade \\(p\\) de produzir uma observa√ß√£o de √°gua (\\(\\text{W}\\)). Tem probabilidade \\(1-p\\) de produzir uma observa√ß√£o de terra (\\(\\text{L}\\)).\n\n\nCada lan√ßamento do globo √© independente dos outros.\n\n\n\n\nAtualiza√ß√£o bayesiana\nNosso problema √© usar a evid√™ncia ‚Äî a sequ√™ncia de lan√ßamentos do globo ‚Äî para decidir entre diferentes propor√ß√µes poss√≠veis de √°gua no globo. Essas propor√ß√µes s√£o como as bolinhas conjecturadas dentro do saco, de antes neste cap√≠tulo. Cada propor√ß√£o poss√≠vel pode ser mais ou menos plaus√≠vel, dada a evid√™ncia. Um modelo bayesiano come√ßa com um conjunto de plausibilidades atribu√≠das a cada uma dessas possibilidades. Essas s√£o as plausibilidades a priori. Ent√£o ele as atualiza √† luz dos dados, para produzir as plausibilidades a posteriori. Esse processo de atualiza√ß√£o √© um tipo de aprendizado, chamado atualiza√ß√£o bayesiana.\nApenas para efeito do exemplo, vamos programar nossa m√°quina bayesiana para atribuir inicialmente a mesma plausibilidade a cada propor√ß√£o de √°gua, cada valor de p.¬†Depois faremos melhor que isso. Agora olhe o gr√°fico superior esquerdo na Figura 2.5. A linha horizontal tracejada representa essa plausibilidade inicial de cada valor poss√≠vel de p.¬†Ap√≥s ver o primeiro lan√ßamento, que √© um ‚ÄúW‚Äù, o modelo atualiza as plausibilidades para a linha s√≥lida. A plausibilidade de p = 0 caiu agora para exatamente zero ‚Äî o equivalente a ‚Äúimposs√≠vel‚Äù. Por qu√™? Porque observamos pelo menos uma parcela de √°gua no globo, ent√£o agora sabemos que h√° alguma √°gua. O modelo executa essa l√≥gica automaticamente. Voc√™ n√£o precisa instru√≠-lo a considerar essa consequ√™ncia. A teoria da probabilidade cuida disso para voc√™, porque √© essencialmente contagem de caminhos pelo jardim de dados bifurcantes, como na se√ß√£o anterior.\nDa mesma forma, a plausibilidade de p &gt; 0,5 aumentou. Isso ocorre porque ainda n√£o h√° evid√™ncia de que haja terra no globo, ent√£o as plausibilidades iniciais s√£o modificadas para serem consistentes com isso. Note, entretanto, que s√£o as plausibilidades relativas que importam, e ainda n√£o h√°\n\nFigura 2.5. Como um modelo bayesiano aprende. Cada lan√ßamento do globo produz uma observa√ß√£o de √°gua (W) ou terra (L). A estimativa do modelo da propor√ß√£o de √°gua no globo √© uma plausibilidade para cada valor poss√≠vel. As linhas e curvas nesta figura s√£o essas cole√ß√µes de plausibilidades. Em cada gr√°fico, plausibilidades anteriores (curva tracejada) s√£o atualizadas √† luz da √∫ltima observa√ß√£o para produzir um novo conjunto de plausibilidades (curva s√≥lida).\nmuita evid√™ncia. Portanto, as diferen√ßas em plausibilidade ainda n√£o s√£o muito grandes. Dessa forma, a quantidade de evid√™ncia vista at√© agora √© incorporada nas plausibilidades de cada valor de p.\nNos gr√°ficos restantes da Figura 2.5, as amostras adicionais do globo s√£o introduzidas ao modelo, uma de cada vez. Cada curva tracejada √© simplesmente a curva s√≥lida do gr√°fico anterior, movendo-se da esquerda para a direita e de cima para baixo. Toda vez que um ‚ÄúW‚Äù √© visto, o pico da curva de plausibilidade se move para a direita, em dire√ß√£o a valores maiores de p.¬†Toda vez que um ‚ÄúL‚Äù √© visto, ela se move na outra dire√ß√£o. A altura m√°xima da curva aumenta com cada amostra, significando que menos valores de p acumulam mais plausibilidade conforme a quantidade de evid√™ncia aumenta. Conforme cada nova observa√ß√£o √© adicionada, a curva √© atualizada de maneira consistente com todas as observa√ß√µes anteriores.\nNote que cada conjunto atualizado de plausibilidades se torna as plausibilidades iniciais para a pr√≥xima observa√ß√£o. Toda conclus√£o √© o ponto de partida para infer√™ncia futura. Contudo, esse processo de atualiza√ß√£o funciona tanto para tr√°s quanto para frente. Dado o conjunto final de plausibilidades no gr√°fico inferior direito da Figura 2.5, e sabendo a observa√ß√£o final (W), √© poss√≠vel matematicamente dividir a observa√ß√£o, para inferir a curva de plausibilidade anterior. Ent√£o os dados poderiam ser apresentados ao seu modelo em qualquer ordem, ou todos de uma vez. Na maioria dos casos, voc√™ apresentar√° os dados todos de uma vez, por conveni√™ncia. Mas √© importante perceber que isso meramente representa a abrevia√ß√£o de um processo iterativo de aprendizado.\n\nRepensando: Tamanho amostral e infer√™ncia confi√°vel. √â comum ouvir que h√° um n√∫mero m√≠nimo de observa√ß√µes para uma estimativa estat√≠stica √∫til. Por exemplo, h√° uma supersti√ß√£o difundida de que 30 observa√ß√µes s√£o necess√°rias antes de se poder usar uma distribui√ß√£o gaussiana. Por qu√™? Na infer√™ncia estat√≠stica n√£o bayesiana, os procedimentos s√£o frequentemente justificados pelo comportamento do m√©todo com tamanhos amostrais muito grandes, o chamado comportamento assint√≥tico. Como resultado, o desempenho com tamanhos amostrais pequenos √© question√°vel.\nEm contraste, estimativas bayesianas s√£o v√°lidas para qualquer tamanho amostral. Isso n√£o significa que mais dados n√£o ajudem ‚Äî certamente ajudam. Em vez disso, as estimativas t√™m uma interpreta√ß√£o clara e v√°lida, independentemente do tamanho amostral. Mas o pre√ßo desse poder √© a depend√™ncia das plausibilidades iniciais, a distribui√ß√£o a priori. Se a distribui√ß√£o a priori for ruim, a infer√™ncia resultante ser√° enganosa. N√£o h√° almo√ßo gr√°tis quando se trata de aprender sobre o mundo. Um golem bayesiano deve escolher uma plausibilidade inicial, e um golem n√£o bayesiano deve escolher um estimador. Ambos os golems pagam pelo almo√ßo com suas suposi√ß√µes.\n\n\n\nAvalia√ß√£o\nO modelo bayesiano aprende de uma maneira que √© comprovadamente √≥tima, desde que o mundo real, o mundo grande, seja descrito com precis√£o pelo modelo. Ou seja, sua m√°quina bayesiana garante infer√™ncia perfeita, dentro do mundo pequeno. Nenhuma outra maneira de usar a informa√ß√£o dispon√≠vel, e come√ßando com o mesmo estado de informa√ß√£o, poderia fazer melhor.\nN√£o fique muito empolgado com essa virtude l√≥gica, contudo. Os c√°lculos podem falhar, ent√£o os resultados sempre precisam ser verificados. E se houver diferen√ßas importantes entre o modelo e a realidade, ent√£o n√£o h√° garantia l√≥gica de desempenho no mundo grande. E mesmo que os dois mundos coincidissem, qualquer amostra particular de dados poderia ainda ser enganosa. Ent√£o vale a pena manter em mente pelo menos dois princ√≠pios cautelosos.\nPrimeiro, a certeza do modelo n√£o √© garantia de que o modelo √© bom. Conforme a quantidade de dados aumenta, o modelo de lan√ßamento do globo ficar√° cada vez mais seguro da propor√ß√£o de √°gua. Isso significa que as curvas na Figura 2.5 se tornar√£o cada vez mais estreitas e altas, restringindo valores plaus√≠veis dentro de uma faixa muito estreita. Mas modelos de todos os tipos ‚Äî bayesianos ou n√£o ‚Äî podem ser muito confiantes sobre uma infer√™ncia, mesmo quando o modelo √© seriamente enganoso. Isso ocorre porque as infer√™ncias s√£o condicionais ao modelo.\nSegundo, √© importante supervisionar e criticar o trabalho do seu modelo. Considere novamente o fato de que a atualiza√ß√£o na se√ß√£o anterior funciona em qualquer ordem de chegada dos dados. Poder√≠amos embaralhar a ordem das observa√ß√µes, contanto que seis W‚Äôs e tr√™s L‚Äôs permane√ßam, e ainda terminar com a mesma curva de plausibilidade final. Isso s√≥ √© verdade, contudo, porque o modelo assume que a ordem √© irrelevante para a infer√™ncia. Quando algo √© irrelevante para a m√°quina, n√£o afetar√° a infer√™ncia diretamente. Mas pode afet√°-la indiretamente, porque os dados depender√£o da ordem. Ent√£o √© importante verificar as infer√™ncias do modelo √† luz de aspectos dos dados que ele n√£o conhece. Tais verifica√ß√µes s√£o um empreendimento inerentemente criativo, deixado para o analista e a comunidade cient√≠fica. Golems s√£o muito ruins nisso.\nO objetivo n√£o √© testar o valor de verdade das suposi√ß√µes do modelo. Sabemos que as suposi√ß√µes do modelo nunca s√£o exatamente corretas, no sentido de corresponder ao verdadeiro processo gerador de dados. Portanto, n√£o h√° motivo para verificar se o modelo √© verdadeiro. A falha em concluir que um modelo √© falso deve ser uma falha de nossa imagina√ß√£o, n√£o um sucesso do modelo. Al√©m disso, modelos n√£o precisam ser exatamente verdadeiros para produzir infer√™ncias altamente precisas e √∫teis. Em vez disso, o objetivo √© verificar a adequa√ß√£o do modelo para algum prop√≥sito.\n\nRepensando: Estat√≠stica deflacion√°ria. Pode ser que a infer√™ncia bayesiana seja o melhor m√©todo de infer√™ncia de prop√≥sito geral conhecido. Contudo, a infer√™ncia bayesiana √© muito menos poderosa do que gostar√≠amos que fosse. N√£o h√° abordagem √† infer√™ncia que forne√ßa garantias universais. Nenhum ramo da matem√°tica aplicada tem acesso irrestrito √† realidade, porque a matem√°tica n√£o √© descoberta, como o pr√≥ton. Em vez disso, ela √© inventada, como a p√°.",
    "crumbs": [
      "Leitura Pr√©via",
      "Aula 2 - Mundos Pequenos e Mundos Grandes"
    ]
  },
  {
    "objectID": "content/pre-reading/pread-02-mundos-pequenos-mundos-grandes.html#componentes-do-modelo",
    "href": "content/pre-reading/pread-02-mundos-pequenos-mundos-grandes.html#componentes-do-modelo",
    "title": "Mundos Pequenos e Mundos Grandes",
    "section": "3 Componentes do modelo",
    "text": "3 Componentes do modelo\nAgora que voc√™ viu como o modelo bayesiano se comporta, √© hora de abrir a m√°quina e aprender como ela funciona. Considere tr√™s tipos diferentes de coisas que contamos nas se√ß√µes anteriores.\n\n\nO n√∫mero de maneiras que cada conjectura poderia produzir uma observa√ß√£o\n\n\nO n√∫mero acumulado de maneiras que cada conjectura poderia produzir os dados inteiros\n\n\nA plausibilidade inicial de cada causa conjecturada dos dados\n\n\nCada uma dessas coisas tem um an√°logo direto na teoria da probabilidade convencional. E assim, a maneira usual de construir um modelo estat√≠stico envolve escolher distribui√ß√µes e dispositivos para cada uma que representem os n√∫meros relativos de maneiras que as coisas podem acontecer.\n\nVari√°veis\nVari√°veis s√£o simplesmente s√≠mbolos que podem assumir diferentes valores. Em um contexto cient√≠fico, vari√°veis incluem coisas que desejamos inferir, como propor√ß√µes e taxas, bem como coisas que podemos observar, os dados. No modelo de lan√ßamento do globo, h√° tr√™s vari√°veis.\nA primeira vari√°vel √© nosso alvo de infer√™ncia, p, a propor√ß√£o de √°gua no globo. Essa vari√°vel n√£o pode ser observada. Vari√°veis n√£o observadas s√£o geralmente chamadas de par√¢metros. Mas, embora p em si n√£o seja observado, podemos inferi-lo a partir das outras vari√°veis.\nAs outras vari√°veis s√£o as vari√°veis observadas, as contagens de √°gua e terra. Chame a contagem de √°gua de W e a contagem de terra de L. A soma dessas duas vari√°veis √© o n√∫mero de lan√ßamentos do globo: N = W + L.\n\n\nDefini√ß√µes\nUma vez que temos as vari√°veis listadas, precisamos definir cada uma delas. Ao definir cada uma, constru√≠mos um modelo que relaciona as vari√°veis umas √†s outras. Lembre-se, o objetivo √© contar todas as maneiras que os dados poderiam surgir, dadas as suposi√ß√µes.\n\nVari√°veis observadas\nPara a contagem de √°gua W e terra L, definimos qu√£o plaus√≠vel qualquer combina√ß√£o de W e L seria, para um valor espec√≠fico de p.¬†Cada valor espec√≠fico de p corresponde a uma plausibilidade espec√≠fica dos dados, como na Figura 2.5.\nPara que n√£o tenhamos que literalmente contar, podemos usar uma fun√ß√£o matem√°tica que nos diz a plausibilidade correta. Na estat√≠stica convencional, uma fun√ß√£o de distribui√ß√£o atribu√≠da a uma vari√°vel observada √© geralmente chamada de verossimilhan√ßa.\nNo caso do modelo de lan√ßamento do globo, a fun√ß√£o que precisamos pode ser derivada diretamente da hist√≥ria dos dados. Uma vez que adicionamos nossas suposi√ß√µes de que (1) cada lan√ßamento √© independente dos outros e (2) a probabilidade de W √© a mesma em cada lan√ßamento, a teoria da probabilidade fornece uma resposta √∫nica, conhecida como distribui√ß√£o binomial. E assim a probabilidade de observar W √°guas e L terras, com probabilidade p de √°gua em cada lan√ßamento, √©:\n\\[\\Pr(W, L|p) = \\frac{(W+L)!}{W!L!} p^{W} (1-p)^{L}\\]\nLeia o acima como:\n\nAs contagens de ‚Äú√°gua‚Äù W e ‚Äúterra‚Äù L s√£o distribu√≠das binomialmente, com probabilidade p de ‚Äú√°gua‚Äù em cada lan√ßamento.\n\nE a f√≥rmula da distribui√ß√£o binomial est√° embutida no R, ent√£o voc√™ pode facilmente calcular a verossimilhan√ßa dos dados ‚Äî seis W‚Äôs em nove lan√ßamentos ‚Äî sob qualquer valor de p com:\n\ndbinom( 6 , size=9 , prob=0.5 )\n\n[1] 0.1640625\nEsse n√∫mero √© o n√∫mero relativo de maneiras de obter seis √°guas, mantendo p em 0,5 e \\(N = W + L\\) em nove. Ent√£o ele faz o trabalho de contar o n√∫mero relativo de caminhos pelo jardim. Mude o 0,5 para qualquer outro valor, para ver como o valor muda.\n\nPensando Mais um Pouco: Nomes e distribui√ß√µes de probabilidade. O ‚Äúd‚Äù em dbinom significa densidade. Fun√ß√µes nomeadas assim quase sempre t√™m parceiras correspondentes que come√ßam com ‚Äúr‚Äù para amostras aleat√≥rias e que come√ßam com ‚Äúp‚Äù para probabilidades acumuladas. Veja, por exemplo, a ajuda ?dbinom.\n\n\n\nVari√°veis n√£o observadas\nAs distribui√ß√µes que atribu√≠mos √†s vari√°veis observadas tipicamente t√™m suas pr√≥prias vari√°veis. Na binomial acima, h√° p, a probabilidade de amostrar √°gua. Como p n√£o √© observado, geralmente o chamamos de PAR√ÇMETRO. Embora n√£o possamos observar p, ainda precisamos defini-lo.\nNa modelagem estat√≠stica, muitas das perguntas mais comuns que fazemos sobre dados s√£o respondidas diretamente por par√¢metros:\n\nQual √© a diferen√ßa m√©dia entre grupos de tratamento?\nQu√£o forte √© a associa√ß√£o entre um tratamento e um resultado?\nO efeito do tratamento depende de uma covari√°vel?\nQuanta varia√ß√£o h√° entre grupos?\n\nPara cada par√¢metro que voc√™ pretende que sua m√°quina bayesiana considere, voc√™ deve fornecer uma distribui√ß√£o de plausibilidade a priori, sua DISTRIBUI√á√ÉO A PRIORI. Uma m√°quina bayesiana deve ter uma atribui√ß√£o inicial de plausibilidade para cada valor poss√≠vel do par√¢metro, e essas atribui√ß√µes iniciais fazem trabalho √∫til.\nEnt√£o, de onde v√™m as distribui√ß√µes a priori? Elas s√£o tanto suposi√ß√µes de engenharia, escolhidas para ajudar a m√°quina a aprender, quanto suposi√ß√µes cient√≠ficas, escolhidas para refletir o que sabemos sobre um fen√¥meno. A distribui√ß√£o a priori plana na Figura 2.5 √© muito comum, mas raramente √© a melhor distribui√ß√£o a priori.\n\nPensando Mais um Pouco: A distribui√ß√£o a priori como distribui√ß√£o de probabilidade. Voc√™ poderia escrever a distribui√ß√£o a priori no exemplo aqui como:\n\\[\\Pr(p) = \\frac{1}{1-0} = 1.\\]\nA distribui√ß√£o a priori √© uma distribui√ß√£o de probabilidade para o par√¢metro. Em geral, para uma distribui√ß√£o a priori uniforme de a at√© b, a probabilidade de qualquer ponto no intervalo √© 1/(b-a). Se voc√™ est√° incomodado pelo fato de que a probabilidade de cada valor de p √© 1, lembre-se de que toda distribui√ß√£o de probabilidade deve somar (integrar) para 1. A express√£o 1/(b-a) garante que a √°rea sob a linha plana de a at√© b √© igual a 1.\n\n\nRepensando: Dado ou par√¢metro? √â t√≠pico conceber dados e par√¢metros como tipos de entidades completamente diferentes. Dados s√£o mensurados e conhecidos; par√¢metros s√£o desconhecidos e devem ser estimados a partir dos dados. Utilmente, no framework bayesiano, a distin√ß√£o entre um dado e um par√¢metro n√£o √© t√£o fundamental. √Äs vezes observamos uma vari√°vel, mas √†s vezes n√£o. Nesse caso, a mesma fun√ß√£o de distribui√ß√£o se aplica, mesmo que n√£o tenhamos observado a vari√°vel. Como resultado, a mesma suposi√ß√£o pode parecer uma ‚Äúverossimilhan√ßa‚Äù ou uma ‚Äúdistribui√ß√£o a priori‚Äù, dependendo do contexto, sem qualquer mudan√ßa no modelo.\n\n\n\n\nUm modelo nasce\nCom todo o trabalho acima, podemos agora resumir nosso modelo. As vari√°veis observadas W e L recebem contagens relativas atrav√©s da distribui√ß√£o binomial. Ent√£o podemos escrever, como atalho:\n\\[W \\sim \\text{Binomial}(N, p)\\]\nonde N = W + L. O acima √© apenas uma conven√ß√£o para comunicar a suposi√ß√£o de que as contagens relativas de maneiras de realizar W em N tentativas com probabilidade p em cada tentativa v√™m da distribui√ß√£o binomial. E o par√¢metro n√£o observado p similarmente recebe:\n\\[p \\sim \\text{Uniform}(0,1)\\]\nIsso significa que p tem uma distribui√ß√£o a priori uniforme ‚Äî plana ‚Äî sobre toda a sua faixa poss√≠vel, de zero a um. Como mencionei anteriormente, isso obviamente n√£o √© o melhor que poder√≠amos fazer, pois sabemos que a Terra tem mais √°gua que terra, mesmo que ainda n√£o saibamos a propor√ß√£o exata.",
    "crumbs": [
      "Leitura Pr√©via",
      "Aula 2 - Mundos Pequenos e Mundos Grandes"
    ]
  },
  {
    "objectID": "content/pre-reading/pread-02-mundos-pequenos-mundos-grandes.html#fazendo-o-modelo-funcionar",
    "href": "content/pre-reading/pread-02-mundos-pequenos-mundos-grandes.html#fazendo-o-modelo-funcionar",
    "title": "Mundos Pequenos e Mundos Grandes",
    "section": "4 Fazendo o modelo funcionar",
    "text": "4 Fazendo o modelo funcionar\nUma vez que voc√™ nomeou todas as vari√°veis e escolheu defini√ß√µes para cada uma, um modelo bayesiano pode atualizar todas as distribui√ß√µes a priori para suas consequ√™ncias puramente l√≥gicas: a distribui√ß√£o a posteriori. Para cada combina√ß√£o √∫nica de dados, verossimilhan√ßa, par√¢metros e distribui√ß√£o a priori, h√° uma distribui√ß√£o a posteriori √∫nica. Essa distribui√ß√£o cont√©m a plausibilidade relativa de diferentes valores de par√¢metros, condicional nos dados e no modelo. A distribui√ß√£o a posteriori assume a forma da probabilidade dos par√¢metros, condicional nos dados. Neste caso, seria Pr(p|W, L), a probabilidade de cada valor poss√≠vel de p, condicional nos W e L espec√≠ficos que observamos.\n\nO teorema de Bayes\nA defini√ß√£o matem√°tica da distribui√ß√£o a posteriori surge do teorema de Bayes. Este √© o teorema que d√° √† an√°lise bayesiana de dados seu nome. Mas o teorema em si √© uma implica√ß√£o trivial da teoria da probabilidade.\nA probabilidade conjunta dos dados W e L e qualquer valor particular de p √©:\n\\[\\Pr(W, L, p) = \\Pr(W, L|p) \\Pr(p)\\]\nIsso apenas diz que a probabilidade de W, L e p √© o produto de Pr(W, L|p) e a probabilidade a priori Pr(p). √â como dizer que a probabilidade de chuva e frio no mesmo dia √© igual √† probabilidade de chuva, quando est√° frio, vezes a probabilidade de que esteja frio. At√© aqui √© apenas defini√ß√£o. Mas √© igualmente verdade que:\n\\[\\Pr(W, L, p) = \\Pr(p|W, L) \\Pr(W, L)\\]\nTudo o que fiz foi inverter qual probabilidade √© condicional, no lado direito. Agora, como ambos os lados direitos acima s√£o iguais √† mesma coisa, Pr(W, L, p), eles tamb√©m s√£o iguais entre si:\n\\[\\Pr(W, L|p) \\Pr(p) = \\Pr(p|W, L) \\Pr(W, L)\\]\nEnt√£o podemos agora resolver para o que queremos, Pr(p|W, L):\n\\[\\Pr(p|W,L) = \\frac{\\Pr(W,L|p)\\Pr(p)}{\\Pr(W,L)}\\]\nE este √© o teorema de Bayes. Ele diz que a probabilidade de qualquer valor particular de p, considerando os dados, √© igual ao produto da plausibilidade relativa dos dados, condicional em p, e da plausibilidade a priori de p, dividido pela probabilidade m√©dia dos dados. Em forma de palavras:\n\\[Posterior = \\frac{\\text{Probabilidade dos dados} \\times \\text{A priori}}{\\text{Probabilidade m√©dia dos dados}}\\]\nA probabilidade m√©dia dos dados, Pr(W, L), √© literalmente a probabilidade m√©dia dos dados. M√©dia sobre o qu√™? Sobre a distribui√ß√£o a priori. Seu trabalho √© apenas padronizar a distribui√ß√£o a posteriori, para garantir que ela some (integre) para um. Em forma matem√°tica:\n\\[\\Pr(W, L) = \\mathbb{E}(\\Pr(W, L|p)) = \\int \\Pr(W, L|p) \\Pr(p) dp\\]\nA li√ß√£o principal √© que a distribui√ß√£o a posteriori √© proporcional ao produto da distribui√ß√£o a priori e da probabilidade dos dados.\n\nFigura 2.6. A distribui√ß√£o a posteriori, como produto da distribui√ß√£o a priori e da verossimilhan√ßa. Linha superior: uma distribui√ß√£o a priori plana constr√≥i uma distribui√ß√£o a posteriori que √© simplesmente proporcional √† verossimilhan√ßa. Linha do meio: uma distribui√ß√£o a priori em degrau, atribuindo probabilidade zero a todos os valores menores que 0,5, resultando em uma distribui√ß√£o a posteriori truncada. Linha inferior: uma distribui√ß√£o a priori com pico que desloca e distorce a distribui√ß√£o a posteriori, relativamente √† verossimilhan√ßa.\nA Figura 2.6 ilustra a intera√ß√£o multiplicativa de uma distribui√ß√£o a priori e uma probabilidade dos dados. Em cada linha, uma distribui√ß√£o a priori √† esquerda √© multiplicada pela probabilidade dos dados no meio para produzir uma distribui√ß√£o a posteriori √† direita. A probabilidade dos dados em cada caso √© a mesma. As distribui√ß√µes a priori, contudo, variam. Como resultado, as distribui√ß√µes a posteriori variam.\n\n\nMotores de estima√ß√£o\nLembre-se de que seu modelo bayesiano √© uma m√°quina, um golem figurativo. Ele tem defini√ß√µes embutidas para a verossimilhan√ßa, os par√¢metros e a distribui√ß√£o a priori. E ent√£o, em seu cora√ß√£o, reside um motor que processa dados, produzindo uma distribui√ß√£o a posteriori.\nV√°rias t√©cnicas num√©ricas s√£o necess√°rias para aproximar a matem√°tica que segue da defini√ß√£o do teorema de Bayes. H√° tr√™s motores de condicionamento diferentes, t√©cnicas num√©ricas para calcular distribui√ß√µes a posteriori:\n\n\nAproxima√ß√£o por grade\n\n\nAproxima√ß√£o quadr√°tica\n\n\nMarkov chain Monte Carlo (MCMC)\n\n\nH√° muitos outros motores, e novos est√£o sendo inventados o tempo todo. Mas os tr√™s acima s√£o comuns e amplamente √∫teis.\n\n\nAproxima√ß√£o por grade\nUma das t√©cnicas de condicionamento mais simples √© a aproxima√ß√£o por grade. Embora a maioria dos par√¢metros seja cont√≠nua, capaz de assumir um n√∫mero infinito de valores, acontece que podemos alcan√ßar uma excelente aproxima√ß√£o da distribui√ß√£o a posteriori cont√≠nua considerando apenas uma grade finita de valores de par√¢metros. Em qualquer valor particular de um par√¢metro, p‚Äô, √© simples calcular a probabilidade a posteriori: basta multiplicar a probabilidade a priori de p‚Äô pela verossimilhan√ßa em p‚Äô. Repetir esse procedimento para cada valor na grade gera uma imagem aproximada da distribui√ß√£o a posteriori exata. Esse procedimento √© chamado de APROXIMA√á√ÉO POR GRADE.\nA aproxima√ß√£o por grade ser√° principalmente √∫til como ferramenta pedag√≥gica, pois aprend√™-la for√ßa o usu√°rio a realmente entender a natureza da atualiza√ß√£o bayesiana. Mas na maioria da sua modelagem real, a aproxima√ß√£o por grade n√£o √© pr√°tica, porque ela escala muito mal conforme o n√∫mero de par√¢metros aumenta.\nNo contexto do problema de lan√ßamento do globo, a aproxima√ß√£o por grade funciona extremamente bem. Aqui est√° a receita:\n\n\nDefina a grade. Isso significa que voc√™ decide quantos pontos usar na estima√ß√£o da distribui√ß√£o a posteriori e ent√£o faz uma lista dos valores de par√¢metros na grade.\n\n\nCalcule o valor da distribui√ß√£o a priori em cada valor de par√¢metro na grade.\n\n\nCalcule a verossimilhan√ßa em cada valor de par√¢metro.\n\n\nCalcule a distribui√ß√£o a posteriori n√£o padronizada em cada valor de par√¢metro, multiplicando a distribui√ß√£o a priori pela verossimilhan√ßa.\n\n\nFinalmente, padronize a distribui√ß√£o a posteriori, dividindo cada valor pela soma de todos os valores.\n\n\nNo contexto do lan√ßamento do globo, aqui est√° o c√≥digo para completar todas as cinco etapas:\n\n# define grid\np_grid &lt;- seq( from=0 , to=1 , length.out=20 )\n\n# define prior\nprior &lt;- rep( 1 , 20 )\n\n# compute likelihood at each value in grid\nlikelihood &lt;- dbinom( 6 , size=9 , prob=p_grid )\n\n# compute product of likelihood and prior\nunstd.posterior &lt;- likelihood * prior\n\n# standardize the posterior, so it sums to 1\nposterior &lt;- unstd.posterior / sum(unstd.posterior)\n\nO c√≥digo acima faz uma grade de apenas 20 pontos. Para exibir a distribui√ß√£o a posteriori agora:\n\nplot( p_grid , posterior , type=\"b\" ,\n      xlab=\"probability of water\" , ylab=\"posterior probability\" )\nmtext( \"20 points\" )\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigura 2.7. Calculando a distribui√ß√£o a posteriori por aproxima√ß√£o por grade. Em cada gr√°fico, a distribui√ß√£o a posteriori para os dados e modelo de lan√ßamento do globo √© aproximada com um n√∫mero finito de pontos igualmente espa√ßados. Com apenas 5 pontos (esquerda), a aproxima√ß√£o √© terr√≠vel. Mas com 20 pontos (direita), a aproxima√ß√£o j√° √© bastante boa.\nVoc√™ obter√° o gr√°fico da direita na Figura 2.7. Tente grades mais esparsas (5 pontos) e mais densas (100 ou 1000 pontos). A densidade correta para sua grade √© determinada por qu√£o precisa voc√™ quer que sua aproxima√ß√£o seja. Mais pontos significa mais precis√£o. Neste exemplo simples, voc√™ pode exagerar e usar 100.000 pontos, mas n√£o haver√° muita mudan√ßa na infer√™ncia ap√≥s os primeiros 100.\nAgora, para replicar as diferentes distribui√ß√µes a priori na Figura 2.5, tente estas linhas de c√≥digo ‚Äî uma de cada vez ‚Äî para a grade da distribui√ß√£o a priori:\n\nprior &lt;- ifelse( p_grid &lt; 0.5 , 0 , 1 )\nprior &lt;- exp( -5*abs( p_grid - 0.5 ) )\n\nO restante do c√≥digo permanece o mesmo.\n\nPensando Mais um Pouco: Vetoriza√ß√£o. Uma das caracter√≠sticas √∫teis do R √© que ele torna trabalhar com listas de n√∫meros quase t√£o f√°cil quanto trabalhar com valores √∫nicos. Ent√£o, embora ambas as linhas de c√≥digo acima n√£o digam nada sobre qu√£o densa √© sua grade, qualquer comprimento que voc√™ tenha escolhido para o vetor p_grid determinar√° o comprimento do vetor prior. No jarg√£o do R, os c√°lculos acima s√£o vetorizados, porque trabalham com listas de valores, vetores. Em um c√°lculo vetorizado, o c√°lculo √© realizado em cada elemento do vetor de entrada ‚Äî p_grid neste caso ‚Äî e a sa√≠da resultante, portanto, tem o mesmo comprimento. Em outros ambientes computacionais, o mesmo c√°lculo exigiria um loop. R tamb√©m pode usar loops, mas c√°lculos vetorizados s√£o tipicamente mais r√°pidos.\n\n\n\nAproxima√ß√£o quadr√°tica\nContinuaremos com a aproxima√ß√£o por grade da distribui√ß√£o a posteriori do lan√ßamento do globo pelo restante deste cap√≠tulo. Mas em breve voc√™ ter√° que recorrer a outra aproxima√ß√£o, uma que faz suposi√ß√µes mais fortes. A raz√£o √© que o n√∫mero de valores √∫nicos a considerar na grade cresce rapidamente conforme o n√∫mero de par√¢metros em seu modelo aumenta.\nUma abordagem √∫til √© a APROXIMA√á√ÉO QUADR√ÅTICA. Sob condi√ß√µes bem gerais, a regi√£o perto do pico da distribui√ß√£o a posteriori ser√° quase gaussiana ‚Äî ou ‚Äúnormal‚Äù ‚Äî em forma. Isso significa que a distribui√ß√£o a posteriori pode ser utilmente aproximada por uma distribui√ß√£o gaussiana. Uma distribui√ß√£o gaussiana √© conveniente, porque pode ser completamente descrita por apenas dois n√∫meros: a localiza√ß√£o de seu centro (m√©dia) e sua dispers√£o (vari√¢ncia).\nUma aproxima√ß√£o gaussiana √© chamada de ‚Äúaproxima√ß√£o quadr√°tica‚Äù porque o logaritmo de uma distribui√ß√£o gaussiana forma uma par√°bola.\nO procedimento cont√©m dois passos:\n\n\nEncontre a moda a posteriori. Isso √© geralmente alcan√ßado por algum algoritmo de otimiza√ß√£o.\n\n\nUma vez que voc√™ encontra o pico da distribui√ß√£o a posteriori, deve estimar a curvatura perto do pico. Essa curvatura √© suficiente para calcular uma aproxima√ß√£o quadr√°tica de toda a distribui√ß√£o a posteriori.\n\n\nPara calcular a aproxima√ß√£o quadr√°tica dos dados de lan√ßamento do globo usando base R:\n\n# Encontrar o MAP (pico da posterior) via otimiza√ß√£o\nW &lt;- 6\nL &lt;- 3\n\n# Fun√ß√£o log-posterior (prior uniforme + binomial)\nlog_post &lt;- function(p) {\n  dbinom(W, W + L, p, log = TRUE) + dunif(p, 0, 1, log = TRUE)\n}\n\n# Otimizar para encontrar o MAP\nresultado &lt;- optimize(log_post, interval = c(0, 1), maximum = TRUE)\np_map &lt;- resultado$maximum\n\n# Curvatura (desvio padr√£o da aproxima√ß√£o quadr√°tica)\ndelta &lt;- 1e-4\nd2 &lt;- (log_post(p_map + delta) - 2 * log_post(p_map) + log_post(p_map - delta)) / delta^2\np_sd &lt;- sqrt(-1 / d2)\n\ncat(sprintf(\"MAP (m√©dia a posteriori): %.2f\\n\", p_map))\ncat(sprintf(\"Desvio padr√£o (aprox. quadr√°tica): %.2f\\n\", p_sd))\ncat(sprintf(\"Intervalo 89%%: [%.2f, %.2f]\\n\",\n    qnorm(0.055, p_map, p_sd),\n    qnorm(0.945, p_map, p_sd)))\n\nMAP (m√©dia a posteriori): 0.67\nDesvio padr√£o (aprox. quadr√°tica): 0.16\nIntervalo 89%: [0.42, 0.92]\nVoc√™ pode ler essa aproxima√ß√£o como: Supondo que a distribui√ß√£o a posteriori √© gaussiana, ela √© maximizada em 0,67 e seu desvio padr√£o √© 0,16.\nComo j√° conhecemos a distribui√ß√£o a posteriori, vamos comparar para ver qu√£o boa √© a aproxima√ß√£o. Usaremos a abordagem anal√≠tica, que usa dbeta, para obter exatamente a resposta certa, sem aproxima√ß√µes:\n\n# Distribui√ß√£o a posteriori anal√≠tica (exata)\nW &lt;- 6\nL &lt;- 3\ncurve( dbeta(x, W+1, L+1), from=0, to=1,\n       xlab=\"p\", ylab=\"densidade\", col=\"blue\", lwd=2)\n\n# Aproxima√ß√£o quadr√°tica\ncurve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE, col=\"black\", lwd=2 )\nlegend(\"topleft\", legend=c(\"Posterior exata\", \"Aprox. quadr√°tica\"),\n       col=c(\"blue\",\"black\"), lty=c(1,2), lwd=2)\n\n\nFigura 2.8. Precis√£o da aproxima√ß√£o quadr√°tica. Em cada gr√°fico, a distribui√ß√£o a posteriori exata √© plotada em azul, e a aproxima√ß√£o quadr√°tica √© plotada como a curva preta. Esquerda: Os dados de lan√ßamento do globo com n = 9 lan√ßamentos e w = 6 √°guas. Meio: O dobro da quantidade de dados, com a mesma fra√ß√£o de √°gua, n = 18 e w = 12. Direita: Quatro vezes mais dados, n = 36 e w = 24.\nConforme a quantidade de dados aumenta, a aproxima√ß√£o quadr√°tica melhora. Esse fen√¥meno, em que a aproxima√ß√£o quadr√°tica melhora com a quantidade de dados, √© muito comum.\n\n\nMarkov chain Monte Carlo\nH√° muitos tipos importantes de modelos, como modelos multin√≠vel (efeitos mistos), para os quais nem a aproxima√ß√£o por grade nem a aproxima√ß√£o quadr√°tica √© sempre satisfat√≥ria. Tais modelos podem ter centenas ou milhares ou dezenas de milhares de par√¢metros. A aproxima√ß√£o por grade rotineiramente falha aqui, porque simplesmente demora demais.\nComo resultado, v√°rias t√©cnicas contra-intuitivas de ajuste de modelos surgiram. A mais popular destas √© Markov Chain Monte Carlo (MCMC), que √© uma fam√≠lia de motores de condicionamento capazes de lidar com modelos altamente complexos.\nO desafio conceitual com MCMC reside em sua estrat√©gia altamente n√£o √≥bvia. Em vez de tentar calcular ou aproximar a distribui√ß√£o a posteriori diretamente, t√©cnicas MCMC meramente sorteiam amostras da distribui√ß√£o a posteriori. Voc√™ termina com uma cole√ß√£o de valores de par√¢metros, e as frequ√™ncias desses valores correspondem √†s plausibilidades a posteriori. Voc√™ pode ent√£o construir uma imagem da distribui√ß√£o a posteriori a partir do histograma dessas amostras.\n\nPensando Mais um Pouco: Monte Carlo e o lan√ßamento do globo. Uma cadeia de Markov funcional para o modelo de lan√ßamento do globo n√£o requer muito c√≥digo. O seguinte c√≥digo R ser√° suficiente:\n\n\nn_samples &lt;- 1000\np &lt;- rep( NA , n_samples )\np[1] &lt;- 0.5\nW &lt;- 6\nL &lt;- 3\nfor ( i in 2:n_samples ) {\n    p_new &lt;- rnorm( 1 , p[i-1] , 0.1 )\n    if ( p_new &lt; 0 ) p_new &lt;- abs( p_new )\n    if ( p_new &gt; 1 ) p_new &lt;- 2 - p_new\n    q0 &lt;- dbinom( W , W+L , p[i-1] )\n    q1 &lt;- dbinom( W , W+L , p_new )\n    p[i] &lt;- ifelse( runif(1) &lt; q1/q0 , p_new , p[i-1] )\n}\n\nOs valores em p s√£o amostras da distribui√ß√£o a posteriori. Para comparar com a distribui√ß√£o a posteriori anal√≠tica:\n\n# Visualizar a distribui√ß√£o das amostras MCMC\nplot(density(p), xlim=c(0,1),\n     main=\"MCMC vs. Posterior anal√≠tica\",\n     xlab=\"p\", ylab=\"densidade\")\n# Sobrepor a posterior exata\ncurve( dbeta( x , W+1 , L+1 ) , lty=2 , add=TRUE, col=\"blue\", lwd=2 )\nlegend(\"topleft\", legend=c(\"MCMC\", \"Exata\"),\n       col=c(\"black\",\"blue\"), lty=c(1,2))",
    "crumbs": [
      "Leitura Pr√©via",
      "Aula 2 - Mundos Pequenos e Mundos Grandes"
    ]
  },
  {
    "objectID": "content/pre-reading/pread-02-mundos-pequenos-mundos-grandes.html#resumo",
    "href": "content/pre-reading/pread-02-mundos-pequenos-mundos-grandes.html#resumo",
    "title": "Mundos Pequenos e Mundos Grandes",
    "section": "5 Resumo",
    "text": "5 Resumo\nEste cap√≠tulo introduziu a mec√¢nica conceitual da an√°lise bayesiana de dados. O alvo da infer√™ncia na infer√™ncia bayesiana √© uma distribui√ß√£o de probabilidade a posteriori. Probabilidades a posteriori declaram os n√∫meros relativos de maneiras que cada causa conjecturada dos dados poderia ter produzido os dados. Esses n√∫meros relativos indicam plausibilidades das diferentes conjecturas. Essas plausibilidades s√£o atualizadas √† luz das observa√ß√µes, um processo conhecido como atualiza√ß√£o bayesiana.\nMais mecanicamente, um modelo bayesiano √© um composto de vari√°veis e defini√ß√µes distribucionais para essas vari√°veis. A probabilidade dos dados, frequentemente chamada de verossimilhan√ßa, fornece a plausibilidade de uma observa√ß√£o (dados), dado um valor fixo para os par√¢metros. A distribui√ß√£o a priori fornece a plausibilidade de cada valor poss√≠vel dos par√¢metros, antes de considerar os dados. As regras da probabilidade nos dizem que a maneira l√≥gica de calcular as plausibilidades, ap√≥s considerar os dados, √© usar o teorema de Bayes. Isso resulta na distribui√ß√£o a posteriori.\nNa pr√°tica, modelos bayesianos s√£o ajustados aos dados usando t√©cnicas num√©ricas, como aproxima√ß√£o por grade, aproxima√ß√£o quadr√°tica e Markov chain Monte Carlo. Cada m√©todo imp√µe diferentes compromissos.",
    "crumbs": [
      "Leitura Pr√©via",
      "Aula 2 - Mundos Pequenos e Mundos Grandes"
    ]
  },
  {
    "objectID": "course-info/syllabus.html",
    "href": "course-info/syllabus.html",
    "title": "Plano de Ensino: PROBABILIDADE E ESTAT√çSTICA",
    "section": "",
    "text": "Ementa\nA Unidade Curricular (UC) explora os fundamentos da infer√™ncia estat√≠stica, com √™nfase em modelos probabil√≠sticos e suas aplica√ß√µes na an√°lise de dados e interpreta√ß√£o de fen√¥menos complexos relacionados √†s Ci√™ncias do Mar.¬†A UC enfatiza a investiga√ß√£o de hip√≥teses sobre processos ambientais por meio da constru√ß√£o e an√°lise de modelos probabil√≠sticos, integrando conhecimentos pr√©vios com evid√™ncias baseadas em dados. O curso promove uma abordagem pr√°tica, com foco na elabora√ß√£o de modelos e na simula√ß√£o computacional, integrando teoria e pr√°tica como suporte √† tomada de decis√£o, de forma a oferecer uma compreens√£o ampla e aplicada dos conceitos te√≥ricos e computacionais envolvidos.\n\n\nConte√∫do program√°tico\n\nFundamentos da Infer√™ncia Estat√≠stica e Modelagem Probabil√≠stica\n\nProbabilidade como l√≥gica e ferramenta para lidar com incertezas.\nConceitos fundamentais: distribui√ß√µes a priori, verossimilhan√ßa e distribui√ß√µes posteriori.\n\nAplica√ß√µes Computacionais e Ferramentas Anal√≠ticas\n\nImplementa√ß√£o de modelos utilizando R, Python e linguagens de programa√ß√£o probabil√≠stica.\nExemplos pr√°ticos aplicados √†s Ci√™ncias do Mar.\n\nConstru√ß√£o de Modelos Probabil√≠sticos\n\nHip√≥teses cient√≠ficas, estruturas de depend√™ncia e rela√ß√µes causais.\nDesenvolvimento de modelos conceituais integrando conhecimento pr√©vio.\nSimula√ß√£o inicial para explorar predi√ß√µes com base no modelo.\n\nIntegra√ß√£o de Dados ao Modelo\n\nIncorpora√ß√£o de observa√ß√µes emp√≠ricas ao modelo conceitual.\nAtualiza√ß√£o de predi√ß√µes ap√≥s a integra√ß√£o de novos dados.\nT√©cnicas de ajuste e calibra√ß√£o de modelos baseadas em dados observados.\n\nAvalia√ß√£o e Refinamento de Modelos\n\nPredi√ß√µes e extrapola√ß√µes baseadas no modelo ajustado.\nCompara√ß√£o de modelos utilizando crit√©rios de valida√ß√£o.\nAn√°lise de sensibilidade a diferentes distribui√ß√µes a priori.\n\nDesenhos Experimentais e Rela√ß√µes Causais Complexas\n\nModelos para classifica√ß√£o e contagem.\nExplora√ß√£o de rela√ß√µes n√£o lineares.\nEstruturas hier√°rquicas e suas aplica√ß√µes.\nModelagem de depend√™ncias espaciais e temporais.\n\n\n\n\nObjetivos\n\nGerais\nCapacitar os alunos a compreender e aplicar conceitos de infer√™ncia estat√≠stica e modelagem probabil√≠stica, utilizando ferramentas computacionais modernas para an√°lise de dados e interpreta√ß√£o de fen√¥menos complexos nas Ci√™ncias do Mar, promovendo a integra√ß√£o entre teoria, pr√°tica e suporte √† tomada de decis√£o.\n\n\nEspec√≠ficos\n\nCompreender os fundamentos da probabilidade como l√≥gica, aplicando-os √† compara√ß√£o entre diferentes hip√≥teses cient√≠ficas.\nImplementar modelos probabil√≠sticos em contextos ambientais utilizando linguagens de programa√ß√£o e ferramentas computacionais.\nDesenvolver e explorar modelos conceituais integrando conhecimentos pr√©vios, representa√ß√µes causais e simula√ß√µes iniciais.\nIncorporar dados emp√≠ricos a modelos probabil√≠sticos, ajustando e calibrando predi√ß√µes com base em observa√ß√µes reais.\nComparar e refinar modelos utilizando crit√©rios de valida√ß√£o e an√°lise de sensibilidade.\nAplicar modelos probabil√≠sticos para descrever rela√ß√µes n√£o lineares, depend√™ncias espaciais e temporais, e processos ambientais complexos.\n\n\n\n\nAvalia√ß√£o\nSer√£o atribu√≠das 5 Listas de Exerc√≠cios (Peso 40%) e 3 Avalia√ß√µes (Peso 60%). A 3¬™ avalia√ß√£o consistir√° em um trabalho final desenvolvido ao longo do semestre e apresentado ao final do curso.\nA nota final do per√≠odo letivo (NL) ser√° computada pela m√©dia ponderada das listas e avalia√ß√µes.\n\nA nota final (NF) ser√° NF = NL para alunos com NL ‚â• 6,0.\nO EXAME ser√° aplicado apenas aos alunos n√£o reprovados por falta e que obtiveram NL entre 3,0 e 5,9 ao final do per√≠odo letivo regular.\nPara estes alunos, a nota final ser√° NF = (NL + NE)/2, onde NE √© a nota obtida no EXAME.\nSe o aluno n√£o realizar o EXAME, NE = 0.",
    "crumbs": [
      "Informa√ß√µes do curso",
      "Plano de Ensino"
    ]
  }
]