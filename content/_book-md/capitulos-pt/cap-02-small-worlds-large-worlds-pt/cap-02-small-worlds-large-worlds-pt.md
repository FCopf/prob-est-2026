# 2 Mundos Pequenos e Mundos Grandes
Quando Cristoforo Colombo (CristÃ³vÃ£o Colombo) navegou infamemente para o oeste no ano de 1492, ele acreditava que a Terra era esfÃ©rica. Nisso, ele era como a maioria das pessoas instruÃ­das de sua Ã©poca. Ele diferia da maioria, porÃ©m, ao acreditar que o planeta era muito menor do que realmente Ã© â€” apenas 30.000 km ao redor de seu equador, em vez dos 40.000 km reais (Figura 2.1).$^{37}$ Esse foi um dos erros mais consequentes da histÃ³ria europeia. Se Colombo tivesse acreditado que a Terra tinha 40.000 km de circunferÃªncia, ele teria raciocinado corretamente que sua frota nÃ£o poderia carregar comida e Ã¡gua potÃ¡vel suficientes para completar uma viagem inteiramente para o oeste atÃ© a Ãsia. Mas com 30.000 km de circunferÃªncia, a Ãsia estaria um pouco a oeste da costa da CalifÃ³rnia. Era possÃ­vel carregar suprimentos suficientes para chegar tÃ£o longe. Encorajado em parte por sua estimativa nÃ£o convencional, Colombo zarpou, eventualmente aportando nas Bahamas.

Colombo fez uma prediÃ§Ã£o baseada em sua visÃ£o de que o mundo era pequeno. Mas como ele vivia em um mundo grande, aspectos da prediÃ§Ã£o estavam errados. No seu caso, o erro foi sortudo. Seu modelo de mundo pequeno estava errado de uma maneira inesperada: havia muita terra no caminho. Se ele tivesse errado da maneira esperada, com nada alÃ©m de oceano entre a Europa e a Ãsia, ele e toda a sua expediÃ§Ã£o teriam ficado sem suprimentos muito antes de alcanÃ§ar as Ãndias Orientais.

Os mundos pequeno e grande de Colombo oferecem um contraste entre modelo e realidade. Toda modelagem estatÃ­stica possui esses mesmos dois enquadramentos: o mundo pequeno do modelo em si e o mundo grande no qual esperamos aplicar o modelo.$^{38}$ Navegar entre esses dois mundos permanece um desafio central da modelagem estatÃ­stica. O desafio Ã© agravado quando se esquece a distinÃ§Ã£o.

O **mundo pequeno** Ã© o mundo lÃ³gico autocontido do modelo. Dentro do mundo pequeno, todas as possibilidades sÃ£o nomeadas. NÃ£o hÃ¡ surpresas puras, como a existÃªncia de um enorme continente entre a Europa e a Ãsia. Dentro do mundo pequeno do modelo, Ã© importante ser capaz de verificar a lÃ³gica do modelo, assegurando que ele funciona conforme esperado sob suposiÃ§Ãµes favorÃ¡veis. Modelos bayesianos tÃªm algumas vantagens nesse aspecto, pois possuem reivindicaÃ§Ãµes razoÃ¡veis de otimalidade: nenhum modelo alternativo poderia fazer melhor uso da informaÃ§Ã£o nos dados e apoiar melhores decisÃµes, assumindo que o mundo pequeno Ã© uma descriÃ§Ã£o precisa do mundo real.$^{39}$

O **mundo grande** Ã© o contexto mais amplo no qual se aplica um modelo. No mundo grande, podem existir eventos que nÃ£o foram imaginados no mundo pequeno. AlÃ©m disso, o modelo Ã© sempre uma representaÃ§Ã£o incompleta do mundo grande, e portanto cometerÃ¡ erros, mesmo que todos os tipos de eventos tenham sido devidamente nomeados. A consistÃªncia lÃ³gica de um modelo no mundo pequeno nÃ£o Ã© garantia de que ele serÃ¡ Ã³timo no mundo grande. Mas certamente Ã© um conforto reconfortante.

![](_page_1_Figure_2.jpeg)

Figura 2.1. IlustraÃ§Ã£o do globo de Martin Behaim de 1492, mostrando o mundo pequeno que Colombo antecipava. A Europa estÃ¡ no lado direito. A Ãsia estÃ¡ Ã  esquerda. A grande ilha rotulada "Cipangu" Ã© o JapÃ£o.

Neste capÃ­tulo, vocÃª comeÃ§arÃ¡ a construir modelos bayesianos. A maneira como modelos bayesianos aprendem a partir de evidÃªncias Ã© indiscutivelmente Ã³tima no mundo pequeno. Quando suas suposiÃ§Ãµes se aproximam da realidade, eles tambÃ©m tÃªm bom desempenho no mundo grande. Mas o desempenho no mundo grande precisa ser demonstrado, e nÃ£o deduzido logicamente. Transitar entre esses dois mundos permite que tanto mÃ©todos formais, como a inferÃªncia bayesiana, quanto mÃ©todos informais, como a revisÃ£o por pares, desempenhem um papel indispensÃ¡vel.

Este capÃ­tulo foca no mundo pequeno. Ele explica a teoria da probabilidade em sua forma essencial: contando as maneiras como as coisas podem acontecer. A inferÃªncia bayesiana surge automaticamente dessa perspectiva. Em seguida, o capÃ­tulo apresenta os componentes estilizados de um modelo estatÃ­stico bayesiano, um modelo para aprender a partir de dados. Depois, mostra como animar o modelo para produzir estimativas.

Todo esse trabalho fornece uma base para o prÃ³ximo capÃ­tulo, no qual vocÃª aprenderÃ¡ a resumir estimativas bayesianas, bem como comeÃ§arÃ¡ a considerar as obrigaÃ§Ãµes do mundo grande.

> **Repensando: RÃ¡pido e frugal no mundo grande.** O mundo natural Ã© complexo, como a tentativa de fazer ciÃªncia nos lembra. No entanto, tudo, desde o humilde carrapato atÃ© o industrioso esquilo e a preguiÃ§a ociosa, consegue frequentemente tomar decisÃµes adaptativas. Mas Ã© uma boa aposta que a maioria dos animais nÃ£o Ã© bayesiana, atÃ© porque ser bayesiano Ã© caro e depende de ter um bom modelo. Em vez disso, os animais usam diversas heurÃ­sticas que sÃ£o ajustadas aos seus ambientes, passados ou presentes. Essas heurÃ­sticas tomam atalhos adaptativos e, portanto, podem superar uma anÃ¡lise bayesiana rigorosa, uma vez que os custos de coleta e processamento de informaÃ§Ã£o (e sobreajuste, CapÃ­tulo 6) sÃ£o levados em conta.$^{40}$ Uma vez que vocÃª jÃ¡ sabe qual informaÃ§Ã£o ignorar ou prestar atenÃ§Ã£o, ser completamente bayesiano Ã© um desperdÃ­cio. NÃ£o Ã© necessÃ¡rio nem suficiente para tomar boas decisÃµes, como animais reais demonstram. Mas para animais humanos, a anÃ¡lise bayesiana fornece uma maneira geral de descobrir informaÃ§Ãµes relevantes e processÃ¡-las logicamente. Apenas nÃ£o pense que Ã© a Ãºnica maneira.

## 2.1. O jardim dos dados bifurcantes
Nosso objetivo nesta seÃ§Ã£o serÃ¡ construir a inferÃªncia bayesiana a partir de origens humildes, para que nÃ£o haja superstiÃ§Ã£o a respeito dela. A inferÃªncia bayesiana Ã© realmente apenas contagem e comparaÃ§Ã£o de possibilidades. Considere, por analogia, o conto de Jorge Luis Borges, "O Jardim dos Caminhos que se Bifurcam." A histÃ³ria Ã© sobre um homem que encontra um livro cheio de contradiÃ§Ãµes. Na maioria dos livros, os personagens chegam a pontos da trama e devem decidir entre caminhos alternativos. Uma protagonista pode chegar Ã  casa de um homem. Ela pode matar o homem, ou entÃ£o tomar uma xÃ­cara de chÃ¡. Apenas

um desses caminhos Ã© tomado â€” assassinato ou chÃ¡. Mas o livro dentro da histÃ³ria de Borges explora todos os caminhos, com cada decisÃ£o se ramificando para fora em um jardim cada vez mais amplo de caminhos bifurcantes.

Este Ã© o mesmo dispositivo que a inferÃªncia bayesiana oferece. Para fazer boas inferÃªncias sobre o que realmente aconteceu, ajuda considerar tudo o que poderia ter acontecido. Uma anÃ¡lise bayesiana Ã© um jardim de dados bifurcantes, no qual sequÃªncias alternativas de eventos sÃ£o cultivadas. Ã€ medida que aprendemos sobre o que aconteceu, algumas dessas sequÃªncias alternativas sÃ£o podadas. No final, o que resta Ã© apenas o que Ã© logicamente consistente com nosso conhecimento.

Essa abordagem fornece uma classificaÃ§Ã£o quantitativa de hipÃ³teses, uma classificaÃ§Ã£o que Ã© maximamente conservadora, dadas as suposiÃ§Ãµes e os dados que a alimentam. A abordagem nÃ£o pode garantir uma resposta correta em termos de mundo grande. Mas pode garantir a melhor resposta possÃ­vel, em termos de mundo pequeno, que poderia ser derivada da informaÃ§Ã£o fornecida.

Considere o seguinte exemplo didÃ¡tico.

**2.1.1. Contando possibilidades.** Suponha que haja um saco contendo quatro bolinhas de gude. Essas bolinhas vÃªm em duas cores: azul e branca. Sabemos que hÃ¡ quatro bolinhas no saco, mas nÃ£o sabemos quantas sÃ£o de cada cor. Sabemos que existem cinco possibilidades: (1) [âšªâšªâšªâšª], (2) [ğŸ”µâšªâšªâšª], (3) [ğŸ”µğŸ”µâšªâšª], (4) [ğŸ”µğŸ”µğŸ”µâšª], (5) [ğŸ”µğŸ”µğŸ”µğŸ”µ]. Essas sÃ£o as Ãºnicas possibilidades consistentes com o que sabemos sobre o conteÃºdo do saco. Chame essas cinco possibilidades de conjecturas.

Nosso objetivo Ã© descobrir qual dessas conjecturas Ã© mais plausÃ­vel, dada alguma evidÃªncia sobre o conteÃºdo do saco. Temos alguma evidÃªncia: uma sequÃªncia de trÃªs bolinhas Ã© retirada do saco, uma de cada vez, recolocando a bolinha cada vez e agitando o saco antes de retirar outra bolinha. A sequÃªncia que emerge Ã©: ğŸ”µâšªğŸ”µ, nessa ordem. Esses sÃ£o os dados.

EntÃ£o, vamos plantar o jardim e ver como usar os dados para inferir o que estÃ¡ no saco. Comecemos considerando apenas a conjectura [ğŸ”µâšªâšªâšª], de que o saco contÃ©m uma bolinha azul e trÃªs brancas. Na primeira retirada do saco, uma de quatro coisas poderia acontecer, correspondendo a uma das quatro bolinhas no saco. Assim, podemos visualizar as possibilidades se ramificando:

![](_page_2_Picture_1b.jpeg)

Note que, embora as trÃªs bolinhas brancas pareÃ§am iguais de uma perspectiva de dados â€” afinal, registramos apenas a cor das bolinhas â€” elas sÃ£o realmente eventos diferentes. Isso Ã© importante, porque significa que hÃ¡ trÃªs vezes mais maneiras de ver âšª do que de ver ğŸ”µ.

Agora considere o jardim Ã  medida que obtemos outra retirada do saco. Ele expande o jardim em mais uma camada:

![](_page_2_Picture_12.jpeg)

Agora hÃ¡ 16 caminhos possÃ­veis atravÃ©s do jardim, um para cada par de retiradas. Na segunda retirada do saco, cada um dos caminhos acima se bifurca novamente em quatro caminhos possÃ­veis. Por quÃª?

![](_page_3_Figure_2.jpeg)

Figura 2.2. Os 64 caminhos possÃ­veis gerados ao supor que o saco contÃ©m uma bolinha azul e trÃªs brancas.

Porque acreditamos que nossa agitaÃ§Ã£o do saco dÃ¡ a cada bolinha uma chance justa de ser retirada, independentemente de qual bolinha foi retirada anteriormente. A terceira camada Ã© construÃ­da da mesma maneira, e o jardim completo Ã© mostrado na Figura 2.2. HÃ¡ $4^3 = 64$ caminhos possÃ­veis no total.

Ã€ medida que consideramos cada retirada do saco, alguns desses caminhos sÃ£o logicamente eliminados. A primeira retirada resultou em ğŸ”µ, lembre-se, entÃ£o os trÃªs caminhos brancos na parte inferior do jardim sÃ£o eliminados imediatamente. Se vocÃª imaginar os dados reais traÃ§ando um caminho pelo jardim, eles devem ter passado pelo Ãºnico caminho azul perto da origem. A segunda retirada do saco produz âšª, entÃ£o trÃªs dos caminhos que se bifurcam a partir da primeira bolinha azul permanecem. Conforme os dados traÃ§am um caminho, sabemos que ele deve ter passado por um desses trÃªs caminhos brancos (depois do primeiro caminho azul), mas nÃ£o sabemos por qual, porque registramos apenas a cor de cada bolinha. Finalmente, a terceira retirada Ã© ğŸ”µ. Cada um dos trÃªs caminhos restantes na camada intermediÃ¡ria sustenta um caminho azul, deixando um total de trÃªs maneiras para a sequÃªncia ğŸ”µâšªğŸ”µ aparecer, supondo que o saco contÃ©m [ğŸ”µâšªâšªâšª]. A Figura 2.3 mostra o jardim novamente, agora com caminhos logicamente eliminados esmaecidos. NÃ£o podemos ter certeza de qual desses trÃªs caminhos os dados reais tomaram. Mas, enquanto estivermos considerando apenas a possibilidade de que o saco contenha uma bolinha azul e trÃªs brancas, podemos ter certeza de que os dados tomaram um desses trÃªs caminhos. Esses sÃ£o os Ãºnicos caminhos consistentes tanto com nosso conhecimento sobre o conteÃºdo do saco (quatro bolinhas, brancas ou azuis) quanto com os dados (ğŸ”µâšªğŸ”µ).

Isso demonstra que hÃ¡ trÃªs (de 64) maneiras para um saco contendo [ğŸ”µâšªâšªâšª] produzir os dados ğŸ”µâšªğŸ”µ. NÃ£o temos como decidir entre essas trÃªs maneiras. O poder inferencial vem de comparar essa contagem com os nÃºmeros de maneiras que cada uma das outras conjecturas sobre o conteÃºdo do saco poderia produzir os mesmos dados. Por exemplo, considere a conjectura [âšªâšªâšªâšª]. HÃ¡ zero maneiras para essa conjectura produzir os dados observados, porque mesmo uma Ãºnica ğŸ”µ Ã© logicamente incompatÃ­vel com ela. A conjectura [ğŸ”µğŸ”µğŸ”µğŸ”µ] Ã© igualmente logicamente incompatÃ­vel com os dados. Portanto, podemos eliminar essas duas conjecturas, porque nenhuma fornece sequer um Ãºnico caminho consistente com os dados.

A Figura 2.4 exibe o jardim completo agora, para as trÃªs conjecturas restantes: [ğŸ”µâšªâšªâšª], [ğŸ”µğŸ”µâšªâšª] e [ğŸ”µğŸ”µğŸ”µâšª]. A fatia superior esquerda exibe o mesmo jardim da Figura 2.3. A superior direita mostra o jardim anÃ¡logo para a conjectura de que o saco contÃ©m trÃªs bolinhas azuis e uma branca. E a fatia inferior mostra o jardim para duas bolinhas azuis

![](_page_4_Figure_2.jpeg)

Figura 2.3. ApÃ³s eliminar caminhos inconsistentes com a sequÃªncia observada, apenas 3 dos 64 caminhos permanecem.

e duas brancas. Agora contamos todas as maneiras que cada conjectura poderia produzir os dados observados. Para uma azul e trÃªs brancas, hÃ¡ trÃªs maneiras, como jÃ¡ contamos. Para duas azuis e duas brancas, hÃ¡ oito caminhos que se bifurcam pelo jardim que sÃ£o logicamente consistentes com a sequÃªncia observada. Para trÃªs azuis e uma branca, hÃ¡ nove caminhos que sobrevivem.

Para resumir, consideramos cinco conjecturas diferentes sobre o conteÃºdo do saco, variando de zero bolinhas azuis a quatro bolinhas azuis. Para cada uma dessas conjecturas, contamos quantas sequÃªncias, caminhos pelo jardim de dados bifurcantes, poderiam potencialmente produzir os dados observados, ğŸ”µâšªğŸ”µ

| Conjectura                          | Maneiras de produzir ğŸ”µâšªğŸ”µ  |
|-------------------------------------|------------------------------|
| [âšªâšªâšªâšª]                          | $0 \times 4 \times 0 = 0$   |
| [ğŸ”µâšªâšªâšª]                          | $1 \times 3 \times 1 = 3$   |
| [ğŸ”µğŸ”µâšªâšª]                          | $2 \times 2 \times 2 = 8$   |
| [ğŸ”µğŸ”µğŸ”µâšª]                          | $3 \times 1 \times 3 = 9$   |
| [ğŸ”µğŸ”µğŸ”µğŸ”µ]                          | $4 \times 0 \times 4 = 0$   |

Note que o nÃºmero de maneiras de produzir os dados ğŸ”µâšªğŸ”µ, para cada conjectura, pode ser calculado contando primeiro o nÃºmero de caminhos em cada "anel" do jardim e depois multiplicando essas contagens. Isso Ã© apenas um artifÃ­cio computacional. Ele nos diz a mesma coisa que a Figura 2.4, mas sem precisar desenhar o jardim. O fato de que os nÃºmeros sÃ£o multiplicados durante o cÃ¡lculo nÃ£o muda o fato de que isso ainda Ã© apenas contagem de caminhos logicamente possÃ­veis. Esse ponto surgirÃ¡ novamente quando vocÃª encontrar a representaÃ§Ã£o mais formal da inferÃªncia bayesiana.

EntÃ£o, para que servem essas contagens? Ao comparar essas contagens, temos parte de uma soluÃ§Ã£o para uma maneira de classificar a plausibilidade relativa de cada composiÃ§Ã£o conjecturada do saco. Mas Ã© apenas uma parte de uma soluÃ§Ã£o, porque, para comparar essas contagens, primeiro precisamos decidir de quantas maneiras cada conjectura poderia ela mesma ser realizada. PoderÃ­amos argumentar que, quando nÃ£o temos motivo para supor o contrÃ¡rio, podemos simplesmente considerar cada conjectura igualmente plausÃ­vel e comparar as contagens diretamente. Mas frequentemente temos motivo para supor o contrÃ¡rio.

![](_page_5_Figure_2.jpeg)

Figura 2.4. O jardim de dados bifurcantes, mostrando para cada possÃ­vel composiÃ§Ã£o do saco os caminhos bifurcantes que sÃ£o logicamente compatÃ­veis com os dados.

> **Repensando: Justificativa.** Usar contagens de caminhos pelo jardim como medidas de plausibilidade relativa pode ser justificado de diversas maneiras. A justificativa aqui Ã© lÃ³gica: se desejamos raciocinar sobre plausibilidade e permanecer consistentes com a lÃ³gica ordinÃ¡ria â€” afirmaÃ§Ãµes sobre verdadeiro e falso â€” entÃ£o devemos obedecer a este procedimento.$^{41}$ HÃ¡ diversas outras justificativas que levam ao mesmo procedimento matemÃ¡tico. Independentemente de como vocÃª escolha justificÃ¡-lo filosoficamente, note que ele realmente funciona. Justificativas e filosofia motivam procedimentos, mas sÃ£o os resultados que importam. As muitas aplicaÃ§Ãµes bem-sucedidas no mundo real da inferÃªncia bayesiana podem ser toda a justificativa que vocÃª precisa. Oponentes do sÃ©culo XX da anÃ¡lise bayesiana de dados argumentaram que a inferÃªncia bayesiana era fÃ¡cil de justificar, mas difÃ­cil de aplicar.$^{42}$ Isso felizmente nÃ£o Ã© mais verdade. De fato, o oposto Ã© frequentemente verdadeiro â€” cientistas estÃ£o mudando para abordagens bayesianas porque elas permitem usar os modelos que desejam. Apenas tenha cuidado para nÃ£o supor que, porque

a inferÃªncia bayesiana Ã© justificada, nenhuma outra abordagem tambÃ©m pode ser justificada. Golems vÃªm em muitos tipos, e alguns de todos os tipos sÃ£o Ãºteis.

**2.1.2. Combinando outras informaÃ§Ãµes.** Podemos ter informaÃ§Ãµes adicionais sobre a plausibilidade relativa de cada conjectura. Essa informaÃ§Ã£o pode surgir do conhecimento de como o conteÃºdo do saco foi gerado. Pode tambÃ©m surgir de dados anteriores. Seja qual for a fonte, seria Ãºtil ter uma maneira de combinar diferentes fontes de informaÃ§Ã£o para atualizar as plausibilidades. Felizmente, hÃ¡ uma soluÃ§Ã£o natural: basta multiplicar as contagens.

Para entender essa soluÃ§Ã£o, suponha que estejamos dispostos a dizer que cada conjectura Ã© igualmente plausÃ­vel no inÃ­cio. EntÃ£o, simplesmente comparamos as contagens de maneiras em que cada conjectura Ã© compatÃ­vel com os dados observados. Essa comparaÃ§Ã£o sugere que [ğŸ”µğŸ”µğŸ”µâšª] Ã© ligeiramente mais plausÃ­vel que [ğŸ”µğŸ”µâšªâšª], e ambos sÃ£o cerca de trÃªs vezes mais plausÃ­veis que [ğŸ”µâšªâšªâšª]. Como essas sÃ£o nossas contagens iniciais, e vamos atualizÃ¡-las em seguida, vamos rotulÃ¡-las *a priori*.

Agora suponha que retiremos outra bolinha do saco para obter outra observaÃ§Ã£o: ğŸ”µ. Agora vocÃª tem duas escolhas. VocÃª poderia comeÃ§ar tudo de novo, fazendo um jardim com quatro camadas para traÃ§ar os caminhos compatÃ­veis com a sequÃªncia de dados ğŸ”µ âšª ğŸ”µ ğŸ”µ. Ou poderia pegar as contagens anteriores â€” as contagens a priori â€” sobre as conjecturas (0, 3, 8, 9, 0) e simplesmente atualizÃ¡-las Ã  luz da nova observaÃ§Ã£o. Acontece que esses dois mÃ©todos sÃ£o matematicamente idÃªnticos, desde que a nova observaÃ§Ã£o seja logicamente independente das observaÃ§Ãµes anteriores.

Veja como fazer isso. Primeiro, contamos o nÃºmero de maneiras que cada conjectura poderia produzir a nova observaÃ§Ã£o, ğŸ”µ. Depois multiplicamos cada uma dessas novas contagens pelos nÃºmeros a priori de maneiras para cada conjectura. Em forma de tabela:

| Conjectura | Maneiras de produzir ğŸ”µ | Contagens a priori | Nova contagem     |
|------------|-----------|--------|-------------------|
| [âšªâšªâšªâšª]   | 0         | 0      | $0 \times 0 = 0$  |
| [ğŸ”µâšªâšªâšª]   | 1         | 3      | $3 \times 1 = 3$  |
| [ğŸ”µğŸ”µâšªâšª]   | 2         | 8      | $8 \times 2 = 16$ |
| [ğŸ”µğŸ”µğŸ”µâšª]   | 3         | 9      | $9 \times 3 = 27$ |
| [ğŸ”µğŸ”µğŸ”µğŸ”µ]   | 4         | 0      | $0 \times 4 = 0$  |

As novas contagens na coluna da direita acima resumem toda a evidÃªncia para cada conjectura. Ã€ medida que novos dados chegam, e desde que esses dados sejam independentes das observaÃ§Ãµes anteriores, o nÃºmero de maneiras logicamente possÃ­veis para uma conjectura produzir todos os dados atÃ© aquele ponto pode ser calculado simplesmente multiplicando a nova contagem pela contagem antiga.

Essa abordagem de atualizaÃ§Ã£o nada mais Ã© do que afirmar que (1) quando temos informaÃ§Ã£o anterior sugerindo que hÃ¡ $W_{\rm prior}$ maneiras para uma conjectura produzir uma observaÃ§Ã£o anterior $D_{\rm prior}$ e (2) adquirimos novas observaÃ§Ãµes $D_{\rm new}$ que a mesma conjectura pode produzir de $W_{\rm new}$ maneiras, entÃ£o (3) o nÃºmero de maneiras que a conjectura pode explicar tanto $D_{\rm prior}$ quanto $D_{\rm new}$ Ã© simplesmente o produto $W_{\rm prior} \times W_{\rm new}$. Por exemplo, na tabela acima, a conjectura [ğŸ”µğŸ”µâšªâšª] tem $W_{\rm prior} = 8$ maneiras de produzir $D_{\rm prior} = ğŸ”µâšªğŸ”µ$. Ela tambÃ©m tem $W_{\rm new} = 2$ maneiras de produzir a nova observaÃ§Ã£o $D_{\rm new} = ğŸ”µ$. Portanto, hÃ¡ $8 \times 2 = 16$ maneiras para a conjectura produzir tanto $D_{\rm prior}$ quanto $D_{\rm new}$. Por que multiplicar? A multiplicaÃ§Ã£o Ã© apenas um atalho para enumerar e contar todos os caminhos pelo jardim que poderiam produzir todas as observaÃ§Ãµes.

Neste exemplo, os dados a priori e os novos dados sÃ£o do mesmo tipo: bolinhas retiradas do saco. Mas, em geral, os dados a priori e os novos dados podem ser de tipos diferentes. Suponha, por exemplo, que alguÃ©m da fÃ¡brica de bolinhas lhe diga que bolinhas azuis sÃ£o raras. EntÃ£o, para cada saco contendo [ğŸ”µğŸ”µğŸ”µâšª], eles fizeram dois sacos contendo [ğŸ”µğŸ”µâšªâšª] e trÃªs sacos contendo [ğŸ”µâšªâšªâšª]. Eles tambÃ©m garantiram que cada saco contivesse pelo menos uma bolinha azul e uma branca. Podemos atualizar nossas contagens novamente:

|  Conjectura   |  Contagem a priori  |   Contagem da fÃ¡brica   |       Nova contagem             |
|---------------|---------------------|-------------------------|---------------------------------|
| [âšªâšªâšªâšª]    | 0                   | 0                       | $0 \times 0 = 0$                |
| [ğŸ”µâšªâšªâšª]    | 3                   | 3                       | $3 \times 3 = 9$                |
| [ğŸ”µğŸ”µâšªâšª]    | 16                  | 2                       | $16 \times 2 = 32$              |
| [ğŸ”µğŸ”µğŸ”µâšª]    | 27                  | 1                       | $27 \times 1 = 27$              |
| [ğŸ”µğŸ”µğŸ”µğŸ”µ]    | 0                   | 0                       | $0 \times 0 = 0$                |

Agora a conjectura [ğŸ”µğŸ”µâšªâšª] Ã© a mais plausÃ­vel, mas apenas ligeiramente melhor que [ğŸ”µğŸ”µğŸ”µâšª]. HÃ¡ um limiar de diferenÃ§a nessas contagens no qual podemos decidir com seguranÃ§a que uma das conjecturas Ã© a correta? VocÃª passarÃ¡ o prÃ³ximo capÃ­tulo explorando essa questÃ£o.

> **Repensando: IgnorÃ¢ncia original.** Qual suposiÃ§Ã£o devemos usar quando nÃ£o hÃ¡ informaÃ§Ã£o anterior sobre as conjecturas? A soluÃ§Ã£o mais comum Ã© atribuir um nÃºmero igual de maneiras em que cada conjectura poderia estar correta, antes de ver quaisquer dados. Isso Ã© Ã s vezes conhecido como o PRINCÃPIO DA INDIFERENÃ‡A: quando nÃ£o hÃ¡ razÃ£o para dizer que uma conjectura Ã© mais plausÃ­vel que outra, pese todas as conjecturas igualmente. Este livro nÃ£o usa nem endossa distribuiÃ§Ãµes a priori de "ignorÃ¢ncia". Como veremos em capÃ­tulos posteriores, a estrutura do modelo e o contexto cientÃ­fico sempre fornecem informaÃ§Ã£o que nos permite fazer melhor do que a ignorÃ¢ncia.

Para o tipo de problemas que examinamos neste livro, o princÃ­pio da indiferenÃ§a resulta em inferÃªncias muito comparÃ¡veis Ã s abordagens nÃ£o bayesianas convencionais, a maioria das quais contÃ©m ponderaÃ§Ã£o implÃ­cita igual das possibilidades. Por exemplo, um intervalo de confianÃ§a nÃ£o bayesiano tÃ­pico pesa igualmente todos os valores possÃ­veis que um parÃ¢metro poderia assumir, independentemente de quÃ£o implausÃ­veis alguns deles sejam. AlÃ©m disso, muitos procedimentos nÃ£o bayesianos se afastaram da ponderaÃ§Ã£o igual, atravÃ©s do uso de verossimilhanÃ§a penalizada e outros mÃ©todos. Discutiremos isso no CapÃ­tulo 7.

**2.1.3. De contagens a probabilidades.** Ã‰ Ãºtil pensar nessa estratÃ©gia como aderindo a um princÃ­pio de ignorÃ¢ncia honesta: quando nÃ£o sabemos o que causou os dados, causas potenciais que podem produzir os dados de mais maneiras sÃ£o mais plausÃ­veis. Isso nos leva a contar caminhos pelo jardim de dados bifurcantes.

Ã‰ difÃ­cil usar essas contagens, porÃ©m, entÃ£o quase sempre as padronizamos de uma maneira que as transforma em probabilidades. Por que Ã© difÃ­cil trabalhar com as contagens? Primeiro, como o valor relativo Ã© tudo que importa, o tamanho das contagens 3, 8 e 9 nÃ£o contÃ©m informaÃ§Ã£o de valor. Elas poderiam ser igualmente 30, 80 e 90. O significado seria o mesmo. SÃ£o apenas os valores relativos que importam. Segundo, conforme a quantidade de dados cresce, as contagens crescerÃ£o muito rapidamente, tornando-se muito grandes e difÃ­ceis de manipular. Quando tivermos 10 pontos de dados, jÃ¡ haverÃ¡ mais de um milhÃ£o de sequÃªncias possÃ­veis. Vamos querer analisar conjuntos de dados com milhares de observaÃ§Ãµes, entÃ£o contar essas coisas explicitamente nÃ£o Ã© prÃ¡tico.

Felizmente, hÃ¡ uma maneira matemÃ¡tica de comprimir tudo isso. Especificamente, definimos a plausibilidade atualizada de cada possÃ­vel composiÃ§Ã£o do saco, apÃ³s ver os dados, como:

$$ \texttt{plausibilidade de [ğŸ”µâšªâšªâšª] apÃ³s ver ğŸ”µâšªğŸ”µ }$$
$$\propto$$
$$ \texttt{maneiras que [ğŸ”µâšªâšªâšª] pode produzir ğŸ”µâšªğŸ”µ }$$
$$\times$$
$$ \texttt{plausibilidade a priori de [ğŸ”µâšªâšªâšª] }$$

Aquele pequeno $\propto$ significa *proporcional a*. Queremos comparar a plausibilidade de cada possÃ­vel composiÃ§Ã£o do saco. EntÃ£o serÃ¡ Ãºtil definir p como a proporÃ§Ã£o de bolinhas que sÃ£o azuis. Para [ğŸ”µâšªâšªâšª], p = 1/4 = 0,25. TambÃ©m defina $D_{\text{new}} = ğŸ”µâšªğŸ”µ$. E agora podemos escrever:

> plausibilidade de p apÃ³s $D_{\text{new}} \propto \text{maneiras que } p$ pode produzir $D_{\text{new}} \times \text{plausibilidade a priori de } p$

O acima apenas significa que, para qualquer valor que p possa assumir, julgamos a plausibilidade desse valor p como proporcional ao nÃºmero de maneiras que ele pode passar pelo jardim de dados bifurcantes. Essa expressÃ£o apenas resume os cÃ¡lculos que vocÃª fez nas tabelas da seÃ§Ã£o anterior.

Finalmente, construÃ­mos probabilidades padronizando a plausibilidade de modo que a soma das plausibilidades para todas as conjecturas possÃ­veis seja um. Tudo o que vocÃª precisa fazer para padronizar Ã© somar todos os produtos, um para cada valor que p pode assumir, e depois dividir cada produto pela soma dos produtos:

$$\texttt{plausibilidade de p apÃ³s} D_{\text{new}} = \frac{\text{maneiras que } p \text{ pode produzir } D_{\text{new}} \times \text{plausibilidade a priori de } p}{\text{soma dos produtos}}$$

Um exemplo trabalhado Ã© necessÃ¡rio para que isso realmente faÃ§a sentido. EntÃ£o considere novamente a tabela de antes, agora atualizada usando nossas definiÃ§Ãµes de *p* e "plausibilidade":

| ComposiÃ§Ã£o possÃ­vel | p       | Maneiras de produzir dados | Plausibilidade |
|---------------------|---------|----------------------------|----------------|
| [âšªâšªâšªâšª]           | 0       | 0                          | 0              |
| [ğŸ”µâšªâšªâšª]           | 0,25    | 3                          | 0,15           |
| [ğŸ”µğŸ”µâšªâšª]           | 0,5     | 8                          | 0,40           |
| [ğŸ”µğŸ”µğŸ”µâšª]           | 0,75    | 9                          | 0,45           |
| [ğŸ”µğŸ”µğŸ”µğŸ”µ]           | 1       | 0                          | 0              |

VocÃª pode calcular rapidamente essas plausibilidades em R:

```r
ways <- c( 0 , 3 , 8 , 9 , 0 )
ways/sum(ways)
```

```
[1] 0.00 0.15 0.40 0.45 0.00
```

Os valores em ways sÃ£o os produtos mencionados antes. E sum(ways) Ã© o denominador "soma dos produtos" na expressÃ£o perto do topo da pÃ¡gina.

Essas plausibilidades tambÃ©m sÃ£o *probabilidades* â€” sÃ£o nÃºmeros reais nÃ£o negativos (zero ou positivos) que somam um. E todas as coisas matemÃ¡ticas que vocÃª pode fazer com probabilidades tambÃ©m pode fazer com esses valores. Especificamente, cada peÃ§a do cÃ¡lculo tem um parceiro direto na teoria da probabilidade aplicada. Esses parceiros tÃªm nomes estereotipados, entÃ£o vale a pena aprendÃª-los, pois vocÃª os verÃ¡ repetidamente.

- Um valor conjecturado da proporÃ§Ã£o de bolinhas azuis, *p*, Ã© geralmente chamado de valor de **PARÃ‚METRO**. Ã‰ apenas uma maneira de indexar explicaÃ§Ãµes possÃ­veis dos dados.
- O nÃºmero relativo de maneiras que um valor *p* pode produzir os dados Ã© geralmente chamado de **VEROSSIMILHANÃ‡A**. Ã‰ derivada enumerando todas as sequÃªncias de dados possÃ­veis que poderiam ter acontecido e depois eliminando aquelas sequÃªncias inconsistentes com os dados.
- A plausibilidade a priori de qualquer *p* especÃ­fico Ã© geralmente chamada de **PROBABILIDADE A PRIORI**.
- A nova plausibilidade atualizada de qualquer *p* especÃ­fico Ã© geralmente chamada de **PROBABILIDADE A POSTERIORI**.

Na prÃ³xima seÃ§Ã£o principal, vocÃª encontrarÃ¡ a notaÃ§Ã£o mais formal para esses objetos e verÃ¡ como eles compÃµem um modelo estatÃ­stico simples.

> **Repensando: AleatorizaÃ§Ã£o.** Quando vocÃª embaralha um baralho de cartas ou atribui sujeitos a tratamentos jogando uma moeda, Ã© comum dizer que o baralho resultante e as atribuiÃ§Ãµes de tratamento sÃ£o aleatorizados. O que significa aleatorizar algo? Significa apenas que processamos a coisa de modo que sabemos quase nada sobre seu arranjo. Embaralhar um baralho de cartas muda nosso estado de conhecimento, de modo que nÃ£o temos mais informaÃ§Ã£o especÃ­fica sobre a ordenaÃ§Ã£o das cartas. Entretanto, o bÃ´nus que surge disso Ã© que, se realmente embaralhamos o suficiente para apagar qualquer conhecimento prÃ©vio da ordenaÃ§Ã£o, entÃ£o a ordem em que as cartas terminam Ã© muito provavelmente uma das muitas ordenaÃ§Ãµes com alta **entropia informacional**. O conceito de entropia informacional serÃ¡ cada vez mais importante conforme avanÃ§amos, e serÃ¡ detalhado nos CapÃ­tulos 7 e 10.

## 2.2. Construindo um modelo
Ao trabalhar com probabilidades em vez de contagens brutas, a inferÃªncia bayesiana se torna muito mais fÃ¡cil, mas parece muito mais difÃ­cil. EntÃ£o, nesta seÃ§Ã£o, damos sequÃªncia ao jardim de dados bifurcantes apresentando a forma convencional de um modelo estatÃ­stico bayesiano. O exemplo didÃ¡tico que usaremos aqui tem a anatomia de uma anÃ¡lise estatÃ­stica tÃ­pica, entÃ£o Ã© o estilo ao qual vocÃª se acostumarÃ¡. Mas cada peÃ§a dele pode ser mapeada no jardim de dados bifurcantes. A lÃ³gica Ã© a mesma.

Suponha que vocÃª tenha um globo terrestre representando nosso planeta, a Terra. Essa versÃ£o do mundo Ã© pequena o suficiente para caber em suas mÃ£os. VocÃª tem curiosidade sobre quanta da superfÃ­cie Ã© coberta por Ã¡gua. VocÃª adota a seguinte estratÃ©gia: jogarÃ¡ o globo para cima. Quando pegÃ¡-lo, registrarÃ¡ se a superfÃ­cie sob seu dedo indicador direito Ã© Ã¡gua ou terra. EntÃ£o jogarÃ¡ o globo para cima novamente e repetirÃ¡ o procedimento.$^{43}$ Essa estratÃ©gia gera uma sequÃªncia de amostras da superfÃ­cie do globo. As primeiras nove amostras podem parecer com:

$$\text{W L W W W L W L W}$$

onde $\text{W}$ indica Ã¡gua (water) e $\text{L}$ indica terra (land). EntÃ£o, neste exemplo, vocÃª observa seis observaÃ§Ãµes $\text{W}$ (Ã¡gua) e trÃªs observaÃ§Ãµes $\text{L}$ (terra). Chame essa sequÃªncia de observaÃ§Ãµes de dados.

Para colocar a lÃ³gica em movimento, precisamos fazer suposiÃ§Ãµes, e essas suposiÃ§Ãµes constituem o modelo. Projetar um modelo bayesiano simples se beneficia de um ciclo de design com trÃªs etapas.

- (1) HistÃ³ria dos dados: motive o modelo narrando como os dados podem ter surgido.
- (2) AtualizaÃ§Ã£o: eduque seu modelo alimentando-o com os dados.
- (3) AvaliaÃ§Ã£o: todos os modelos estatÃ­sticos requerem supervisÃ£o, levando possivelmente Ã  revisÃ£o do modelo.

As prÃ³ximas seÃ§Ãµes percorrem essas etapas, no contexto da evidÃªncia do lanÃ§amento do globo.

**2.2.1. Uma histÃ³ria dos dados.** A anÃ¡lise bayesiana de dados geralmente significa produzir uma histÃ³ria para como os dados vieram a existir. Essa histÃ³ria pode ser descritiva, especificando associaÃ§Ãµes que podem ser usadas para prever resultados, dadas observaÃ§Ãµes. Ou pode ser causal, uma teoria de como alguns eventos produzem outros eventos. Tipicamente, qualquer histÃ³ria que vocÃª pretenda ser causal tambÃ©m pode ser descritiva. Mas muitas histÃ³rias descritivas sÃ£o difÃ­ceis de interpretar causalmente. Contudo, todas as histÃ³rias de dados sÃ£o completas, no sentido de que sÃ£o suficientes para especificar um algoritmo para simular novos dados. No prÃ³ximo capÃ­tulo, vocÃª verÃ¡ exemplos de como fazer exatamente isso, pois simular novos dados Ã© Ãºtil nÃ£o apenas para crÃ­tica de modelos, mas tambÃ©m para construÃ§Ã£o de modelos.

VocÃª pode motivar sua histÃ³ria dos dados tentando explicar como cada dado nasce. Isso geralmente significa descrever aspectos da realidade subjacente, bem como o processo de amostragem. A histÃ³ria dos dados neste caso Ã© simplesmente uma reformulaÃ§Ã£o do processo de amostragem:

- (1) A verdadeira proporÃ§Ã£o de Ã¡gua cobrindo o globo Ã© $p$.
- (2) Um Ãºnico lanÃ§amento do globo tem probabilidade $p$ de produzir uma observaÃ§Ã£o de Ã¡gua ($\text{W}$). Tem probabilidade $1-p$ de produzir uma observaÃ§Ã£o de terra ($\text{L}$).
- (3) Cada lanÃ§amento do globo Ã© independente dos outros.

A histÃ³ria dos dados Ã© entÃ£o traduzida em um modelo formal de probabilidade. Esse modelo de probabilidade Ã© fÃ¡cil de construir, porque o processo de construÃ§Ã£o pode ser utilmente decomposto em uma sÃ©rie de decisÃµes componentes. Antes de conhecer esses componentes, contudo, serÃ¡ Ãºtil visualizar como um modelo bayesiano se comporta. Depois que vocÃª se familiarizar com como um modelo aprende a partir de dados, abriremos a mÃ¡quina e investigaremos sua engenharia.

> **Repensando: O valor de contar histÃ³rias.** A histÃ³ria dos dados tem valor, mesmo que vocÃª rapidamente a abandone e nunca a use para construir um modelo ou simular novas observaÃ§Ãµes. De fato, Ã© importante eventualmente descartar a histÃ³ria, porque muitas histÃ³rias diferentes sempre correspondem ao mesmo modelo. Como resultado, mostrar que um modelo faz um bom trabalho nÃ£o apoia unicamente nossa histÃ³ria dos dados. Ainda assim, a histÃ³ria tem valor porque, ao tentar delinear a histÃ³ria, frequentemente percebe-se que perguntas adicionais devem ser respondidas. A maioria das histÃ³rias de dados Ã© muito mais especÃ­fica do que as hipÃ³teses verbais que inspiram a coleta de dados. As hipÃ³teses podem ser vagas, como "Ã© mais provÃ¡vel chover em dias quentes." Quando vocÃª Ã© forÃ§ado a considerar amostragem e mensuraÃ§Ã£o e fazer uma declaraÃ§Ã£o precisa de como a temperatura prevÃª a chuva, muitas histÃ³rias e modelos resultantes serÃ£o consistentes com a mesma hipÃ³tese vaga. Resolver essa ambiguidade frequentemente leva a percepÃ§Ãµes importantes e revisÃµes de modelo, antes que qualquer modelo seja ajustado aos dados.

**2.2.2. AtualizaÃ§Ã£o bayesiana.** Nosso problema Ã© usar a evidÃªncia â€” a sequÃªncia de lanÃ§amentos do globo â€” para decidir entre diferentes proporÃ§Ãµes possÃ­veis de Ã¡gua no globo. Essas proporÃ§Ãµes sÃ£o como as bolinhas conjecturadas dentro do saco, de antes neste capÃ­tulo. Cada proporÃ§Ã£o possÃ­vel pode ser mais ou menos plausÃ­vel, dada a evidÃªncia. Um modelo bayesiano comeÃ§a com um conjunto de plausibilidades atribuÃ­das a cada uma dessas possibilidades. Essas sÃ£o as plausibilidades a priori. EntÃ£o ele as atualiza Ã  luz dos dados, para produzir as plausibilidades a posteriori. Esse processo de atualizaÃ§Ã£o Ã© um tipo de aprendizado, chamado **atualizaÃ§Ã£o bayesiana**. Os detalhes dessa atualizaÃ§Ã£o â€” como ela Ã© mecanicamente alcanÃ§ada â€” podem esperar atÃ© mais adiante neste capÃ­tulo. Por ora, vejamos apenas como tal mÃ¡quina se comporta.

Apenas para efeito do exemplo, vamos programar nossa mÃ¡quina bayesiana para atribuir inicialmente a mesma plausibilidade a cada proporÃ§Ã£o de Ã¡gua, cada valor de p. Depois faremos melhor que isso. Agora olhe o grÃ¡fico superior esquerdo na Figura 2.5. A linha horizontal tracejada representa essa plausibilidade inicial de cada valor possÃ­vel de p. ApÃ³s ver o primeiro lanÃ§amento, que Ã© um "W", o modelo atualiza as plausibilidades para a linha sÃ³lida. A plausibilidade de p = 0 caiu agora para exatamente zero â€” o equivalente a "impossÃ­vel". Por quÃª? Porque observamos pelo menos uma parcela de Ã¡gua no globo, entÃ£o agora sabemos que hÃ¡ alguma Ã¡gua. O modelo executa essa lÃ³gica automaticamente. VocÃª nÃ£o precisa instruÃ­-lo a considerar essa consequÃªncia. A teoria da probabilidade cuida disso para vocÃª, porque Ã© essencialmente contagem de caminhos pelo jardim de dados bifurcantes, como na seÃ§Ã£o anterior.

Da mesma forma, a plausibilidade de p > 0,5 aumentou. Isso ocorre porque ainda nÃ£o hÃ¡ evidÃªncia de que haja terra no globo, entÃ£o as plausibilidades iniciais sÃ£o modificadas para serem consistentes com isso. Note, entretanto, que sÃ£o as plausibilidades relativas que importam, e ainda nÃ£o hÃ¡

![](_page_11_Figure_2.jpeg)

Figura 2.5. Como um modelo bayesiano aprende. Cada lanÃ§amento do globo produz uma observaÃ§Ã£o de Ã¡gua (W) ou terra (L). A estimativa do modelo da proporÃ§Ã£o de Ã¡gua no globo Ã© uma plausibilidade para cada valor possÃ­vel. As linhas e curvas nesta figura sÃ£o essas coleÃ§Ãµes de plausibilidades. Em cada grÃ¡fico, plausibilidades anteriores (curva tracejada) sÃ£o atualizadas Ã  luz da Ãºltima observaÃ§Ã£o para produzir um novo conjunto de plausibilidades (curva sÃ³lida).

muita evidÃªncia. Portanto, as diferenÃ§as em plausibilidade ainda nÃ£o sÃ£o muito grandes. Dessa forma, a quantidade de evidÃªncia vista atÃ© agora Ã© incorporada nas plausibilidades de cada valor de p.

Nos grÃ¡ficos restantes da Figura 2.5, as amostras adicionais do globo sÃ£o introduzidas ao modelo, uma de cada vez. Cada curva tracejada Ã© simplesmente a curva sÃ³lida do grÃ¡fico anterior, movendo-se da esquerda para a direita e de cima para baixo. Toda vez que um "W" Ã© visto, o pico da curva de plausibilidade se move para a direita, em direÃ§Ã£o a valores maiores de p. Toda vez que um "L" Ã© visto, ela se move

na outra direÃ§Ã£o. A altura mÃ¡xima da curva aumenta com cada amostra, significando que menos valores de p acumulam mais plausibilidade conforme a quantidade de evidÃªncia aumenta. Conforme cada nova observaÃ§Ã£o Ã© adicionada, a curva Ã© atualizada de maneira consistente com todas as observaÃ§Ãµes anteriores.

Note que cada conjunto atualizado de plausibilidades se torna as plausibilidades iniciais para a prÃ³xima observaÃ§Ã£o. Toda conclusÃ£o Ã© o ponto de partida para inferÃªncia futura. Contudo, esse processo de atualizaÃ§Ã£o funciona tanto para trÃ¡s quanto para frente. Dado o conjunto final de plausibilidades no grÃ¡fico inferior direito da Figura 2.5, e sabendo a observaÃ§Ã£o final (W), Ã© possÃ­vel matematicamente dividir a observaÃ§Ã£o, para inferir a curva de plausibilidade anterior. EntÃ£o os dados poderiam ser apresentados ao seu modelo em qualquer ordem, ou todos de uma vez. Na maioria dos casos, vocÃª apresentarÃ¡ os dados todos de uma vez, por conveniÃªncia. Mas Ã© importante perceber que isso meramente representa a abreviaÃ§Ã£o de um processo iterativo de aprendizado.

> **Repensando: Tamanho amostral e inferÃªncia confiÃ¡vel.** Ã‰ comum ouvir que hÃ¡ um nÃºmero mÃ­nimo de observaÃ§Ãµes para uma estimativa estatÃ­stica Ãºtil. Por exemplo, hÃ¡ uma superstiÃ§Ã£o difundida de que 30 observaÃ§Ãµes sÃ£o necessÃ¡rias antes de se poder usar uma distribuiÃ§Ã£o gaussiana. Por quÃª? Na inferÃªncia estatÃ­stica nÃ£o bayesiana, os procedimentos sÃ£o frequentemente justificados pelo comportamento do mÃ©todo com tamanhos amostrais muito grandes, o chamado comportamento assintÃ³tico. Como resultado, o desempenho com tamanhos amostrais pequenos Ã© questionÃ¡vel.

Em contraste, estimativas bayesianas sÃ£o vÃ¡lidas para qualquer tamanho amostral. Isso nÃ£o significa que mais dados nÃ£o ajudem â€” certamente ajudam. Em vez disso, as estimativas tÃªm uma interpretaÃ§Ã£o clara e vÃ¡lida, independentemente do tamanho amostral. Mas o preÃ§o desse poder Ã© a dependÃªncia das plausibilidades iniciais, a distribuiÃ§Ã£o a priori. Se a distribuiÃ§Ã£o a priori for ruim, a inferÃªncia resultante serÃ¡ enganosa. NÃ£o hÃ¡ almoÃ§o grÃ¡tis,$^{44}$ quando se trata de aprender sobre o mundo. Um golem bayesiano deve escolher uma plausibilidade inicial, e um golem nÃ£o bayesiano deve escolher um estimador. Ambos os golems pagam pelo almoÃ§o com suas suposiÃ§Ãµes.

**2.2.3. AvaliaÃ§Ã£o.** O modelo bayesiano aprende de uma maneira que Ã© comprovadamente Ã³tima, desde que o mundo real, o mundo grande, seja descrito com precisÃ£o pelo modelo. Ou seja, sua mÃ¡quina bayesiana garante inferÃªncia perfeita, dentro do mundo pequeno. Nenhuma outra maneira de usar a informaÃ§Ã£o disponÃ­vel, e comeÃ§ando com o mesmo estado de informaÃ§Ã£o, poderia fazer melhor.

NÃ£o fique muito empolgado com essa virtude lÃ³gica, contudo. Os cÃ¡lculos podem falhar, entÃ£o os resultados sempre precisam ser verificados. E se houver diferenÃ§as importantes entre o modelo e a realidade, entÃ£o nÃ£o hÃ¡ garantia lÃ³gica de desempenho no mundo grande. E mesmo que os dois mundos coincidissem, qualquer amostra particular de dados poderia ainda ser enganosa. EntÃ£o vale a pena manter em mente pelo menos dois princÃ­pios cautelosos.

Primeiro, a certeza do modelo nÃ£o Ã© garantia de que o modelo Ã© bom. Conforme a quantidade de dados aumenta, o modelo de lanÃ§amento do globo ficarÃ¡ cada vez mais seguro da proporÃ§Ã£o de Ã¡gua. Isso significa que as curvas na Figura 2.5 se tornarÃ£o cada vez mais estreitas e altas, restringindo valores plausÃ­veis dentro de uma faixa muito estreita. Mas modelos de todos os tipos â€” bayesianos ou nÃ£o â€” podem ser muito confiantes sobre uma inferÃªncia, mesmo quando o modelo Ã© seriamente enganoso. Isso ocorre porque as inferÃªncias sÃ£o condicionais ao modelo. O que seu modelo lhe diz Ã© que, dado um compromisso com esse modelo especÃ­fico, ele pode estar muito seguro de que os valores plausÃ­veis estÃ£o em uma faixa estreita. Sob um modelo diferente, as coisas podem parecer diferentes. HaverÃ¡ exemplos em capÃ­tulos posteriores.

Segundo, Ã© importante supervisionar e criticar o trabalho do seu modelo. Considere novamente o fato de que a atualizaÃ§Ã£o na seÃ§Ã£o anterior funciona em qualquer ordem de chegada dos dados. PoderÃ­amos embaralhar a ordem das observaÃ§Ãµes, contanto que seis W's e trÃªs L's permaneÃ§am, e ainda terminar com a mesma curva de plausibilidade final. Isso sÃ³ Ã© verdade, contudo, porque o modelo assume que a ordem Ã© irrelevante para a inferÃªncia. Quando algo Ã© irrelevante para a mÃ¡quina, nÃ£o afetarÃ¡ a inferÃªncia diretamente. Mas pode afetÃ¡-la indiretamente, porque os dados dependerÃ£o da ordem. EntÃ£o Ã© importante verificar as inferÃªncias do modelo Ã  luz de aspectos dos dados que ele nÃ£o conhece. Tais verificaÃ§Ãµes sÃ£o um empreendimento inerentemente criativo, deixado para o analista e a comunidade cientÃ­fica. Golems sÃ£o muito ruins nisso.

No CapÃ­tulo 3, vocÃª verÃ¡ alguns exemplos de tais verificaÃ§Ãµes. Por ora, note que o objetivo nÃ£o Ã© testar o valor de verdade das suposiÃ§Ãµes do modelo. Sabemos que as suposiÃ§Ãµes do modelo nunca sÃ£o exatamente corretas, no sentido de corresponder ao verdadeiro processo gerador de dados. Portanto, nÃ£o hÃ¡ motivo para verificar se o modelo Ã© verdadeiro. A falha em concluir que um modelo Ã© falso deve ser uma falha de nossa imaginaÃ§Ã£o, nÃ£o um sucesso do modelo. AlÃ©m disso, modelos nÃ£o precisam ser exatamente verdadeiros para produzir inferÃªncias altamente precisas e Ãºteis. Todos os tipos de suposiÃ§Ãµes de mundo pequeno sobre distribuiÃ§Ãµes de erro e similares podem ser violados no mundo grande, mas um modelo pode ainda produzir uma estimativa perfeitamente Ãºtil. Isso ocorre porque modelos sÃ£o essencialmente mÃ¡quinas de processamento de informaÃ§Ã£o, e hÃ¡ alguns aspectos surpreendentes da informaÃ§Ã£o que nÃ£o podem ser facilmente capturados ao enquadrar o problema em termos da verdade das suposiÃ§Ãµes.$^{45}$

Em vez disso, o objetivo Ã© verificar a adequaÃ§Ã£o do modelo para algum propÃ³sito. Isso geralmente significa fazer e responder perguntas adicionais, alÃ©m daquelas que originalmente construÃ­ram o modelo. Tanto as perguntas quanto as respostas dependerÃ£o do contexto cientÃ­fico. EntÃ£o Ã© difÃ­cil fornecer conselhos gerais. HaverÃ¡ muitos exemplos ao longo do livro, e Ã© claro que a literatura cientÃ­fica estÃ¡ repleta de avaliaÃ§Ãµes da adequaÃ§Ã£o de modelos para diferentes trabalhos â€” prediÃ§Ã£o, compreensÃ£o, mensuraÃ§Ã£o e persuasÃ£o.

> **Repensando: EstatÃ­stica deflacionÃ¡ria.** Pode ser que a inferÃªncia bayesiana seja o melhor mÃ©todo de inferÃªncia de propÃ³sito geral conhecido. Contudo, a inferÃªncia bayesiana Ã© muito menos poderosa do que gostarÃ­amos que fosse. NÃ£o hÃ¡ abordagem Ã  inferÃªncia que forneÃ§a garantias universais. Nenhum ramo da matemÃ¡tica aplicada tem acesso irrestrito Ã  realidade, porque a matemÃ¡tica nÃ£o Ã© descoberta, como o prÃ³ton. Em vez disso, ela Ã© inventada, como a pÃ¡.$^{46}$

## 2.3. Componentes do modelo

Agora que vocÃª viu como o modelo bayesiano se comporta, Ã© hora de abrir a mÃ¡quina e aprender como ela funciona. Considere trÃªs tipos diferentes de coisas que contamos nas seÃ§Ãµes anteriores.

- (1) O nÃºmero de maneiras que cada conjectura poderia produzir uma observaÃ§Ã£o
- (2) O nÃºmero acumulado de maneiras que cada conjectura poderia produzir os dados inteiros
- (3) A plausibilidade inicial de cada causa conjecturada dos dados

Cada uma dessas coisas tem um anÃ¡logo direto na teoria da probabilidade convencional. E assim, a maneira usual de construir um modelo estatÃ­stico envolve escolher distribuiÃ§Ãµes e dispositivos para cada uma que representem os nÃºmeros relativos de maneiras que as coisas podem acontecer.

Nesta seÃ§Ã£o, vocÃª conhecerÃ¡ esses componentes em algum detalhe e verÃ¡ como cada um se relaciona com a contagem que vocÃª fez anteriormente no capÃ­tulo. A tarefa diante de nÃ³s Ã© realmente nada mais do que nomear todas as variÃ¡veis e definir cada uma. Faremos essas tarefas em sequÃªncia.

**2.3.1. VariÃ¡veis.** VariÃ¡veis sÃ£o simplesmente sÃ­mbolos que podem assumir diferentes valores. Em um contexto cientÃ­fico, variÃ¡veis incluem coisas que desejamos inferir, como proporÃ§Ãµes e taxas, bem como coisas que podemos observar, os dados. No modelo de lanÃ§amento do globo, hÃ¡ trÃªs variÃ¡veis.

A primeira variÃ¡vel Ã© nosso alvo de inferÃªncia, p, a proporÃ§Ã£o de Ã¡gua no globo. Essa variÃ¡vel nÃ£o pode ser observada. VariÃ¡veis nÃ£o observadas sÃ£o geralmente chamadas de **parÃ¢metros**. Mas, embora p em si nÃ£o seja observado, podemos inferi-lo a partir das outras variÃ¡veis.

As outras variÃ¡veis sÃ£o as variÃ¡veis observadas, as contagens de Ã¡gua e terra. Chame a contagem de Ã¡gua de W e a contagem de terra de L. A soma dessas duas variÃ¡veis Ã© o nÃºmero de lanÃ§amentos do globo: N = W + L.

**2.3.2. DefiniÃ§Ãµes.** Uma vez que temos as variÃ¡veis listadas, precisamos definir cada uma delas. Ao definir cada uma, construÃ­mos um modelo que relaciona as variÃ¡veis umas Ã s outras. Lembre-se, o objetivo Ã© contar todas as maneiras que os dados poderiam surgir, dadas as suposiÃ§Ãµes. Isso significa, como no modelo de lanÃ§amento do globo, que para cada valor possÃ­vel das variÃ¡veis nÃ£o observadas, como p, precisamos definir o nÃºmero relativo de maneiras â€” a probabilidade â€” que os valores de cada variÃ¡vel observada poderiam surgir. E entÃ£o, para cada variÃ¡vel nÃ£o observada, precisamos definir a plausibilidade a priori de cada valor que ela poderia assumir. ReconheÃ§o que tudo isso Ã© um pouco abstrato. EntÃ£o aqui estÃ£o os detalhes, para o globo.

2.3.2.1. *VariÃ¡veis observadas*. Para a contagem de Ã¡gua W e terra L, definimos quÃ£o plausÃ­vel qualquer combinaÃ§Ã£o de W e L seria, para um valor especÃ­fico de p. Isso Ã© muito parecido com a contagem de bolinhas que fizemos anteriormente no capÃ­tulo. Cada valor especÃ­fico de p corresponde a uma plausibilidade especÃ­fica dos dados, como na Figura 2.5.

Para que nÃ£o tenhamos que literalmente contar, podemos usar uma funÃ§Ã£o matemÃ¡tica que nos diz a plausibilidade correta. Na estatÃ­stica convencional, uma funÃ§Ã£o de distribuiÃ§Ã£o atribuÃ­da a uma variÃ¡vel observada Ã© geralmente chamada de **verossimilhanÃ§a**. Esse termo tem significado especial na estatÃ­stica nÃ£o bayesiana, contudo. Seremos capazes de fazer coisas com nossas distribuiÃ§Ãµes que modelos nÃ£o bayesianos proÃ­bem. EntÃ£o tentarei evitar o termo verossimilhanÃ§a, apenas para evitar confundi-lo. Mas quando alguÃ©m diz "verossimilhanÃ§a", geralmente quer dizer uma funÃ§Ã£o de distribuiÃ§Ã£o atribuÃ­da a uma variÃ¡vel observada.

No caso do modelo de lanÃ§amento do globo, a funÃ§Ã£o que precisamos pode ser derivada diretamente da histÃ³ria dos dados. Comece nomeando todos os eventos possÃ­veis. HÃ¡ dois: Ã¡gua (W) e terra (L). NÃ£o hÃ¡ outros eventos. O globo nunca fica preso no teto, por exemplo. Quando observamos uma amostra de W's e L's de comprimento N (nove na amostra real), precisamos dizer quÃ£o provÃ¡vel Ã© essa amostra exata, dentre o universo de amostras potenciais do mesmo comprimento. Isso pode soar desafiador, mas Ã© o tipo de coisa em que vocÃª fica bom muito rapidamente, uma vez que comeÃ§a a praticar.

Neste caso, uma vez que adicionamos nossas suposiÃ§Ãµes de que (1) cada lanÃ§amento Ã© independente dos outros e (2) a probabilidade de W Ã© a mesma em cada lanÃ§amento, a teoria da probabilidade fornece uma resposta Ãºnica, conhecida como distribuiÃ§Ã£o binomial. Esta Ã© a distribuiÃ§Ã£o comum de "lanÃ§amento de moeda". E assim a probabilidade de observar W Ã¡guas e L terras, com probabilidade p de Ã¡gua em cada lanÃ§amento, Ã©:

$$\Pr(W, L|p) = \frac{(W+L)!}{W!L!} p^{W} (1-p)^{L}$$

Leia o acima como:

> *As contagens de "Ã¡gua" W e "terra" L sÃ£o distribuÃ­das binomialmente, com probabilidade p de "Ã¡gua" em cada lanÃ§amento.*

E a fÃ³rmula da distribuiÃ§Ã£o binomial estÃ¡ embutida no R, entÃ£o vocÃª pode facilmente calcular a verossimilhanÃ§a dos dados â€” seis W's em nove lanÃ§amentos â€” sob qualquer valor de p com:

```r
dbinom( 6 , size=9 , prob=0.5 )
```

```
[1] 0.1640625
```

Esse nÃºmero Ã© o nÃºmero relativo de maneiras de obter seis Ã¡guas, mantendo p em 0,5 e $N = W + L$ em nove. EntÃ£o ele faz o trabalho de contar o nÃºmero relativo de caminhos pelo jardim. Mude o 0,5 para qualquer outro valor, para ver como o valor muda.

Muito mais adiante no livro, no CapÃ­tulo 10, veremos que a distribuiÃ§Ã£o binomial Ã© bastante especial, porque ela representa a maneira de **MÃXIMA ENTROPIA** de contar eventos binÃ¡rios. "MÃ¡xima entropia" pode soar como algo ruim. Entropia nÃ£o Ã© desordem? "MÃ¡xima entropia" nÃ£o significa a morte do universo? Na verdade, significa que a distribuiÃ§Ã£o nÃ£o contÃ©m informaÃ§Ã£o adicional alÃ©m de: hÃ¡ dois eventos, e as probabilidades de cada um em cada tentativa sÃ£o p e 1-p. O CapÃ­tulo 10 explica isso em mais detalhes, e os detalhes certamente podem esperar.

> [!NOTE]
> **Pensando Mais um Pouco: Nomes e distribuiÃ§Ãµes de probabilidade.** O "d" em `dbinom` significa *densidade*. FunÃ§Ãµes nomeadas assim quase sempre tÃªm parceiras correspondentes que comeÃ§am com "r" para amostras aleatÃ³rias e que comeÃ§am com "p" para probabilidades acumuladas. Veja, por exemplo, a ajuda `?dbinom`.

> **Repensando: Um papel central para a verossimilhanÃ§a.** Uma grande quantidade de tinta foi derramada focando em como anÃ¡lises de dados bayesianas e nÃ£o bayesianas diferem. Focar nas diferenÃ§as Ã© Ãºtil, mas Ã s vezes nos distrai de similaridades fundamentais. Notavelmente, as suposiÃ§Ãµes mais influentes tanto em modelos bayesianos quanto em muitos modelos nÃ£o bayesianos sÃ£o as distribuiÃ§Ãµes atribuÃ­das aos dados, as funÃ§Ãµes de verossimilhanÃ§a. As verossimilhanÃ§as influenciam a inferÃªncia para cada dado, e conforme o tamanho amostral aumenta, a verossimilhanÃ§a importa cada vez mais. Isso ajuda a explicar por que inferÃªncias bayesianas e nÃ£o bayesianas sÃ£o frequentemente tÃ£o similares. Se tivÃ©ssemos que definir "bayesiano" usando apenas um aspecto, deverÃ­amos descrever a verossimilhanÃ§a, nÃ£o as distribuiÃ§Ãµes a priori.

2.3.2.2. *VariÃ¡veis nÃ£o observadas*. As distribuiÃ§Ãµes que atribuÃ­mos Ã s variÃ¡veis observadas tipicamente tÃªm suas prÃ³prias variÃ¡veis. Na binomial acima, hÃ¡ p, a probabilidade de amostrar Ã¡gua. Como p nÃ£o Ã© observado, geralmente o chamamos de **PARÃ‚METRO**. Embora nÃ£o possamos observar p, ainda precisamos defini-lo.

Em capÃ­tulos futuros, haverÃ¡ mais parÃ¢metros em seus modelos. Na modelagem estatÃ­stica, muitas das perguntas mais comuns que fazemos sobre dados sÃ£o respondidas diretamente por parÃ¢metros:

- Qual Ã© a diferenÃ§a mÃ©dia entre grupos de tratamento?
- QuÃ£o forte Ã© a associaÃ§Ã£o entre um tratamento e um resultado?
- O efeito do tratamento depende de uma covariÃ¡vel?
- Quanta variaÃ§Ã£o hÃ¡ entre grupos?

VocÃª verÃ¡ como essas perguntas se tornam parÃ¢metros extras dentro da funÃ§Ã£o de distribuiÃ§Ã£o que atribuÃ­mos aos dados.

Para cada parÃ¢metro que vocÃª pretende que sua mÃ¡quina bayesiana considere, vocÃª deve fornecer uma distribuiÃ§Ã£o de plausibilidade a priori, sua **DISTRIBUIÃ‡ÃƒO A PRIORI**. Uma mÃ¡quina bayesiana deve ter uma atribuiÃ§Ã£o inicial de plausibilidade para cada valor possÃ­vel do parÃ¢metro, e essas atribuiÃ§Ãµes iniciais fazem trabalho Ãºtil. Quando vocÃª tem uma estimativa anterior para fornecer Ã  mÃ¡quina, ela pode se tornar a distribuiÃ§Ã£o a priori, como nos passos da Figura 2.5. Na Figura 2.5, a mÃ¡quina fez seu aprendizado um dado de cada vez. Como resultado, cada estimativa se torna a distribuiÃ§Ã£o a priori para o prÃ³ximo passo. Mas isso

nÃ£o resolve o problema de fornecer uma distribuiÃ§Ã£o a priori, porque no inÃ­cio dos tempos, quando N = 0, a mÃ¡quina ainda tinha um estado inicial de informaÃ§Ã£o para o parÃ¢metro p: uma linha plana especificando plausibilidade igual para cada valor possÃ­vel.

EntÃ£o, de onde vÃªm as distribuiÃ§Ãµes a priori? Elas sÃ£o tanto suposiÃ§Ãµes de engenharia, escolhidas para ajudar a mÃ¡quina a aprender, quanto suposiÃ§Ãµes cientÃ­ficas, escolhidas para refletir o que sabemos sobre um fenÃ´meno. A distribuiÃ§Ã£o a priori plana na Figura 2.5 Ã© muito comum, mas raramente Ã© a melhor distribuiÃ§Ã£o a priori. CapÃ­tulos posteriores focarÃ£o muito mais na escolha da distribuiÃ§Ã£o a priori.

HÃ¡ uma escola de inferÃªncia bayesiana que enfatiza a escolha de distribuiÃ§Ãµes a priori com base nas crenÃ§as pessoais do analista.$^{47}$ Embora essa abordagem **BAYESIANA SUBJETIVA** prospere em alguns programas de estatÃ­stica, filosofia e economia, ela Ã© rara nas ciÃªncias. Dentro da anÃ¡lise bayesiana de dados nas ciÃªncias naturais e sociais, a distribuiÃ§Ã£o a priori Ã© considerada apenas parte do modelo. Como tal, ela deve ser escolhida, avaliada e revisada assim como todos os outros componentes do modelo. Na prÃ¡tica, o subjetivista e o nÃ£o subjetivista frequentemente analisarÃ£o dados de maneira quase idÃªntica.

Nada disso deve ser entendido como significando que qualquer anÃ¡lise estatÃ­stica nÃ£o Ã© inerentemente subjetiva, porque Ã© claro que Ã© â€” muitas pequenas decisÃµes subjetivas estÃ£o envolvidas em todas as partes da ciÃªncia. Ã‰ apenas que distribuiÃ§Ãµes a priori e anÃ¡lise bayesiana de dados nÃ£o sÃ£o mais inerentemente subjetivas do que verossimilhanÃ§as e as suposiÃ§Ãµes de amostragem repetida necessÃ¡rias para testes de significÃ¢ncia.$^{48}$ Qualquer pessoa que tenha visitado um plantÃ£o de estatÃ­stica em uma universidade provavelmente jÃ¡ experimentou essa subjetividade â€” estatÃ­sticos geralmente nÃ£o concordam exatamente sobre como analisar qualquer coisa alÃ©m dos problemas mais simples. O fato de que a inferÃªncia estatÃ­stica usa matemÃ¡tica nÃ£o implica que haja apenas uma maneira razoÃ¡vel ou Ãºtil de conduzir uma anÃ¡lise. A engenharia tambÃ©m usa matemÃ¡tica, mas hÃ¡ muitas maneiras de construir uma ponte.

AlÃ©m de tudo acima, nÃ£o hÃ¡ lei mandando que usemos apenas uma distribuiÃ§Ã£o a priori. Se vocÃª nÃ£o tem um argumento forte para nenhuma distribuiÃ§Ã£o a priori particular, entÃ£o tente diferentes. Porque a distribuiÃ§Ã£o a priori Ã© uma suposiÃ§Ã£o, ela deve ser interrogada como outras suposiÃ§Ãµes: alterando-a e verificando quÃ£o sensÃ­vel a inferÃªncia Ã© Ã  suposiÃ§Ã£o. NinguÃ©m Ã© obrigado a jurar um compromisso com as suposiÃ§Ãµes de um modelo, e nenhum conjunto de suposiÃ§Ãµes merece nossa obediÃªncia.

> [!NOTE]
> **Pensando Mais um Pouco: A distribuiÃ§Ã£o a priori como distribuiÃ§Ã£o de probabilidade.** VocÃª poderia escrever a distribuiÃ§Ã£o a priori no exemplo aqui como:
>
>$$\Pr(p) = \frac{1}{1-0} = 1.$$
>
>A distribuiÃ§Ã£o a priori Ã© uma distribuiÃ§Ã£o de probabilidade para o parÃ¢metro. Em geral, para uma distribuiÃ§Ã£o a priori uniforme de a atÃ© b, a probabilidade de qualquer ponto no intervalo Ã© 1/(b-a). Se vocÃª estÃ¡ incomodado pelo fato de que a probabilidade de cada valor de p Ã© 1, lembre-se de que toda distribuiÃ§Ã£o de probabilidade deve somar (integrar) para 1. A expressÃ£o 1/(b-a) garante que a Ã¡rea sob a linha plana de a atÃ© b Ã© igual a 1. HaverÃ¡ mais a dizer sobre isso no CapÃ­tulo 4.

> **Repensando: Dado ou parÃ¢metro?** Ã‰ tÃ­pico conceber dados e parÃ¢metros como tipos de entidades completamente diferentes. Dados sÃ£o mensurados e conhecidos; parÃ¢metros sÃ£o desconhecidos e devem ser estimados a partir dos dados. Utilmente, no framework bayesiano, a distinÃ§Ã£o entre um dado e um parÃ¢metro nÃ£o Ã© tÃ£o fundamental. Ã€s vezes observamos uma variÃ¡vel, mas Ã s vezes nÃ£o. Nesse caso, a mesma funÃ§Ã£o de distribuiÃ§Ã£o se aplica, mesmo que nÃ£o tenhamos observado a variÃ¡vel. Como resultado, a mesma suposiÃ§Ã£o pode parecer uma "verossimilhanÃ§a" ou uma "distribuiÃ§Ã£o a priori", dependendo do contexto, sem qualquer mudanÃ§a no modelo. Muito mais adiante no livro (CapÃ­tulo 15), vocÃª verÃ¡ como explorar essa identidade profunda

entre certeza (dados) e incerteza (parÃ¢metros) para incorporar erro de mensuraÃ§Ã£o e dados faltantes em sua modelagem.

> **Repensando: A priori, a priori, calÃ§as em chamas.** Historicamente, alguns oponentes da inferÃªncia bayesiana objetaram Ã  arbitrariedade das distribuiÃ§Ãµes a priori. Ã‰ verdade que as distribuiÃ§Ãµes a priori sÃ£o muito flexÃ­veis, sendo capazes de codificar muitos estados diferentes de informaÃ§Ã£o. Se a distribuiÃ§Ã£o a priori pode ser qualquer coisa, nÃ£o Ã© possÃ­vel obter qualquer resposta que se queira? De fato, Ã©. Independentemente disso, apÃ³s uns duzentos anos de cÃ¡lculo bayesiano, nÃ£o aconteceu de as pessoas usarem distribuiÃ§Ãµes a priori para mentir. Se seu objetivo Ã© mentir com estatÃ­stica, vocÃª seria tolo em fazÃª-lo com distribuiÃ§Ãµes a priori, porque tal mentira seria facilmente descoberta. Melhor usar a maquinaria mais opaca da verossimilhanÃ§a. Ou melhor ainda â€” nÃ£o siga realmente este conselho! â€” massageie os dados, descarte alguns "outliers" e de outra forma engaje em transformaÃ§Ã£o motivada dos dados.

Ã‰ verdade, porÃ©m, que a escolha da verossimilhanÃ§a Ã© muito mais convencionalizada do que a escolha da distribuiÃ§Ã£o a priori. Mas escolhas convencionais sÃ£o frequentemente escolhas pobres, contrabandeando influÃªncias que podem ser difÃ­ceis de descobrir. Nesse aspecto, tanto modelos bayesianos quanto nÃ£o bayesianos sÃ£o igualmente atormentados, porque ambas as tradiÃ§Ãµes dependem fortemente de funÃ§Ãµes de verossimilhanÃ§a e formas de modelo convencionalizadas. E o fato de que o procedimento nÃ£o bayesiano nÃ£o precisa fazer uma suposiÃ§Ã£o sobre a distribuiÃ§Ã£o a priori Ã© de pouco conforto. Isso porque procedimentos nÃ£o bayesianos precisam fazer escolhas que os bayesianos nÃ£o precisam, como escolha de estimador ou penalidade na verossimilhanÃ§a. Frequentemente, tais escolhas podem ser mostradas como equivalentes a alguma escolha bayesiana de distribuiÃ§Ã£o a priori ou, mais precisamente, escolha de funÃ§Ã£o de perda. (VocÃª conhecerÃ¡ funÃ§Ãµes de perda mais adiante, no CapÃ­tulo 3.)

**2.3.3. Um modelo nasce.** Com todo o trabalho acima, podemos agora resumir nosso modelo. As variÃ¡veis observadas W e L recebem contagens relativas atravÃ©s da distribuiÃ§Ã£o binomial. EntÃ£o podemos escrever, como atalho:

$$W \sim \text{Binomial}(N, p)$$

onde N = W + L. O acima Ã© apenas uma convenÃ§Ã£o para comunicar a suposiÃ§Ã£o de que as contagens relativas de maneiras de realizar W em N tentativas com probabilidade p em cada tentativa vÃªm da distribuiÃ§Ã£o binomial. E o parÃ¢metro nÃ£o observado p similarmente recebe:

$$p \sim \text{Uniform}(0,1)$$

Isso significa que p tem uma distribuiÃ§Ã£o a priori uniforme â€” plana â€” sobre toda a sua faixa possÃ­vel, de zero a um. Como mencionei anteriormente, isso obviamente nÃ£o Ã© o melhor que poderÃ­amos fazer, pois sabemos que a Terra tem mais Ã¡gua que terra, mesmo que ainda nÃ£o saibamos a proporÃ§Ã£o exata.

Em seguida, vejamos como usar essas suposiÃ§Ãµes para gerar inferÃªncia.

## 2.4. Fazendo o modelo funcionar
Uma vez que vocÃª nomeou todas as variÃ¡veis e escolheu definiÃ§Ãµes para cada uma, um modelo bayesiano pode atualizar todas as distribuiÃ§Ãµes a priori para suas consequÃªncias puramente lÃ³gicas: a **distribuiÃ§Ã£o a posteriori**. Para cada combinaÃ§Ã£o Ãºnica de dados, verossimilhanÃ§a, parÃ¢metros e distribuiÃ§Ã£o a priori, hÃ¡ uma distribuiÃ§Ã£o a posteriori Ãºnica. Essa distribuiÃ§Ã£o contÃ©m a plausibilidade relativa de diferentes valores de parÃ¢metros, condicional nos dados e no modelo. A distribuiÃ§Ã£o a posteriori assume a forma da probabilidade dos parÃ¢metros, condicional nos dados. Neste caso, seria Pr(p|W, L), a probabilidade de cada valor possÃ­vel de p, condicional nos W e L especÃ­ficos que observamos.

**2.4.1. O teorema de Bayes.** A definiÃ§Ã£o matemÃ¡tica da distribuiÃ§Ã£o a posteriori surge do **teorema de Bayes**. Este Ã© o teorema que dÃ¡ Ã  anÃ¡lise bayesiana de dados seu nome. Mas o teorema em si Ã© uma implicaÃ§Ã£o trivial da teoria da probabilidade. Aqui estÃ¡ uma derivaÃ§Ã£o rÃ¡pida dele, no contexto do exemplo de lanÃ§amento do globo. Na verdade, isso serÃ¡ apenas uma re-expressÃ£o da derivaÃ§Ã£o do jardim de dados bifurcantes de antes neste capÃ­tulo. O que a faz parecer diferente Ã© que ela usarÃ¡ as regras da teoria da probabilidade para extrair a regra de atualizaÃ§Ã£o. Mas ainda Ã© apenas contagem.

A probabilidade conjunta dos dados W e L e qualquer valor particular de p Ã©:

$$\Pr(W, L, p) = \Pr(W, L|p) \Pr(p)$$

Isso apenas diz que a probabilidade de W, L e p Ã© o produto de Pr(W, L|p) e a probabilidade a priori Pr(p). Ã‰ como dizer que a probabilidade de chuva e frio no mesmo dia Ã© igual Ã  probabilidade de chuva, quando estÃ¡ frio, vezes a probabilidade de que esteja frio. AtÃ© aqui Ã© apenas definiÃ§Ã£o. Mas Ã© igualmente verdade que:

$$\Pr(W, L, p) = \Pr(p|W, L) \Pr(W, L)$$

Tudo o que fiz foi inverter qual probabilidade Ã© condicional, no lado direito. Ainda Ã© uma definiÃ§Ã£o verdadeira. Ã‰ como dizer que a probabilidade de chuva e frio no mesmo dia Ã© igual Ã  probabilidade de que esteja frio, quando estÃ¡ chovendo, vezes a probabilidade de chuva. Compare essa afirmaÃ§Ã£o com a do parÃ¡grafo anterior.

Agora, como ambos os lados direitos acima sÃ£o iguais Ã  mesma coisa, Pr(W, L, p), eles tambÃ©m sÃ£o iguais entre si:

$$\Pr(W, L|p) \Pr(p) = \Pr(p|W, L) \Pr(W, L)$$

EntÃ£o podemos agora resolver para o que queremos, Pr(p|W, L):

$$\Pr(p|W,L) = \frac{\Pr(W,L|p)\Pr(p)}{\Pr(W,L)}$$

E este Ã© o teorema de Bayes. Ele diz que a probabilidade de qualquer valor particular de p, considerando os dados, Ã© igual ao produto da plausibilidade relativa dos dados, condicional em p, e da plausibilidade a priori de p, dividido por essa coisa Pr(W, L), que chamarei de probabilidade mÃ©dia dos dados. Em forma de palavras:

$$Posterior = \frac{\text{Probabilidade dos dados} \times \text{A priori}}{\text{Probabilidade mÃ©dia dos dados}}$$

A probabilidade mÃ©dia dos dados, Pr(W, L), pode ser confusa. Ela Ã© comumente chamada de "evidÃªncia" ou "verossimilhanÃ§a mÃ©dia", nenhum dos quais Ã© um nome transparente. A probabilidade Pr(W, L) Ã© literalmente a probabilidade mÃ©dia dos dados. MÃ©dia sobre o quÃª? Sobre a distribuiÃ§Ã£o a priori. Seu trabalho Ã© apenas padronizar a distribuiÃ§Ã£o a posteriori, para garantir que ela some (integre) para um. Em forma matemÃ¡tica:

$$\Pr(W, L) = \mathbb{E}(\Pr(W, L|p)) = \int \Pr(W, L|p) \Pr(p) dp$$

O operador $\mathbb{E}$ significa tomar uma esperanÃ§a. Tais mÃ©dias sÃ£o comumente chamadas de marginais na estatÃ­stica matemÃ¡tica, e portanto vocÃª tambÃ©m pode ver essa mesma probabilidade chamada de verossimilhanÃ§a marginal. E a integral acima apenas define a maneira correta de calcular a mÃ©dia sobre uma distribuiÃ§Ã£o contÃ­nua de valores, como os infinitos valores possÃ­veis de p.

A liÃ§Ã£o principal Ã© que a distribuiÃ§Ã£o a posteriori Ã© proporcional ao produto da distribuiÃ§Ã£o a priori e da probabilidade dos dados. Por quÃª? Porque para cada valor especÃ­fico de p, o nÃºmero de caminhos

![](_page_19_Figure_2.jpeg)

Figura 2.6. A distribuiÃ§Ã£o a posteriori, como produto da distribuiÃ§Ã£o a priori e da verossimilhanÃ§a. Linha superior: uma distribuiÃ§Ã£o a priori plana constrÃ³i uma distribuiÃ§Ã£o a posteriori que Ã© simplesmente proporcional Ã  verossimilhanÃ§a. Linha do meio: uma distribuiÃ§Ã£o a priori em degrau, atribuindo probabilidade zero a todos os valores menores que 0,5, resultando em uma distribuiÃ§Ã£o a posteriori truncada. Linha inferior: uma distribuiÃ§Ã£o a priori com pico que desloca e distorce a distribuiÃ§Ã£o a posteriori, relativamente Ã  verossimilhanÃ§a.

pelo jardim de dados bifurcantes Ã© o produto do nÃºmero a priori de caminhos e o novo nÃºmero de caminhos. A multiplicaÃ§Ã£o Ã© apenas contagem comprimida. A probabilidade mÃ©dia no denominador apenas padroniza as contagens para que somem um. EntÃ£o, embora o teorema de Bayes pareÃ§a complicado, porque a relaÃ§Ã£o com a contagem de caminhos Ã© obscurecida, ele apenas expressa a contagem que a lÃ³gica exige.

A Figura 2.6 ilustra a interaÃ§Ã£o multiplicativa de uma distribuiÃ§Ã£o a priori e uma probabilidade dos dados. Em cada linha, uma distribuiÃ§Ã£o a priori Ã  esquerda Ã© multiplicada pela probabilidade dos dados no meio para produzir uma distribuiÃ§Ã£o a posteriori Ã  direita. A probabilidade dos dados em cada caso Ã© a mesma. As distribuiÃ§Ãµes a priori, contudo, variam. Como resultado, as distribuiÃ§Ãµes a posteriori variam.

> **Repensando: A anÃ¡lise bayesiana de dados nÃ£o Ã© sobre o teorema de Bayes.** Uma noÃ§Ã£o comum sobre a anÃ¡lise bayesiana de dados, e a inferÃªncia bayesiana mais geralmente, Ã© que ela se distingue pelo uso do teorema de Bayes. Isso Ã© um erro. A inferÃªncia sob qualquer conceito de probabilidade eventualmente farÃ¡ uso do teorema de Bayes. Exemplos introdutÃ³rios comuns de anÃ¡lise "bayesiana" usando testes de HIV e DNA nÃ£o sÃ£o unicamente bayesianos. Como todos os elementos do cÃ¡lculo sÃ£o frequÃªncias de observaÃ§Ãµes, uma anÃ¡lise nÃ£o bayesiana faria exatamente a mesma coisa. Em vez disso, abordagens bayesianas podem usar o teorema de Bayes mais geralmente, para quantificar incerteza sobre entidades teÃ³ricas que nÃ£o podem ser observadas, como parÃ¢metros e modelos. InferÃªncias poderosas podem ser produzidas tanto sob conceitos de probabilidade bayesianos quanto nÃ£o bayesianos, mas diferentes justificativas e sacrifÃ­cios sÃ£o necessÃ¡rios.

**2.4.2. Motores.** Lembre-se de que seu modelo bayesiano Ã© uma mÃ¡quina, um golem figurativo. Ele tem definiÃ§Ãµes embutidas para a verossimilhanÃ§a, os parÃ¢metros e a distribuiÃ§Ã£o a priori. E entÃ£o, em seu coraÃ§Ã£o, reside um motor que processa dados, produzindo uma distribuiÃ§Ã£o a posteriori. A aÃ§Ã£o desse motor pode ser pensada como condicionar a distribuiÃ§Ã£o a priori nos dados. Como explicado na seÃ§Ã£o anterior, esse condicionamento Ã© governado pelas regras da teoria da probabilidade, que define uma distribuiÃ§Ã£o a posteriori unicamente lÃ³gica para cada conjunto de suposiÃ§Ãµes e observaÃ§Ãµes.

Contudo, conhecer a regra matemÃ¡tica Ã© frequentemente de pouca ajuda, porque muitos dos modelos interessantes na ciÃªncia contemporÃ¢nea nÃ£o podem ser condicionados formalmente, nÃ£o importa sua habilidade em matemÃ¡tica. E embora alguns modelos amplamente Ãºteis como a regressÃ£o linear possam ser condicionados formalmente, isso sÃ³ Ã© possÃ­vel se vocÃª restringir sua escolha de distribuiÃ§Ã£o a priori a formas especiais que sÃ£o fÃ¡ceis de trabalhar matematicamente. GostarÃ­amos de evitar escolhas de modelagem forÃ§adas desse tipo, favorecendo motores de condicionamento que possam acomodar qualquer distribuiÃ§Ã£o a priori que for mais Ãºtil para a inferÃªncia.

O que isso significa Ã© que vÃ¡rias tÃ©cnicas numÃ©ricas sÃ£o necessÃ¡rias para aproximar a matemÃ¡tica que segue da definiÃ§Ã£o do teorema de Bayes. Neste livro, vocÃª conhecerÃ¡ trÃªs motores de condicionamento diferentes, tÃ©cnicas numÃ©ricas para calcular distribuiÃ§Ãµes a posteriori:

- (1) AproximaÃ§Ã£o por grade
- (2) AproximaÃ§Ã£o quadrÃ¡tica
- (3) Markov chain Monte Carlo (MCMC)

HÃ¡ muitos outros motores, e novos estÃ£o sendo inventados o tempo todo. Mas os trÃªs que vocÃª conhecerÃ¡ aqui sÃ£o comuns e amplamente Ãºteis. AlÃ©m disso, conforme os aprende, vocÃª tambÃ©m aprenderÃ¡ princÃ­pios que o ajudarÃ£o a entender outras tÃ©cnicas.

> **Repensando: Como vocÃª ajusta o modelo Ã© parte do modelo.** Anteriormente neste capÃ­tulo, defini implicitamente o modelo como um composto de uma distribuiÃ§Ã£o a priori e uma verossimilhanÃ§a. Essa definiÃ§Ã£o Ã© tÃ­pica. Mas em termos prÃ¡ticos, devemos tambÃ©m considerar como o modelo Ã© ajustado aos dados como parte do modelo. Em problemas muito simples, como o exemplo de lanÃ§amento do globo que consome este capÃ­tulo, o cÃ¡lculo da densidade a posteriori Ã© trivial e infalÃ­vel. Em problemas mesmo moderadamente complexos, contudo, os detalhes de ajustar o modelo aos dados nos forÃ§am a reconhecer que nossa tÃ©cnica numÃ©rica influencia nossas inferÃªncias. Isso porque diferentes erros e compromissos surgem sob diferentes tÃ©cnicas. O mesmo modelo ajustado aos mesmos dados usando diferentes tÃ©cnicas pode produzir diferentes respostas. Quando algo dÃ¡ errado, cada peÃ§a da mÃ¡quina pode ser suspeita. E assim nossos golems carregam consigo seus motores de atualizaÃ§Ã£o, tÃ£o escravos de sua engenharia quanto sÃ£o das distribuiÃ§Ãµes a priori e verossimilhanÃ§as que programamos neles.

**2.4.3. AproximaÃ§Ã£o por grade.** Uma das tÃ©cnicas de condicionamento mais simples Ã© a aproximaÃ§Ã£o por grade. Embora a maioria dos parÃ¢metros seja *contÃ­nua*, capaz de assumir um nÃºmero infinito de valores, acontece que podemos alcanÃ§ar uma excelente aproximaÃ§Ã£o da distribuiÃ§Ã£o a posteriori contÃ­nua considerando apenas uma grade finita de valores de parÃ¢metros. Em qualquer valor particular de um parÃ¢metro, p', Ã© simples calcular a probabilidade a posteriori: basta multiplicar a probabilidade a priori de p' pela verossimilhanÃ§a em p'. Repetir esse procedimento para cada valor na grade gera uma imagem aproximada da distribuiÃ§Ã£o a posteriori exata. Esse procedimento Ã© chamado de **APROXIMAÃ‡ÃƒO POR GRADE**. Nesta seÃ§Ã£o, vocÃª verÃ¡ como realizar uma aproximaÃ§Ã£o por grade, usando trechos simples de cÃ³digo R.

A aproximaÃ§Ã£o por grade serÃ¡ principalmente Ãºtil como ferramenta pedagÃ³gica, pois aprendÃª-la forÃ§a o usuÃ¡rio a realmente entender a natureza da atualizaÃ§Ã£o bayesiana. Mas na maioria da sua modelagem real, a aproximaÃ§Ã£o por grade nÃ£o Ã© prÃ¡tica. A razÃ£o Ã© que ela escala muito mal conforme o nÃºmero de parÃ¢metros aumenta. EntÃ£o, em capÃ­tulos posteriores, a aproximaÃ§Ã£o por grade desaparecerÃ¡, para ser substituÃ­da por outras tÃ©cnicas mais eficientes. Ainda assim, o valor conceitual deste exercÃ­cio seguirÃ¡ adiante, conforme vocÃª se gradua para outras tÃ©cnicas.

No contexto do problema de lanÃ§amento do globo, a aproximaÃ§Ã£o por grade funciona extremamente bem. EntÃ£o vamos construir uma aproximaÃ§Ã£o por grade para o modelo que construÃ­mos atÃ© agora. Aqui estÃ¡ a receita:

- (1) Defina a grade. Isso significa que vocÃª decide quantos pontos usar na estimaÃ§Ã£o da distribuiÃ§Ã£o a posteriori e entÃ£o faz uma lista dos valores de parÃ¢metros na grade.
- (2) Calcule o valor da distribuiÃ§Ã£o a priori em cada valor de parÃ¢metro na grade.
- (3) Calcule a verossimilhanÃ§a em cada valor de parÃ¢metro.
- (4) Calcule a distribuiÃ§Ã£o a posteriori nÃ£o padronizada em cada valor de parÃ¢metro, multiplicando a distribuiÃ§Ã£o a priori pela verossimilhanÃ§a.
- (5) Finalmente, padronize a distribuiÃ§Ã£o a posteriori, dividindo cada valor pela soma de todos os valores.

No contexto do lanÃ§amento do globo, aqui estÃ¡ o cÃ³digo para completar todas as cinco etapas:

```r
# define grid
p_grid <- seq( from=0 , to=1 , length.out=20 )

# define prior
prior <- rep( 1 , 20 )

# compute likelihood at each value in grid
likelihood <- dbinom( 6 , size=9 , prob=p_grid )

# compute product of likelihood and prior
unstd.posterior <- likelihood * prior

# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
```

O cÃ³digo acima faz uma grade de apenas 20 pontos. Para exibir a distribuiÃ§Ã£o a posteriori agora:

```r
plot( p_grid , posterior , type="b" ,
```

|  |  |
|:--------:|:--------:|
| ![](_page_22_Figure_2.jpeg) | ![](_page_22_Figure_3.jpeg) |

Figura 2.7. Calculando a distribuiÃ§Ã£o a posteriori por aproximaÃ§Ã£o por grade. Em cada grÃ¡fico, a distribuiÃ§Ã£o a posteriori para os dados e modelo de lanÃ§amento do globo Ã© aproximada com um nÃºmero finito de pontos igualmente espaÃ§ados. Com apenas 5 pontos (esquerda), a aproximaÃ§Ã£o Ã© terrÃ­vel. Mas com 20 pontos (direita), a aproximaÃ§Ã£o jÃ¡ Ã© bastante boa. Compare com a distribuiÃ§Ã£o a posteriori exata, resolvida analiticamente, na Figura 2.5 (pÃ¡gina 30).

VocÃª obterÃ¡ o grÃ¡fico da direita na Figura 2.7. Tente grades mais esparsas (5 pontos) e mais densas (100 ou 1000 pontos). A densidade correta para sua grade Ã© determinada por quÃ£o precisa vocÃª quer que sua aproximaÃ§Ã£o seja. Mais pontos significa mais precisÃ£o. Neste exemplo simples, vocÃª pode exagerar e usar 100.000 pontos, mas nÃ£o haverÃ¡ muita mudanÃ§a na inferÃªncia apÃ³s os primeiros 100.

Agora, para replicar as diferentes distribuiÃ§Ãµes a priori na Figura 2.5, tente estas linhas de cÃ³digo â€” uma de cada vez â€” para a grade da distribuiÃ§Ã£o a priori:

```r
prior <- ifelse( p_grid < 0.5 , 0 , 1 )
prior <- exp( -5*abs( p_grid - 0.5 ) )
```

O restante do cÃ³digo permanece o mesmo.

> [!NOTE]
> **Pensando Mais um Pouco: VetorizaÃ§Ã£o.** Uma das caracterÃ­sticas Ãºteis do R Ã© que ele torna trabalhar com listas de nÃºmeros quase tÃ£o fÃ¡cil quanto trabalhar com valores Ãºnicos. EntÃ£o, embora ambas as linhas de cÃ³digo acima nÃ£o digam nada sobre quÃ£o densa Ã© sua grade, qualquer comprimento que vocÃª tenha escolhido para o vetor p_grid determinarÃ¡ o comprimento do vetor prior. No jargÃ£o do R, os cÃ¡lculos acima sÃ£o *vetorizados*, porque trabalham com listas de valores, *vetores*. Em um cÃ¡lculo vetorizado, o cÃ¡lculo Ã© realizado em cada elemento do vetor de entrada â€” p_grid neste caso â€” e a saÃ­da resultante, portanto, tem o mesmo comprimento. Em outros ambientes computacionais, o mesmo cÃ¡lculo exigiria um *loop*. R tambÃ©m pode usar loops, mas cÃ¡lculos vetorizados sÃ£o tipicamente mais rÃ¡pidos. Eles podem, contudo, ser muito mais difÃ­ceis de ler quando vocÃª estÃ¡ comeÃ§ando com R. Tenha paciÃªncia, e vocÃª logo se acostumarÃ¡ a cÃ¡lculos vetorizados.

**2.4.4. AproximaÃ§Ã£o quadrÃ¡tica.** Continuaremos com a aproximaÃ§Ã£o por grade da distribuiÃ§Ã£o a posteriori do lanÃ§amento do globo, pelo restante deste capÃ­tulo e do prÃ³ximo. Mas em breve vocÃª terÃ¡ que recorrer a

outra aproximaÃ§Ã£o, uma que faz suposiÃ§Ãµes mais fortes. A razÃ£o Ã© que o nÃºmero de valores Ãºnicos a considerar na grade cresce rapidamente conforme o nÃºmero de parÃ¢metros em seu modelo aumenta. Para o modelo de lanÃ§amento do globo com um Ãºnico parÃ¢metro, nÃ£o Ã© problema calcular uma grade de 100 ou 1000 valores. Mas para dois parÃ¢metros aproximados por 100 valores cada, jÃ¡ sÃ£o $100^2 = 10000$ valores para calcular. Para 10 parÃ¢metros, a grade se torna bilhÃµes de valores. Hoje em dia, Ã© rotina ter modelos com centenas ou milhares de parÃ¢metros. A estratÃ©gia de aproximaÃ§Ã£o por grade escala muito mal com a complexidade do modelo, entÃ£o ela nÃ£o nos levarÃ¡ muito longe.

Uma abordagem Ãºtil Ã© a **APROXIMAÃ‡ÃƒO QUADRÃTICA**. Sob condiÃ§Ãµes bem gerais, a regiÃ£o perto do pico da distribuiÃ§Ã£o a posteriori serÃ¡ quase gaussiana â€” ou "normal" â€” em forma. Isso significa que a distribuiÃ§Ã£o a posteriori pode ser utilmente aproximada por uma distribuiÃ§Ã£o gaussiana. Uma distribuiÃ§Ã£o gaussiana Ã© conveniente, porque pode ser completamente descrita por apenas dois nÃºmeros: a localizaÃ§Ã£o de seu centro (mÃ©dia) e sua dispersÃ£o (variÃ¢ncia).

Uma aproximaÃ§Ã£o gaussiana Ã© chamada de "aproximaÃ§Ã£o quadrÃ¡tica" porque o logaritmo de uma distribuiÃ§Ã£o gaussiana forma uma parÃ¡bola. E uma parÃ¡bola Ã© uma funÃ§Ã£o quadrÃ¡tica. EntÃ£o essa aproximaÃ§Ã£o essencialmente representa qualquer log-posteriori com uma parÃ¡bola.

Usaremos a aproximaÃ§Ã£o quadrÃ¡tica durante boa parte da primeira metade deste livro. Para muitos dos procedimentos mais comuns em estatÃ­stica aplicada â€” regressÃ£o linear, por exemplo â€” a aproximaÃ§Ã£o funciona muito bem. Frequentemente, Ã© atÃ© exatamente correta, nÃ£o sendo realmente uma aproximaÃ§Ã£o. Computacionalmente, a aproximaÃ§Ã£o quadrÃ¡tica Ã© muito barata, pelo menos comparada Ã  aproximaÃ§Ã£o por grade e ao MCMC (discutido a seguir). O procedimento, que o R conduzirÃ¡ alegremente a seu comando, contÃ©m dois passos.

- (1) Encontre a moda a posteriori. Isso Ã© geralmente alcanÃ§ado por algum algoritmo de otimizaÃ§Ã£o, um procedimento que virtualmente "escala" a distribuiÃ§Ã£o a posteriori, como se fosse uma montanha. O golem nÃ£o sabe onde estÃ¡ o pico, mas conhece a inclinaÃ§Ã£o sob seus pÃ©s. HÃ¡ muitos procedimentos de otimizaÃ§Ã£o bem desenvolvidos, a maioria mais esperta do que simples escalada de colinas. Mas todos tentam encontrar picos.
- (2) Uma vez que vocÃª encontra o pico da distribuiÃ§Ã£o a posteriori, deve estimar a curvatura perto do pico. Essa curvatura Ã© suficiente para calcular uma aproximaÃ§Ã£o quadrÃ¡tica de toda a distribuiÃ§Ã£o a posteriori. Em alguns casos, esses cÃ¡lculos podem ser feitos analiticamente, mas geralmente seu computador usa alguma tÃ©cnica numÃ©rica.

Para calcular a aproximaÃ§Ã£o quadrÃ¡tica para os dados de lanÃ§amento do globo, usaremos uma ferramenta no pacote rethinking: quap. Vamos usar quap bastante na primeira metade deste livro. Ã‰ uma ferramenta flexÃ­vel de ajuste de modelos que nos permitirÃ¡ especificar um grande nÃºmero de diferentes modelos de "regressÃ£o". EntÃ£o valerÃ¡ a pena experimentÃ¡-la agora mesmo. VocÃª terÃ¡ uma compreensÃ£o mais aprofundada dela mais adiante.

Para calcular a aproximaÃ§Ã£o quadrÃ¡tica dos dados de lanÃ§amento do globo:

```r
library(rethinking)
globe.qa <- quap(
  alist(
    W ~ dbinom( W+L , p ) ,
    p ~ dunif( 0 , 1 )
  ) , data=list(W=6,L=3) )
precis( globe.qa )
```

Para usar quap, vocÃª fornece uma *fÃ³rmula*, uma lista de *dados*. A fÃ³rmula define a probabilidade dos dados e a distribuiÃ§Ã£o a priori. Direi muito mais sobre essas fÃ³rmulas no CapÃ­tulo 4. Agora vejamos a saÃ­da:

```
  Mean StdDev 5.5% 94.5%
p 0.67 0.16 0.42 0.92
```

A funÃ§Ã£o precis apresenta um breve resumo da aproximaÃ§Ã£o quadrÃ¡tica. Neste caso, ela mostra o valor mÃ©dio a posteriori de p = 0,67, que ela chama de "Mean" (MÃ©dia). A curvatura Ã© rotulada "StdDev". Isso significa desvio padrÃ£o. Esse valor Ã© o desvio padrÃ£o da distribuiÃ§Ã£o a posteriori, enquanto o valor mÃ©dio Ã© seu pico. Finalmente, os dois Ãºltimos valores na saÃ­da de precis mostram o intervalo percentil de 89%, que vocÃª aprenderÃ¡ mais sobre no prÃ³ximo capÃ­tulo. VocÃª pode ler esse tipo de aproximaÃ§Ã£o como: Supondo que a distribuiÃ§Ã£o a posteriori Ã© gaussiana, ela Ã© maximizada em 0,67 e seu desvio padrÃ£o Ã© 0,16.

Como jÃ¡ conhecemos a distribuiÃ§Ã£o a posteriori, vamos comparar para ver quÃ£o boa Ã© a aproximaÃ§Ã£o. Usarei a abordagem analÃ­tica aqui, que usa dbeta. NÃ£o explicarei esse cÃ¡lculo, mas ele garante que temos exatamente a resposta certa, sem aproximaÃ§Ãµes. VocÃª pode encontrar uma explicaÃ§Ã£o e derivaÃ§Ã£o em praticamente qualquer livro de texto matemÃ¡tico sobre inferÃªncia bayesiana.

```r
# analytical calculation
W <- 6
L <- 3
curve( dbeta(x, W+1, L+1), from=0, to=1)
# quadratic approximation
curve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE )
```

VocÃª pode ver esse grÃ¡fico (com um pouco de formataÃ§Ã£o extra) Ã  esquerda na Figura 2.8. A curva azul Ã© a distribuiÃ§Ã£o a posteriori analÃ­tica e a curva preta Ã© a aproximaÃ§Ã£o quadrÃ¡tica. A curva preta se sai razoavelmente em seu lado esquerdo, mas parece bastante ruim em seu lado direito. Ela atÃ© atribui probabilidade positiva a p = 1, o que sabemos ser impossÃ­vel, jÃ¡ que vimos pelo menos uma amostra de terra.

Conforme a quantidade de dados aumenta, contudo, a aproximaÃ§Ã£o quadrÃ¡tica melhora. No meio da Figura 2.8, o tamanho amostral Ã© dobrado para n = 18 lanÃ§amentos, mas com a mesma fraÃ§Ã£o de Ã¡gua, de modo que a moda da distribuiÃ§Ã£o a posteriori estÃ¡ no mesmo lugar. A aproximaÃ§Ã£o quadrÃ¡tica parece melhor agora, embora ainda nÃ£o Ã³tima. Com quatro vezes mais dados, no lado direito da figura, as duas curvas sÃ£o quase iguais agora.

Esse fenÃ´meno, em que a aproximaÃ§Ã£o quadrÃ¡tica melhora com a quantidade de dados, Ã© muito comum. Ã‰ uma das razÃµes pelas quais tantos procedimentos estatÃ­sticos clÃ¡ssicos sÃ£o nervosos sobre amostras pequenas: esses procedimentos usam aproximaÃ§Ãµes quadrÃ¡ticas (ou outras) que sÃ£o conhecidas como seguras apenas com dados infinitos. Frequentemente, essas aproximaÃ§Ãµes sÃ£o Ãºteis com menos do que dados infinitos, obviamente. Mas a taxa de melhoria conforme o tamanho amostral aumenta varia muito dependendo dos detalhes. Em alguns modelos, a aproximaÃ§Ã£o quadrÃ¡tica pode permanecer terrÃ­vel mesmo com milhares de amostras.

Usar a aproximaÃ§Ã£o quadrÃ¡tica em um contexto bayesiano traz consigo todas as mesmas preocupaÃ§Ãµes. Mas vocÃª sempre pode recorrer a algum algoritmo diferente da aproximaÃ§Ã£o quadrÃ¡tica, se tiver dÃºvidas. De fato, a aproximaÃ§Ã£o por grade funciona muito bem com amostras pequenas, porque

![](_page_25_Figure_2.jpeg)

Figura 2.8. PrecisÃ£o da aproximaÃ§Ã£o quadrÃ¡tica. Em cada grÃ¡fico, a distribuiÃ§Ã£o a posteriori exata Ã© plotada em azul, e a aproximaÃ§Ã£o quadrÃ¡tica Ã© plotada como a curva preta. Esquerda: Os dados de lanÃ§amento do globo com n = 9 lanÃ§amentos e w = 6 Ã¡guas. Meio: O dobro da quantidade de dados, com a mesma fraÃ§Ã£o de Ã¡gua, n = 18 e w = 12. Direita: Quatro vezes mais dados, n = 36 e w = 24.

em tais casos o modelo deve ser simples e os cÃ¡lculos serÃ£o bastante rÃ¡pidos. VocÃª tambÃ©m pode usar MCMC, que Ã© introduzido a seguir.

> **Repensando: EstimaÃ§Ã£o de mÃ¡xima verossimilhanÃ§a.** A aproximaÃ§Ã£o quadrÃ¡tica, seja com uma distribuiÃ§Ã£o a priori uniforme ou com muitos dados, Ã© frequentemente equivalente a uma **estimativa de mÃ¡xima verossimilhanÃ§a** (MLE) e seu **erro padrÃ£o**. O MLE Ã© uma estimativa de parÃ¢metro nÃ£o bayesiana muito comum. Essa correspondÃªncia entre uma aproximaÃ§Ã£o bayesiana e um estimador nÃ£o bayesiano comum Ã© tanto uma bÃªnÃ§Ã£o quanto uma maldiÃ§Ã£o. Ã‰ uma bÃªnÃ§Ã£o porque nos permite reinterpretar uma ampla gama de ajustes de modelos nÃ£o bayesianos publicados em termos bayesianos. Ã‰ uma maldiÃ§Ã£o porque estimativas de mÃ¡xima verossimilhanÃ§a tÃªm algumas desvantagens curiosas, e a aproximaÃ§Ã£o quadrÃ¡tica pode compartilhÃ¡-las. Exploraremos estas em capÃ­tulos posteriores.

> [!NOTE]
> **Pensando Mais um Pouco: Os Hessianos estÃ£o chegando.** Ã€s vezes ajuda saber mais sobre como a aproximaÃ§Ã£o quadrÃ¡tica Ã© calculada. Em particular, a aproximaÃ§Ã£o Ã s vezes falha. Quando falha, as chances sÃ£o de que vocÃª receberÃ¡ uma mensagem de erro confusa que diz algo sobre o "Hessiano." Estudantes de histÃ³ria mundial podem saber que os Hessianos eram mercenÃ¡rios alemÃ£es contratados pelos britÃ¢nicos no sÃ©culo XVIII para fazer vÃ¡rias coisas, incluindo lutar contra o revolucionÃ¡rio americano George Washington. Esses mercenÃ¡rios sÃ£o nomeados em homenagem a uma regiÃ£o do que Ã© agora a Alemanha central, Hesse.

O Hessiano que nos preocupa aqui tem pouco a ver com mercenÃ¡rios. Ã‰ nomeado em homenagem ao matemÃ¡tico Ludwig Otto Hesse (1811â€“1874). Um Hessiano Ã© uma matriz quadrada de segundas derivadas. Ã‰ usado para muitos propÃ³sitos na matemÃ¡tica, mas na aproximaÃ§Ã£o quadrÃ¡tica sÃ£o as segundas derivadas do logaritmo da probabilidade a posteriori com respeito aos parÃ¢metros. Acontece que essas derivadas sÃ£o suficientes para descrever uma distribuiÃ§Ã£o gaussiana, porque o logaritmo de uma distribuiÃ§Ã£o gaussiana Ã© apenas uma parÃ¡bola. ParÃ¡bolas nÃ£o tÃªm derivadas alÃ©m da segunda, entÃ£o, uma vez que sabemos o centro da parÃ¡bola (a moda a posteriori) e sua segunda derivada, sabemos tudo sobre ela. E, de fato, a segunda derivada (com respeito ao resultado) do logaritmo de uma distribuiÃ§Ã£o gaussiana Ã© proporcional ao inverso do quadrado de seu desvio padrÃ£o (sua "precisÃ£o": pÃ¡gina 79). EntÃ£o, conhecer o desvio padrÃ£o nos diz tudo sobre sua forma.

O desvio padrÃ£o Ã© tipicamente calculado a partir do Hessiano, entÃ£o computar o Hessiano Ã© quase sempre um passo necessÃ¡rio. Mas Ã s vezes o cÃ¡lculo dÃ¡ errado, e seu golem engasgarÃ¡ tentando computar o Hessiano. Nesses casos, vocÃª tem vÃ¡rias opÃ§Ãµes. Nem toda esperanÃ§a estÃ¡ perdida. Mas por ora Ã© suficiente reconhecer o termo e associÃ¡-lo com uma tentativa de encontrar o desvio padrÃ£o para uma aproximaÃ§Ã£o quadrÃ¡tica.

**2.4.5. Markov chain Monte Carlo.** HÃ¡ muitos tipos importantes de modelos, como modelos multinÃ­vel (efeitos mistos), para os quais nem a aproximaÃ§Ã£o por grade nem a aproximaÃ§Ã£o quadrÃ¡tica Ã© sempre satisfatÃ³ria. Tais modelos podem ter centenas ou milhares ou dezenas de milhares de parÃ¢metros. A aproximaÃ§Ã£o por grade rotineiramente falha aqui, porque simplesmente demora demais â€” o Sol ficarÃ¡ escuro antes de seu computador terminar a grade. Formas especiais de aproximaÃ§Ã£o quadrÃ¡tica podem funcionar, se tudo estiver exatamente certo. Mas comumente, algo nÃ£o estÃ¡ exatamente certo. AlÃ©m disso, modelos multinÃ­vel nem sempre nos permitem escrever uma Ãºnica funÃ§Ã£o unificada para a distribuiÃ§Ã£o a posteriori. Isso significa que a funÃ§Ã£o a maximizar (ao encontrar o MAP) nÃ£o Ã© conhecida, mas deve ser calculada em partes.

Como resultado, vÃ¡rias tÃ©cnicas contra-intuitivas de ajuste de modelos surgiram. A mais popular destas Ã© **Markov Chain Monte Carlo** (MCMC), que Ã© uma famÃ­lia de motores de condicionamento capazes de lidar com modelos altamente complexos. Ã‰ justo dizer que MCMC Ã© em grande parte responsÃ¡vel pela insurgÃªncia da anÃ¡lise bayesiana de dados que comeÃ§ou nos anos 1990. Embora MCMC seja mais antigo que os anos 1990, poder computacional acessÃ­vel nÃ£o Ã©, entÃ£o devemos tambÃ©m agradecer aos engenheiros. Muito mais adiante no livro (CapÃ­tulo 9), vocÃª conhecerÃ¡ exemplos simples e precisos de ajuste de modelos por MCMC, voltados a ajudÃ¡-lo a entender a tÃ©cnica.

O desafio conceitual com MCMC reside em sua estratÃ©gia altamente nÃ£o Ã³bvia. Em vez de tentar calcular ou aproximar a distribuiÃ§Ã£o a posteriori diretamente, tÃ©cnicas MCMC meramente sorteiam amostras da distribuiÃ§Ã£o a posteriori. VocÃª termina com uma coleÃ§Ã£o de valores de parÃ¢metros, e as frequÃªncias desses valores correspondem Ã s plausibilidades a posteriori. VocÃª pode entÃ£o construir uma imagem da distribuiÃ§Ã£o a posteriori a partir do histograma dessas amostras.

Quase sempre trabalhamos diretamente com essas amostras, em vez de primeiro construir alguma estimativa matemÃ¡tica a partir delas. E as amostras sÃ£o de muitas maneiras mais convenientes do que ter a distribuiÃ§Ã£o a posteriori, porque sÃ£o mais fÃ¡ceis de raciocinar. E assim Ã© para onde nos voltamos no prÃ³ximo capÃ­tulo, para raciocinar com amostras.

> [!NOTE]
> **Pensando Mais um Pouco:** Monte Carlo e o lanÃ§amento do globo. Se vocÃª estÃ¡ ansioso para ver MCMC em aÃ§Ã£o, uma cadeia de Markov funcional para o modelo de lanÃ§amento do globo nÃ£o requer muito cÃ³digo. O seguinte cÃ³digo R serÃ¡ suficiente:
>
```r
n_samples <- 1000
p <- rep( NA , n_samples )
p[1] <- 0.5
W <- 6
L <- 3
for ( i in 2:n_samples ) {
    p_new <- rnorm( 1 , p[i-1] , 0.1 )
    if ( p_new < 0 ) p_new <- abs( p_new )
    if ( p_new > 1 ) p_new <- 2 - p_new
    q0 <- dbinom( W , W+L , p[i-1] )
    q1 <- dbinom( W , W+L , p_new )
    p[i] <- ifelse( runif(1) < q1/q0 , p_new , p[i-1] )
}
```
> Os valores em p sÃ£o amostras da distribuiÃ§Ã£o a posteriori. Para comparar com a distribuiÃ§Ã£o a posteriori analÃ­tica:
>
```r
dens( p , xlim=c(0,1) )
curve( dbeta( x , W+1 , L+1 ) , lty=2 , add=TRUE )
```
>
> Ã‰ estranho. Mas funciona. Explicarei esse algoritmo, o ALGORITMO DE METROPOLIS, no CapÃ­tulo 9.

## 2.5. Resumo

Este capÃ­tulo introduziu a mecÃ¢nica conceitual da anÃ¡lise bayesiana de dados. O alvo da inferÃªncia na inferÃªncia bayesiana Ã© uma distribuiÃ§Ã£o de probabilidade a posteriori. Probabilidades a posteriori declaram os nÃºmeros relativos de maneiras que cada causa conjecturada dos dados poderia ter produzido os dados. Esses nÃºmeros relativos indicam plausibilidades das diferentes conjecturas. Essas plausibilidades sÃ£o atualizadas Ã  luz das observaÃ§Ãµes, um processo conhecido como atualizaÃ§Ã£o bayesiana.

Mais mecanicamente, um modelo bayesiano Ã© um composto de variÃ¡veis e definiÃ§Ãµes distribucionais para essas variÃ¡veis. A probabilidade dos dados, frequentemente chamada de verossimilhanÃ§a, fornece a plausibilidade de uma observaÃ§Ã£o (dados), dado um valor fixo para os parÃ¢metros. A distribuiÃ§Ã£o a priori fornece a plausibilidade de cada valor possÃ­vel dos parÃ¢metros, antes de considerar os dados. As regras da probabilidade nos dizem que a maneira lÃ³gica de calcular as plausibilidades, apÃ³s considerar os dados, Ã© usar o teorema de Bayes. Isso resulta na distribuiÃ§Ã£o a posteriori.

Na prÃ¡tica, modelos bayesianos sÃ£o ajustados aos dados usando tÃ©cnicas numÃ©ricas, como aproximaÃ§Ã£o por grade, aproximaÃ§Ã£o quadrÃ¡tica e Markov chain Monte Carlo. Cada mÃ©todo impÃµe diferentes compromissos.

## 2.6. PrÃ¡tica

FÃ¡cil.

- 2E1. Quais das expressÃµes abaixo correspondem Ã  afirmaÃ§Ã£o: a probabilidade de chuva na segunda-feira?
  - (1) Pr(chuva)
  - (2) Pr(chuva|segunda-feira)
  - (3) Pr(segunda-feira|chuva)
  - (4) Pr(chuva, segunda-feira) / Pr(segunda-feira)
- **2E2.** Qual das seguintes afirmaÃ§Ãµes corresponde Ã  expressÃ£o: Pr(segunda-feira|chuva)?
  - (1) A probabilidade de chuva na segunda-feira.
  - (2) A probabilidade de chuva, dado que Ã© segunda-feira.
  - (3) A probabilidade de que seja segunda-feira, dado que estÃ¡ chovendo.
  - (4) A probabilidade de que seja segunda-feira e que esteja chovendo.
- **2E3.** Quais das expressÃµes abaixo correspondem Ã  afirmaÃ§Ã£o: *a probabilidade de que seja segunda-feira, dado que estÃ¡ chovendo*?
  - (1) Pr(segunda-feira|chuva)
  - (2) Pr(chuva|segunda-feira)
  - (3) Pr(chuva|segunda-feira) Pr(segunda-feira)
  - (4) Pr(chuva|segunda-feira) Pr(segunda-feira) / Pr(chuva)
  - (5) Pr(segunda-feira|chuva) Pr(chuva) / Pr(segunda-feira)

**2E4.** O estatÃ­stico bayesiano Bruno de Finetti (1906â€“1985) comeÃ§ou seu livro sobre teoria da probabilidade com a declaraÃ§Ã£o: "A PROBABILIDADE NÃƒO EXISTE." As maiÃºsculas apareciam no original, entÃ£o imagino que de Finetti queria que gritÃ¡ssemos essa afirmaÃ§Ã£o. O que ele quis dizer Ã© que a probabilidade Ã© um dispositivo para descrever incerteza da perspectiva de um observador com conhecimento limitado; ela nÃ£o tem realidade objetiva. Discuta o exemplo de lanÃ§amento do globo do capÃ­tulo, Ã  luz dessa afirmaÃ§Ã£o. O que significa dizer "a probabilidade de Ã¡gua Ã© 0,7"?

**MÃ©dio.**

- **2M1.** Relembre o modelo de lanÃ§amento do globo do capÃ­tulo. Calcule e plote a distribuiÃ§Ã£o a posteriori aproximada por grade para cada um dos seguintes conjuntos de observaÃ§Ãµes. Em cada caso, assuma uma distribuiÃ§Ã£o a priori uniforme para p.
  - (1) W, W, W
  - (2) W, W, W, L
  - (3) L, W, W, L, W, W, W
- **2M2.** Agora assuma uma distribuiÃ§Ã£o a priori para p que Ã© igual a zero quando p < 0,5 e Ã© uma constante positiva quando p â‰¥ 0,5. Novamente calcule e plote a distribuiÃ§Ã£o a posteriori aproximada por grade para cada um dos conjuntos de observaÃ§Ãµes no problema acima.
- **2M3.** Suponha que haja dois globos, um para a Terra e um para Marte. O globo da Terra Ã© 70% coberto de Ã¡gua. O globo de Marte Ã© 100% terra. Suponha ainda que um desses globos â€” vocÃª nÃ£o sabe qual â€” foi lanÃ§ado ao ar e produziu uma observaÃ§Ã£o de "terra". Assuma que cada globo tinha a mesma probabilidade de ser lanÃ§ado. Mostre que a probabilidade a posteriori de que o globo era a Terra, condicional em ver "terra" (Pr(Terra|terra)), Ã© 0,23.
- **2M4.** Suponha que vocÃª tenha um baralho com apenas trÃªs cartas. Cada carta tem dois lados, e cada lado Ã© preto ou branco. Uma carta tem dois lados pretos. A segunda carta tem um lado preto e um branco. A terceira carta tem dois lados brancos. Agora suponha que todas as trÃªs cartas sejam colocadas em um saco e embaralhadas. AlguÃ©m coloca a mÃ£o no saco e puxa uma carta, colocando-a plana sobre a mesa. Um lado preto Ã© mostrado virado para cima, mas vocÃª nÃ£o sabe a cor do lado virado para baixo. Mostre que a probabilidade de que o outro lado tambÃ©m seja preto Ã© 2/3. Use o mÃ©todo de contagem (SeÃ§Ã£o 2 do capÃ­tulo) para abordar este problema. Isso significa contar as maneiras que cada carta poderia produzir os dados observados (um lado preto virado para cima na mesa).
- **2M5.** Agora suponha que haja quatro cartas: P/P, P/B, B/B e outra P/P. Novamente suponha que uma carta Ã© retirada do saco e um lado preto aparece virado para cima. Novamente calcule a probabilidade de que o outro lado seja preto.
- **2M6.** Imagine que tinta preta Ã© pesada, e portanto cartas com lados pretos sÃ£o mais pesadas que cartas com lados brancos. Como resultado, Ã© menos provÃ¡vel que uma carta com lados pretos seja retirada do saco. EntÃ£o novamente assuma que hÃ¡ trÃªs cartas: P/P, P/B e B/B. ApÃ³s experimentar diversas vezes, vocÃª conclui que para cada maneira de retirar a carta P/P do saco, hÃ¡ 2 maneiras de retirar a carta P/B e 3 maneiras de retirar a carta B/B. Novamente suponha que uma carta Ã© retirada e um lado preto aparece virado para cima. Mostre que a probabilidade de que o outro lado seja preto agora Ã© 0,5. Use o mÃ©todo de contagem, como antes.
- **2M7.** Assuma novamente o problema original das cartas, com uma Ãºnica carta mostrando um lado preto virado para cima. Antes de olhar o outro lado, retiramos outra carta do saco e a colocamos virada para cima na mesa. A face mostrada na nova carta Ã© branca. Mostre que a probabilidade de que a primeira carta, a que mostra um lado preto, tenha preto em seu outro lado agora Ã© 0,75. Use o mÃ©todo de contagem, se puder. Dica: Trate isso como a sequÃªncia de lanÃ§amentos do globo, contando todas as maneiras de ver cada observaÃ§Ã£o, para cada possÃ­vel primeira carta.

**DifÃ­cil.**

**2H1.** Suponha que haja duas espÃ©cies de urso panda. Ambas sÃ£o igualmente comuns na natureza e vivem nos mesmos lugares. Elas se parecem exatamente e comem o mesmo alimento, e ainda nÃ£o hÃ¡ ensaio genÃ©tico capaz de diferenciÃ¡-las. Elas diferem, contudo, nos tamanhos de suas famÃ­lias. A espÃ©cie A dÃ¡ Ã  luz gÃªmeos 10% das vezes, caso contrÃ¡rio dando Ã  luz um Ãºnico filhote. A espÃ©cie B dÃ¡ Ã  luz gÃªmeos 20% das vezes, caso contrÃ¡rio dando Ã  luz filhotes Ãºnicos. Assuma que esses nÃºmeros sÃ£o conhecidos com certeza, a partir de muitos anos de pesquisa de campo.

Agora suponha que vocÃª estÃ¡ gerenciando um programa de reproduÃ§Ã£o de pandas em cativeiro. VocÃª tem uma nova fÃªmea de panda de espÃ©cie desconhecida, e ela acabou de dar Ã  luz gÃªmeos. Qual Ã© a probabilidade de que seu prÃ³ximo nascimento tambÃ©m seja de gÃªmeos?

- **2H2.** Relembre todos os fatos do problema acima. Agora calcule a probabilidade de que o panda que temos Ã© da espÃ©cie A, assumindo que observamos apenas o primeiro nascimento e que foram gÃªmeos.
- **2H3.** Continuando do problema anterior, suponha que a mesma mÃ£e panda tem um segundo nascimento e que nÃ£o sÃ£o gÃªmeos, mas um filhote Ãºnico. Calcule a probabilidade a posteriori de que esse panda Ã© da espÃ©cie A.
- **2H4.** Um orgulho comum dos estatÃ­sticos bayesianos Ã© que a inferÃªncia bayesiana torna fÃ¡cil usar todos os dados, mesmo que os dados sejam de tipos diferentes.

EntÃ£o suponha agora que um veterinÃ¡rio aparece com um novo teste genÃ©tico que ela afirma poder identificar a espÃ©cie de nossa mÃ£e panda. Mas o teste, como todos os testes, Ã© imperfeito. Esta Ã© a informaÃ§Ã£o que vocÃª tem sobre o teste:

- A probabilidade de que ele identifique corretamente um panda da espÃ©cie A Ã© 0,8.
- A probabilidade de que ele identifique corretamente um panda da espÃ©cie B Ã© 0,65.

O veterinÃ¡rio administra o teste em seu panda e lhe diz que o teste Ã© positivo para a espÃ©cie A. Primeiro ignore sua informaÃ§Ã£o anterior dos nascimentos e calcule a probabilidade a posteriori de que seu panda Ã© da espÃ©cie A. EntÃ£o refaÃ§a seu cÃ¡lculo, agora usando os dados de nascimento tambÃ©m.
