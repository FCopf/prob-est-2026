---
title: "Mundos Pequenos e Mundos Grandes"
subtitle: "Probabilidade e Estat√≠stica ‚Äî Aula 2"
author:
  - "Prof. Fabio Cop (*fcferreira@unifesp.br*)"
  - "Instituto do Mar - Unifesp"
date: today
lang: pt-BR
language:
  title-block-author-single: ""
  title-block-author-plural: ""
format:
  html:
    toc: true
    toc-title: "Conte√∫do"
    toc-depth: 3
    number-sections: true
    embed-resources: true
    code-fold: false
    code-tools: true
execute:
  eval: false
  echo: true
---

::: {.callout-note appearance="minimal" title="Sobre este material"}
Tradu√ß√£o adaptada do livro *Statistical Rethinking: A Bayesian Course with Examples in R and Stan* (2¬™ ed.) de Richard McElreath. Os recursos originais do autor, v√≠deos das aulas, c√≥digos e materiais complementares, est√£o dispon√≠veis em [https://xcelab.net/rm/](https://xcelab.net/rm/) e [https://github.com/rmcelreath/stat_rethinking_2026](https://github.com/rmcelreath/stat_rethinking_2026).
:::

Quando Cristoforo Colombo (Crist√≥v√£o Colombo) navegou infamemente para o oeste no ano de 1492, ele acreditava que a Terra era esf√©rica. Nisso, ele era como a maioria das pessoas instru√≠das de sua √©poca. Ele diferia da maioria, por√©m, ao acreditar que o planeta era muito menor do que realmente √© ‚Äî apenas 30.000 km ao redor de seu equador, em vez dos 40.000 km reais (Figura 2.1). Esse foi um dos erros mais consequentes da hist√≥ria europeia. Se Colombo tivesse acreditado que a Terra tinha 40.000 km de circunfer√™ncia, ele teria raciocinado corretamente que sua frota n√£o poderia carregar comida e √°gua pot√°vel suficientes para completar uma viagem inteiramente para o oeste at√© a √Åsia. Mas com 30.000 km de circunfer√™ncia, a √Åsia estaria um pouco a oeste da costa da Calif√≥rnia. Era poss√≠vel carregar suprimentos suficientes para chegar t√£o longe. Encorajado em parte por sua estimativa n√£o convencional, Colombo zarpou, eventualmente aportando nas Bahamas.

Colombo fez uma predi√ß√£o baseada em sua vis√£o de que o mundo era pequeno. Mas como ele vivia em um mundo grande, aspectos da predi√ß√£o estavam errados. No seu caso, o erro foi sortudo. Seu modelo de mundo pequeno estava errado de uma maneira inesperada: havia muita terra no caminho. Se ele tivesse errado da maneira esperada, com nada al√©m de oceano entre a Europa e a √Åsia, ele e toda a sua expedi√ß√£o teriam ficado sem suprimentos muito antes de alcan√ßar as √çndias Orientais.

Os mundos pequeno e grande de Colombo oferecem um contraste entre modelo e realidade. Toda modelagem estat√≠stica possui esses mesmos dois enquadramentos: o mundo pequeno do modelo em si e o mundo grande no qual esperamos aplicar o modelo. Navegar entre esses dois mundos permanece um desafio central da modelagem estat√≠stica. O desafio √© agravado quando se esquece a distin√ß√£o.

O **mundo pequeno** √© o mundo l√≥gico autocontido do modelo. Dentro do mundo pequeno, todas as possibilidades s√£o nomeadas. N√£o h√° surpresas puras, como a exist√™ncia de um enorme continente entre a Europa e a √Åsia. Dentro do mundo pequeno do modelo, √© importante ser capaz de verificar a l√≥gica do modelo, assegurando que ele funciona conforme esperado sob suposi√ß√µes favor√°veis. Modelos bayesianos t√™m algumas vantagens nesse aspecto, pois possuem reivindica√ß√µes razo√°veis de otimalidade: nenhum modelo alternativo poderia fazer melhor uso da informa√ß√£o nos dados e apoiar melhores decis√µes, assumindo que o mundo pequeno √© uma descri√ß√£o precisa do mundo real.

O **mundo grande** √© o contexto mais amplo no qual se aplica um modelo. No mundo grande, podem existir eventos que n√£o foram imaginados no mundo pequeno. Al√©m disso, o modelo √© sempre uma representa√ß√£o incompleta do mundo grande, e portanto cometer√° erros, mesmo que todos os tipos de eventos tenham sido devidamente nomeados. A consist√™ncia l√≥gica de um modelo no mundo pequeno n√£o √© garantia de que ele ser√° √≥timo no mundo grande. Mas certamente √© um conforto reconfortante.

![](cap-02-small-worlds-large-worlds-pt/_page_1_Figure_2.jpeg)

Figura 2.1. Ilustra√ß√£o do globo de Martin Behaim de 1492, mostrando o mundo pequeno que Colombo antecipava. A Europa est√° no lado direito. A √Åsia est√° √† esquerda. A grande ilha rotulada "Cipangu" √© o Jap√£o.

Neste cap√≠tulo, voc√™ come√ßar√° a construir modelos bayesianos. A maneira como modelos bayesianos aprendem a partir de evid√™ncias √© indiscutivelmente √≥tima no mundo pequeno. Quando suas suposi√ß√µes se aproximam da realidade, eles tamb√©m t√™m bom desempenho no mundo grande. Mas o desempenho no mundo grande precisa ser demonstrado, e n√£o deduzido logicamente. Transitar entre esses dois mundos permite que tanto m√©todos formais, como a infer√™ncia bayesiana, quanto m√©todos informais, como a revis√£o por pares, desempenhem um papel indispens√°vel.

Este cap√≠tulo foca no mundo pequeno. Ele explica a teoria da probabilidade em sua forma essencial: contando as maneiras como as coisas podem acontecer. A infer√™ncia bayesiana surge automaticamente dessa perspectiva. Em seguida, o cap√≠tulo apresenta os componentes estilizados de um modelo estat√≠stico bayesiano, um modelo para aprender a partir de dados. Depois, mostra como animar o modelo para produzir estimativas.

> **Repensando: R√°pido e frugal no mundo grande.** O mundo natural √© complexo, como a tentativa de fazer ci√™ncia nos lembra. No entanto, tudo, desde o humilde carrapato at√© o industrioso esquilo e a pregui√ßa ociosa, consegue frequentemente tomar decis√µes adaptativas. Mas √© uma boa aposta que a maioria dos animais n√£o √© bayesiana, at√© porque ser bayesiano √© caro e depende de ter um bom modelo. Em vez disso, os animais usam diversas heur√≠sticas que s√£o ajustadas aos seus ambientes, passados ou presentes. Essas heur√≠sticas tomam atalhos adaptativos e, portanto, podem superar uma an√°lise bayesiana rigorosa, uma vez que os custos de coleta e processamento de informa√ß√£o s√£o levados em conta. Uma vez que voc√™ j√° sabe qual informa√ß√£o ignorar ou prestar aten√ß√£o, ser completamente bayesiano √© um desperd√≠cio. N√£o √© necess√°rio nem suficiente para tomar boas decis√µes, como animais reais demonstram. Mas para animais humanos, a an√°lise bayesiana fornece uma maneira geral de descobrir informa√ß√µes relevantes e process√°-las logicamente. Apenas n√£o pense que √© a √∫nica maneira.

## O jardim dos dados bifurcantes

Nosso objetivo nesta se√ß√£o ser√° construir a infer√™ncia bayesiana a partir de origens humildes, para que n√£o haja supersti√ß√£o a respeito dela. A infer√™ncia bayesiana √© realmente apenas contagem e compara√ß√£o de possibilidades. Considere, por analogia, o conto de Jorge Luis Borges, "O Jardim dos Caminhos que se Bifurcam." A hist√≥ria √© sobre um homem que encontra um livro cheio de contradi√ß√µes. Na maioria dos livros, os personagens chegam a pontos da trama e devem decidir entre caminhos alternativos. Uma protagonista pode chegar √† casa de um homem. Ela pode matar o homem, ou ent√£o tomar uma x√≠cara de ch√°. Apenas um desses caminhos √© tomado ‚Äî assassinato ou ch√°. Mas o livro dentro da hist√≥ria de Borges explora todos os caminhos, com cada decis√£o se ramificando para fora em um jardim cada vez mais amplo de caminhos bifurcantes.

Este √© o mesmo dispositivo que a infer√™ncia bayesiana oferece. Para fazer boas infer√™ncias sobre o que realmente aconteceu, ajuda considerar tudo o que poderia ter acontecido. Uma an√°lise bayesiana √© um jardim de dados bifurcantes, no qual sequ√™ncias alternativas de eventos s√£o cultivadas. √Ä medida que aprendemos sobre o que aconteceu, algumas dessas sequ√™ncias alternativas s√£o podadas. No final, o que resta √© apenas o que √© logicamente consistente com nosso conhecimento.

Essa abordagem fornece uma classifica√ß√£o quantitativa de hip√≥teses, uma classifica√ß√£o que √© maximamente conservadora, dadas as suposi√ß√µes e os dados que a alimentam. A abordagem n√£o pode garantir uma resposta correta em termos de mundo grande. Mas pode garantir a melhor resposta poss√≠vel, em termos de mundo pequeno, que poderia ser derivada da informa√ß√£o fornecida.

Considere o seguinte exemplo did√°tico.

### Contando possibilidades {-}

Suponha que haja um saco contendo quatro bolinhas de gude. Essas bolinhas v√™m em duas cores: azul e branca. Sabemos que h√° quatro bolinhas no saco, mas n√£o sabemos quantas s√£o de cada cor. Sabemos que existem cinco possibilidades: (1) [‚ö™‚ö™‚ö™‚ö™], (2) [üîµ‚ö™‚ö™‚ö™], (3) [üîµüîµ‚ö™‚ö™], (4) [üîµüîµüîµ‚ö™], (5) [üîµüîµüîµüîµ]. Essas s√£o as √∫nicas possibilidades consistentes com o que sabemos sobre o conte√∫do do saco. Chame essas cinco possibilidades de conjecturas.

Nosso objetivo √© descobrir qual dessas conjecturas √© mais plaus√≠vel, dada alguma evid√™ncia sobre o conte√∫do do saco. Temos alguma evid√™ncia: uma sequ√™ncia de tr√™s bolinhas √© retirada do saco, uma de cada vez, recolocando a bolinha cada vez e agitando o saco antes de retirar outra bolinha. A sequ√™ncia que emerge √©: üîµ‚ö™üîµ, nessa ordem. Esses s√£o os dados.

Ent√£o, vamos plantar o jardim e ver como usar os dados para inferir o que est√° no saco. Comecemos considerando apenas a conjectura [üîµ‚ö™‚ö™‚ö™], de que o saco cont√©m uma bolinha azul e tr√™s brancas. Na primeira retirada do saco, uma de quatro coisas poderia acontecer, correspondendo a uma das quatro bolinhas no saco. Assim, podemos visualizar as possibilidades se ramificando:

![](cap-02-small-worlds-large-worlds-pt/_page_2_Picture_1b.jpeg)

Note que, embora as tr√™s bolinhas brancas pare√ßam iguais de uma perspectiva de dados ‚Äî afinal, registramos apenas a cor das bolinhas ‚Äî elas s√£o realmente eventos diferentes. Isso √© importante, porque significa que h√° tr√™s vezes mais maneiras de ver ‚ö™ do que de ver üîµ.

Agora considere o jardim √† medida que obtemos outra retirada do saco. Ele expande o jardim em mais uma camada:

![](cap-02-small-worlds-large-worlds-pt/_page_2_Picture_12.jpeg)

Agora h√° 16 caminhos poss√≠veis atrav√©s do jardim, um para cada par de retiradas. Na segunda retirada do saco, cada um dos caminhos acima se bifurca novamente em quatro caminhos poss√≠veis. Por qu√™?

![](cap-02-small-worlds-large-worlds-pt/_page_3_Figure_2.jpeg)

Figura 2.2. Os 64 caminhos poss√≠veis gerados ao supor que o saco cont√©m uma bolinha azul e tr√™s brancas.

Porque acreditamos que nossa agita√ß√£o do saco d√° a cada bolinha uma chance justa de ser retirada, independentemente de qual bolinha foi retirada anteriormente. A terceira camada √© constru√≠da da mesma maneira, e o jardim completo √© mostrado na Figura 2.2. H√° $4^3 = 64$ caminhos poss√≠veis no total.

√Ä medida que consideramos cada retirada do saco, alguns desses caminhos s√£o logicamente eliminados. A primeira retirada resultou em üîµ, lembre-se, ent√£o os tr√™s caminhos brancos na parte inferior do jardim s√£o eliminados imediatamente. Se voc√™ imaginar os dados reais tra√ßando um caminho pelo jardim, eles devem ter passado pelo √∫nico caminho azul perto da origem. A segunda retirada do saco produz ‚ö™, ent√£o tr√™s dos caminhos que se bifurcam a partir da primeira bolinha azul permanecem. Conforme os dados tra√ßam um caminho, sabemos que ele deve ter passado por um desses tr√™s caminhos brancos (depois do primeiro caminho azul), mas n√£o sabemos por qual, porque registramos apenas a cor de cada bolinha. Finalmente, a terceira retirada √© üîµ. Cada um dos tr√™s caminhos restantes na camada intermedi√°ria sustenta um caminho azul, deixando um total de tr√™s maneiras para a sequ√™ncia üîµ‚ö™üîµ aparecer, supondo que o saco cont√©m [üîµ‚ö™‚ö™‚ö™]. A Figura 2.3 mostra o jardim novamente, agora com caminhos logicamente eliminados esmaecidos. N√£o podemos ter certeza de qual desses tr√™s caminhos os dados reais tomaram. Mas, enquanto estivermos considerando apenas a possibilidade de que o saco contenha uma bolinha azul e tr√™s brancas, podemos ter certeza de que os dados tomaram um desses tr√™s caminhos. Esses s√£o os √∫nicos caminhos consistentes tanto com nosso conhecimento sobre o conte√∫do do saco (quatro bolinhas, brancas ou azuis) quanto com os dados (üîµ‚ö™üîµ).

Isso demonstra que h√° tr√™s (de 64) maneiras para um saco contendo [üîµ‚ö™‚ö™‚ö™] produzir os dados üîµ‚ö™üîµ. N√£o temos como decidir entre essas tr√™s maneiras. O poder inferencial vem de comparar essa contagem com os n√∫meros de maneiras que cada uma das outras conjecturas sobre o conte√∫do do saco poderia produzir os mesmos dados. Por exemplo, considere a conjectura [‚ö™‚ö™‚ö™‚ö™]. H√° zero maneiras para essa conjectura produzir os dados observados, porque mesmo uma √∫nica üîµ √© logicamente incompat√≠vel com ela. A conjectura [üîµüîµüîµüîµ] √© igualmente logicamente incompat√≠vel com os dados. Portanto, podemos eliminar essas duas conjecturas, porque nenhuma fornece sequer um √∫nico caminho consistente com os dados.

A Figura 2.4 exibe o jardim completo agora, para as tr√™s conjecturas restantes: [üîµ‚ö™‚ö™‚ö™], [üîµüîµ‚ö™‚ö™] e [üîµüîµüîµ‚ö™]. A fatia superior esquerda exibe o mesmo jardim da Figura 2.3. A superior direita mostra o jardim an√°logo para a conjectura de que o saco cont√©m tr√™s bolinhas azuis e uma branca. E a fatia inferior mostra o jardim para duas bolinhas azuis

![](cap-02-small-worlds-large-worlds-pt/_page_4_Figure_2.jpeg)

Figura 2.3. Ap√≥s eliminar caminhos inconsistentes com a sequ√™ncia observada, apenas 3 dos 64 caminhos permanecem.

e duas brancas. Agora contamos todas as maneiras que cada conjectura poderia produzir os dados observados. Para uma azul e tr√™s brancas, h√° tr√™s maneiras, como j√° contamos. Para duas azuis e duas brancas, h√° oito caminhos que se bifurcam pelo jardim que s√£o logicamente consistentes com a sequ√™ncia observada. Para tr√™s azuis e uma branca, h√° nove caminhos que sobrevivem.

Para resumir, consideramos cinco conjecturas diferentes sobre o conte√∫do do saco, variando de zero bolinhas azuis a quatro bolinhas azuis. Para cada uma dessas conjecturas, contamos quantas sequ√™ncias, caminhos pelo jardim de dados bifurcantes, poderiam potencialmente produzir os dados observados, üîµ‚ö™üîµ

| Conjectura                          | Maneiras de produzir üîµ‚ö™üîµ  |
|-------------------------------------|------------------------------|
| [‚ö™‚ö™‚ö™‚ö™]                          | $0 \times 4 \times 0 = 0$   |
| [üîµ‚ö™‚ö™‚ö™]                          | $1 \times 3 \times 1 = 3$   |
| [üîµüîµ‚ö™‚ö™]                          | $2 \times 2 \times 2 = 8$   |
| [üîµüîµüîµ‚ö™]                          | $3 \times 1 \times 3 = 9$   |
| [üîµüîµüîµüîµ]                          | $4 \times 0 \times 4 = 0$   |

Note que o n√∫mero de maneiras de produzir os dados üîµ‚ö™üîµ, para cada conjectura, pode ser calculado contando primeiro o n√∫mero de caminhos em cada "anel" do jardim e depois multiplicando essas contagens. Isso √© apenas um artif√≠cio computacional. Ele nos diz a mesma coisa que a Figura 2.4, mas sem precisar desenhar o jardim. O fato de que os n√∫meros s√£o multiplicados durante o c√°lculo n√£o muda o fato de que isso ainda √© apenas contagem de caminhos logicamente poss√≠veis. Esse ponto surgir√° novamente quando voc√™ encontrar a representa√ß√£o mais formal da infer√™ncia bayesiana.

Ent√£o, para que servem essas contagens? Ao comparar essas contagens, temos parte de uma solu√ß√£o para uma maneira de classificar a plausibilidade relativa de cada composi√ß√£o conjecturada do saco. Mas √© apenas uma parte de uma solu√ß√£o, porque, para comparar essas contagens, primeiro precisamos decidir de quantas maneiras cada conjectura poderia ela mesma ser realizada. Poder√≠amos argumentar que, quando n√£o temos motivo para supor o contr√°rio, podemos simplesmente considerar cada conjectura igualmente plaus√≠vel e comparar as contagens diretamente. Mas frequentemente temos motivo para supor o contr√°rio.

![](cap-02-small-worlds-large-worlds-pt/_page_5_Figure_2.jpeg)

Figura 2.4. O jardim de dados bifurcantes, mostrando para cada poss√≠vel composi√ß√£o do saco os caminhos bifurcantes que s√£o logicamente compat√≠veis com os dados.

> **Repensando: Justificativa.** Usar contagens de caminhos pelo jardim como medidas de plausibilidade relativa pode ser justificado de diversas maneiras. A justificativa aqui √© l√≥gica: se desejamos raciocinar sobre plausibilidade e permanecer consistentes com a l√≥gica ordin√°ria ‚Äî afirma√ß√µes sobre verdadeiro e falso ‚Äî ent√£o devemos obedecer a este procedimento. H√° diversas outras justificativas que levam ao mesmo procedimento matem√°tico. Independentemente de como voc√™ escolha justific√°-lo filosoficamente, note que ele realmente funciona. Justificativas e filosofia motivam procedimentos, mas s√£o os resultados que importam. As muitas aplica√ß√µes bem-sucedidas no mundo real da infer√™ncia bayesiana podem ser toda a justificativa que voc√™ precisa. Apenas tenha cuidado para n√£o supor que, porque a infer√™ncia bayesiana √© justificada, nenhuma outra abordagem tamb√©m pode ser justificada. Golems v√™m em muitos tipos, e alguns de todos os tipos s√£o √∫teis.

### Combinando outras informa√ß√µes {-}

Podemos ter informa√ß√µes adicionais sobre a plausibilidade relativa de cada conjectura. Essa informa√ß√£o pode surgir do conhecimento de como o conte√∫do do saco foi gerado. Pode tamb√©m surgir de dados anteriores. Seja qual for a fonte, seria √∫til ter uma maneira de combinar diferentes fontes de informa√ß√£o para atualizar as plausibilidades. Felizmente, h√° uma solu√ß√£o natural: basta multiplicar as contagens.

Para entender essa solu√ß√£o, suponha que estejamos dispostos a dizer que cada conjectura √© igualmente plaus√≠vel no in√≠cio. Ent√£o, simplesmente comparamos as contagens de maneiras em que cada conjectura √© compat√≠vel com os dados observados. Essa compara√ß√£o sugere que [üîµüîµüîµ‚ö™] √© ligeiramente mais plaus√≠vel que [üîµüîµ‚ö™‚ö™], e ambos s√£o cerca de tr√™s vezes mais plaus√≠veis que [üîµ‚ö™‚ö™‚ö™]. Como essas s√£o nossas contagens iniciais, e vamos atualiz√°-las em seguida, vamos rotul√°-las *a priori*.

Agora suponha que retiremos outra bolinha do saco para obter outra observa√ß√£o: üîµ. Agora voc√™ tem duas escolhas. Voc√™ poderia come√ßar tudo de novo, fazendo um jardim com quatro camadas para tra√ßar os caminhos compat√≠veis com a sequ√™ncia de dados üîµ ‚ö™ üîµ üîµ. Ou poderia pegar as contagens anteriores ‚Äî as contagens a priori ‚Äî sobre as conjecturas (0, 3, 8, 9, 0) e simplesmente atualiz√°-las √† luz da nova observa√ß√£o. Acontece que esses dois m√©todos s√£o matematicamente id√™nticos, desde que a nova observa√ß√£o seja logicamente independente das observa√ß√µes anteriores.

Veja como fazer isso. Primeiro, contamos o n√∫mero de maneiras que cada conjectura poderia produzir a nova observa√ß√£o, üîµ. Depois multiplicamos cada uma dessas novas contagens pelos n√∫meros a priori de maneiras para cada conjectura. Em forma de tabela:

| Conjectura | Maneiras de produzir üîµ | Contagens a priori | Nova contagem     |
|------------|-----------|--------|-------------------|
| [‚ö™‚ö™‚ö™‚ö™]   | 0         | 0      | $0 \times 0 = 0$  |
| [üîµ‚ö™‚ö™‚ö™]   | 1         | 3      | $3 \times 1 = 3$  |
| [üîµüîµ‚ö™‚ö™]   | 2         | 8      | $8 \times 2 = 16$ |
| [üîµüîµüîµ‚ö™]   | 3         | 9      | $9 \times 3 = 27$ |
| [üîµüîµüîµüîµ]   | 4         | 0      | $0 \times 4 = 0$  |

As novas contagens na coluna da direita acima resumem toda a evid√™ncia para cada conjectura. √Ä medida que novos dados chegam, e desde que esses dados sejam independentes das observa√ß√µes anteriores, o n√∫mero de maneiras logicamente poss√≠veis para uma conjectura produzir todos os dados at√© aquele ponto pode ser calculado simplesmente multiplicando a nova contagem pela contagem antiga.

Essa abordagem de atualiza√ß√£o nada mais √© do que afirmar que (1) quando temos informa√ß√£o anterior sugerindo que h√° $W_{\rm prior}$ maneiras para uma conjectura produzir uma observa√ß√£o anterior $D_{\rm prior}$ e (2) adquirimos novas observa√ß√µes $D_{\rm new}$ que a mesma conjectura pode produzir de $W_{\rm new}$ maneiras, ent√£o (3) o n√∫mero de maneiras que a conjectura pode explicar tanto $D_{\rm prior}$ quanto $D_{\rm new}$ √© simplesmente o produto $W_{\rm prior} \times W_{\rm new}$. Por exemplo, na tabela acima, a conjectura [üîµüîµ‚ö™‚ö™] tem $W_{\rm prior} = 8$ maneiras de produzir $D_{\rm prior} = üîµ‚ö™üîµ$. Ela tamb√©m tem $W_{\rm new} = 2$ maneiras de produzir a nova observa√ß√£o $D_{\rm new} = üîµ$. Portanto, h√° $8 \times 2 = 16$ maneiras para a conjectura produzir tanto $D_{\rm prior}$ quanto $D_{\rm new}$. Por que multiplicar? A multiplica√ß√£o √© apenas um atalho para enumerar e contar todos os caminhos pelo jardim que poderiam produzir todas as observa√ß√µes.

Neste exemplo, os dados a priori e os novos dados s√£o do mesmo tipo: bolinhas retiradas do saco. Mas, em geral, os dados a priori e os novos dados podem ser de tipos diferentes. Suponha, por exemplo, que algu√©m da f√°brica de bolinhas lhe diga que bolinhas azuis s√£o raras. Ent√£o, para cada saco contendo [üîµüîµüîµ‚ö™], eles fizeram dois sacos contendo [üîµüîµ‚ö™‚ö™] e tr√™s sacos contendo [üîµ‚ö™‚ö™‚ö™]. Eles tamb√©m garantiram que cada saco contivesse pelo menos uma bolinha azul e uma branca. Podemos atualizar nossas contagens novamente:

|  Conjectura   |  Contagem a priori  |   Contagem da f√°brica   |       Nova contagem             |
|---------------|---------------------|-------------------------|---------------------------------|
| [‚ö™‚ö™‚ö™‚ö™]    | 0                   | 0                       | $0 \times 0 = 0$                |
| [üîµ‚ö™‚ö™‚ö™]    | 3                   | 3                       | $3 \times 3 = 9$                |
| [üîµüîµ‚ö™‚ö™]    | 16                  | 2                       | $16 \times 2 = 32$              |
| [üîµüîµüîµ‚ö™]    | 27                  | 1                       | $27 \times 1 = 27$              |
| [üîµüîµüîµüîµ]    | 0                   | 0                       | $0 \times 0 = 0$                |

Agora a conjectura [üîµüîµ‚ö™‚ö™] √© a mais plaus√≠vel, mas apenas ligeiramente melhor que [üîµüîµüîµ‚ö™].

> **Repensando: Ignor√¢ncia original.** Qual suposi√ß√£o devemos usar quando n√£o h√° informa√ß√£o anterior sobre as conjecturas? A solu√ß√£o mais comum √© atribuir um n√∫mero igual de maneiras em que cada conjectura poderia estar correta, antes de ver quaisquer dados. Isso √© √†s vezes conhecido como o PRINC√çPIO DA INDIFEREN√áA: quando n√£o h√° raz√£o para dizer que uma conjectura √© mais plaus√≠vel que outra, pese todas as conjecturas igualmente.

### De contagens a probabilidades {-}

√â √∫til pensar nessa estrat√©gia como aderindo a um princ√≠pio de ignor√¢ncia honesta: quando n√£o sabemos o que causou os dados, causas potenciais que podem produzir os dados de mais maneiras s√£o mais plaus√≠veis. Isso nos leva a contar caminhos pelo jardim de dados bifurcantes.

√â dif√≠cil usar essas contagens, por√©m, ent√£o quase sempre as padronizamos de uma maneira que as transforma em probabilidades. Por que √© dif√≠cil trabalhar com as contagens? Primeiro, como o valor relativo √© tudo que importa, o tamanho das contagens 3, 8 e 9 n√£o cont√©m informa√ß√£o de valor. Elas poderiam ser igualmente 30, 80 e 90. O significado seria o mesmo. S√£o apenas os valores relativos que importam. Segundo, conforme a quantidade de dados cresce, as contagens crescer√£o muito rapidamente, tornando-se muito grandes e dif√≠ceis de manipular.

Felizmente, h√° uma maneira matem√°tica de comprimir tudo isso. Especificamente, definimos a plausibilidade atualizada de cada poss√≠vel composi√ß√£o do saco, ap√≥s ver os dados, como:

$$ \texttt{plausibilidade de [üîµ‚ö™‚ö™‚ö™] ap√≥s ver üîµ‚ö™üîµ }$$
$$\propto$$
$$ \texttt{maneiras que [üîµ‚ö™‚ö™‚ö™] pode produzir üîµ‚ö™üîµ }$$
$$\times$$
$$ \texttt{plausibilidade a priori de [üîµ‚ö™‚ö™‚ö™] }$$

Aquele pequeno $\propto$ significa *proporcional a*. Queremos comparar a plausibilidade de cada poss√≠vel composi√ß√£o do saco. Ent√£o ser√° √∫til definir p como a propor√ß√£o de bolinhas que s√£o azuis. Para [üîµ‚ö™‚ö™‚ö™], p = 1/4 = 0,25. Tamb√©m defina $D_{\text{new}} = üîµ‚ö™üîµ$. E agora podemos escrever:

> plausibilidade de p ap√≥s $D_{\text{new}} \propto \text{maneiras que } p$ pode produzir $D_{\text{new}} \times \text{plausibilidade a priori de } p$

O acima apenas significa que, para qualquer valor que p possa assumir, julgamos a plausibilidade desse valor p como proporcional ao n√∫mero de maneiras que ele pode passar pelo jardim de dados bifurcantes.

Finalmente, constru√≠mos probabilidades padronizando a plausibilidade de modo que a soma das plausibilidades para todas as conjecturas poss√≠veis seja um. Tudo o que voc√™ precisa fazer para padronizar √© somar todos os produtos, um para cada valor que p pode assumir, e depois dividir cada produto pela soma dos produtos:

$$\texttt{plausibilidade de p ap√≥s} D_{\text{new}} = \frac{\text{maneiras que } p \text{ pode produzir } D_{\text{new}} \times \text{plausibilidade a priori de } p}{\text{soma dos produtos}}$$

Um exemplo trabalhado √© necess√°rio para que isso realmente fa√ßa sentido. Ent√£o considere novamente a tabela de antes, agora atualizada usando nossas defini√ß√µes de *p* e "plausibilidade":

| Composi√ß√£o poss√≠vel | p       | Maneiras de produzir dados | Plausibilidade |
|---------------------|---------|----------------------------|----------------|
| [‚ö™‚ö™‚ö™‚ö™]           | 0       | 0                          | 0              |
| [üîµ‚ö™‚ö™‚ö™]           | 0,25    | 3                          | 0,15           |
| [üîµüîµ‚ö™‚ö™]           | 0,5     | 8                          | 0,40           |
| [üîµüîµüîµ‚ö™]           | 0,75    | 9                          | 0,45           |
| [üîµüîµüîµüîµ]           | 1       | 0                          | 0              |

Voc√™ pode calcular rapidamente essas plausibilidades em R:

```{r}
ways <- c( 0 , 3 , 8 , 9 , 0 )
ways/sum(ways)
```

```
[1] 0.00 0.15 0.40 0.45 0.00
```

Os valores em ways s√£o os produtos mencionados antes. E sum(ways) √© o denominador "soma dos produtos" na express√£o perto do topo da p√°gina.

Essas plausibilidades tamb√©m s√£o *probabilidades* ‚Äî s√£o n√∫meros reais n√£o negativos (zero ou positivos) que somam um. E todas as coisas matem√°ticas que voc√™ pode fazer com probabilidades tamb√©m pode fazer com esses valores. Especificamente, cada pe√ßa do c√°lculo tem um parceiro direto na teoria da probabilidade aplicada. Esses parceiros t√™m nomes estereotipados, ent√£o vale a pena aprend√™-los, pois voc√™ os ver√° repetidamente.

- Um valor conjecturado da propor√ß√£o de bolinhas azuis, *p*, √© geralmente chamado de valor de **PAR√ÇMETRO**. √â apenas uma maneira de indexar explica√ß√µes poss√≠veis dos dados.
- O n√∫mero relativo de maneiras que um valor *p* pode produzir os dados √© geralmente chamado de **VEROSSIMILHAN√áA**. √â derivada enumerando todas as sequ√™ncias de dados poss√≠veis que poderiam ter acontecido e depois eliminando aquelas sequ√™ncias inconsistentes com os dados.
- A plausibilidade a priori de qualquer *p* espec√≠fico √© geralmente chamada de **PROBABILIDADE A PRIORI**.
- A nova plausibilidade atualizada de qualquer *p* espec√≠fico √© geralmente chamada de **PROBABILIDADE A POSTERIORI**.

> **Repensando: Aleatoriza√ß√£o.** Quando voc√™ embaralha um baralho de cartas ou atribui sujeitos a tratamentos jogando uma moeda, √© comum dizer que o baralho resultante e as atribui√ß√µes de tratamento s√£o aleatorizados. O que significa aleatorizar algo? Significa apenas que processamos a coisa de modo que sabemos quase nada sobre seu arranjo. Embaralhar um baralho de cartas muda nosso estado de conhecimento, de modo que n√£o temos mais informa√ß√£o espec√≠fica sobre a ordena√ß√£o das cartas. Entretanto, o b√¥nus que surge disso √© que, se realmente embaralhamos o suficiente para apagar qualquer conhecimento pr√©vio da ordena√ß√£o, ent√£o a ordem em que as cartas terminam √© muito provavelmente uma das muitas ordena√ß√µes com alta **entropia informacional**.

## Construindo um modelo

Ao trabalhar com probabilidades em vez de contagens brutas, a infer√™ncia bayesiana se torna muito mais f√°cil, mas parece muito mais dif√≠cil. Ent√£o, nesta se√ß√£o, damos sequ√™ncia ao jardim de dados bifurcantes apresentando a forma convencional de um modelo estat√≠stico bayesiano. O exemplo did√°tico que usaremos aqui tem a anatomia de uma an√°lise estat√≠stica t√≠pica, ent√£o √© o estilo ao qual voc√™ se acostumar√°. Mas cada pe√ßa dele pode ser mapeada no jardim de dados bifurcantes. A l√≥gica √© a mesma.

Suponha que voc√™ tenha um globo terrestre representando nosso planeta, a Terra. Essa vers√£o do mundo √© pequena o suficiente para caber em suas m√£os. Voc√™ tem curiosidade sobre quanta da superf√≠cie √© coberta por √°gua. Voc√™ adota a seguinte estrat√©gia: jogar√° o globo para cima. Quando peg√°-lo, registrar√° se a superf√≠cie sob seu dedo indicador direito √© √°gua ou terra. Ent√£o jogar√° o globo para cima novamente e repetir√° o procedimento. Essa estrat√©gia gera uma sequ√™ncia de amostras da superf√≠cie do globo. As primeiras nove amostras podem parecer com:

$$\text{W L W W W L W L W}$$

onde $\text{W}$ indica √°gua (water) e $\text{L}$ indica terra (land). Ent√£o, neste exemplo, voc√™ observa seis observa√ß√µes $\text{W}$ (√°gua) e tr√™s observa√ß√µes $\text{L}$ (terra). Chame essa sequ√™ncia de observa√ß√µes de dados.

Para colocar a l√≥gica em movimento, precisamos fazer suposi√ß√µes, e essas suposi√ß√µes constituem o modelo. Projetar um modelo bayesiano simples se beneficia de um ciclo de design com tr√™s etapas.

- (1) Hist√≥ria dos dados: motive o modelo narrando como os dados podem ter surgido.
- (2) Atualiza√ß√£o: eduque seu modelo alimentando-o com os dados.
- (3) Avalia√ß√£o: todos os modelos estat√≠sticos requerem supervis√£o, levando possivelmente √† revis√£o do modelo.

As pr√≥ximas se√ß√µes percorrem essas etapas, no contexto da evid√™ncia do lan√ßamento do globo.

### Uma hist√≥ria dos dados {-}

A an√°lise bayesiana de dados geralmente significa produzir uma hist√≥ria para como os dados vieram a existir. Essa hist√≥ria pode ser descritiva, especificando associa√ß√µes que podem ser usadas para prever resultados, dadas observa√ß√µes. Ou pode ser causal, uma teoria de como alguns eventos produzem outros eventos. Tipicamente, qualquer hist√≥ria que voc√™ pretenda ser causal tamb√©m pode ser descritiva. Mas muitas hist√≥rias descritivas s√£o dif√≠ceis de interpretar causalmente. Contudo, todas as hist√≥rias de dados s√£o completas, no sentido de que s√£o suficientes para especificar um algoritmo para simular novos dados.

Voc√™ pode motivar sua hist√≥ria dos dados tentando explicar como cada dado nasce. Isso geralmente significa descrever aspectos da realidade subjacente, bem como o processo de amostragem. A hist√≥ria dos dados neste caso √© simplesmente uma reformula√ß√£o do processo de amostragem:

- (1) A verdadeira propor√ß√£o de √°gua cobrindo o globo √© $p$.
- (2) Um √∫nico lan√ßamento do globo tem probabilidade $p$ de produzir uma observa√ß√£o de √°gua ($\text{W}$). Tem probabilidade $1-p$ de produzir uma observa√ß√£o de terra ($\text{L}$).
- (3) Cada lan√ßamento do globo √© independente dos outros.

### Atualiza√ß√£o bayesiana {-}

Nosso problema √© usar a evid√™ncia ‚Äî a sequ√™ncia de lan√ßamentos do globo ‚Äî para decidir entre diferentes propor√ß√µes poss√≠veis de √°gua no globo. Essas propor√ß√µes s√£o como as bolinhas conjecturadas dentro do saco, de antes neste cap√≠tulo. Cada propor√ß√£o poss√≠vel pode ser mais ou menos plaus√≠vel, dada a evid√™ncia. Um modelo bayesiano come√ßa com um conjunto de plausibilidades atribu√≠das a cada uma dessas possibilidades. Essas s√£o as plausibilidades a priori. Ent√£o ele as atualiza √† luz dos dados, para produzir as plausibilidades a posteriori. Esse processo de atualiza√ß√£o √© um tipo de aprendizado, chamado **atualiza√ß√£o bayesiana**.

Apenas para efeito do exemplo, vamos programar nossa m√°quina bayesiana para atribuir inicialmente a mesma plausibilidade a cada propor√ß√£o de √°gua, cada valor de p. Depois faremos melhor que isso. Agora olhe o gr√°fico superior esquerdo na Figura 2.5. A linha horizontal tracejada representa essa plausibilidade inicial de cada valor poss√≠vel de p. Ap√≥s ver o primeiro lan√ßamento, que √© um "W", o modelo atualiza as plausibilidades para a linha s√≥lida. A plausibilidade de p = 0 caiu agora para exatamente zero ‚Äî o equivalente a "imposs√≠vel". Por qu√™? Porque observamos pelo menos uma parcela de √°gua no globo, ent√£o agora sabemos que h√° alguma √°gua. O modelo executa essa l√≥gica automaticamente. Voc√™ n√£o precisa instru√≠-lo a considerar essa consequ√™ncia. A teoria da probabilidade cuida disso para voc√™, porque √© essencialmente contagem de caminhos pelo jardim de dados bifurcantes, como na se√ß√£o anterior.

Da mesma forma, a plausibilidade de p > 0,5 aumentou. Isso ocorre porque ainda n√£o h√° evid√™ncia de que haja terra no globo, ent√£o as plausibilidades iniciais s√£o modificadas para serem consistentes com isso. Note, entretanto, que s√£o as plausibilidades relativas que importam, e ainda n√£o h√°

![](cap-02-small-worlds-large-worlds-pt/_page_11_Figure_2.jpeg)

Figura 2.5. Como um modelo bayesiano aprende. Cada lan√ßamento do globo produz uma observa√ß√£o de √°gua (W) ou terra (L). A estimativa do modelo da propor√ß√£o de √°gua no globo √© uma plausibilidade para cada valor poss√≠vel. As linhas e curvas nesta figura s√£o essas cole√ß√µes de plausibilidades. Em cada gr√°fico, plausibilidades anteriores (curva tracejada) s√£o atualizadas √† luz da √∫ltima observa√ß√£o para produzir um novo conjunto de plausibilidades (curva s√≥lida).

muita evid√™ncia. Portanto, as diferen√ßas em plausibilidade ainda n√£o s√£o muito grandes. Dessa forma, a quantidade de evid√™ncia vista at√© agora √© incorporada nas plausibilidades de cada valor de p.

Nos gr√°ficos restantes da Figura 2.5, as amostras adicionais do globo s√£o introduzidas ao modelo, uma de cada vez. Cada curva tracejada √© simplesmente a curva s√≥lida do gr√°fico anterior, movendo-se da esquerda para a direita e de cima para baixo. Toda vez que um "W" √© visto, o pico da curva de plausibilidade se move para a direita, em dire√ß√£o a valores maiores de p. Toda vez que um "L" √© visto, ela se move na outra dire√ß√£o. A altura m√°xima da curva aumenta com cada amostra, significando que menos valores de p acumulam mais plausibilidade conforme a quantidade de evid√™ncia aumenta. Conforme cada nova observa√ß√£o √© adicionada, a curva √© atualizada de maneira consistente com todas as observa√ß√µes anteriores.

Note que cada conjunto atualizado de plausibilidades se torna as plausibilidades iniciais para a pr√≥xima observa√ß√£o. Toda conclus√£o √© o ponto de partida para infer√™ncia futura. Contudo, esse processo de atualiza√ß√£o funciona tanto para tr√°s quanto para frente. Dado o conjunto final de plausibilidades no gr√°fico inferior direito da Figura 2.5, e sabendo a observa√ß√£o final (W), √© poss√≠vel matematicamente dividir a observa√ß√£o, para inferir a curva de plausibilidade anterior. Ent√£o os dados poderiam ser apresentados ao seu modelo em qualquer ordem, ou todos de uma vez. Na maioria dos casos, voc√™ apresentar√° os dados todos de uma vez, por conveni√™ncia. Mas √© importante perceber que isso meramente representa a abrevia√ß√£o de um processo iterativo de aprendizado.

> **Repensando: Tamanho amostral e infer√™ncia confi√°vel.** √â comum ouvir que h√° um n√∫mero m√≠nimo de observa√ß√µes para uma estimativa estat√≠stica √∫til. Por exemplo, h√° uma supersti√ß√£o difundida de que 30 observa√ß√µes s√£o necess√°rias antes de se poder usar uma distribui√ß√£o gaussiana. Por qu√™? Na infer√™ncia estat√≠stica n√£o bayesiana, os procedimentos s√£o frequentemente justificados pelo comportamento do m√©todo com tamanhos amostrais muito grandes, o chamado comportamento assint√≥tico. Como resultado, o desempenho com tamanhos amostrais pequenos √© question√°vel.
>
> Em contraste, estimativas bayesianas s√£o v√°lidas para qualquer tamanho amostral. Isso n√£o significa que mais dados n√£o ajudem ‚Äî certamente ajudam. Em vez disso, as estimativas t√™m uma interpreta√ß√£o clara e v√°lida, independentemente do tamanho amostral. Mas o pre√ßo desse poder √© a depend√™ncia das plausibilidades iniciais, a distribui√ß√£o a priori. Se a distribui√ß√£o a priori for ruim, a infer√™ncia resultante ser√° enganosa. N√£o h√° almo√ßo gr√°tis quando se trata de aprender sobre o mundo. Um golem bayesiano deve escolher uma plausibilidade inicial, e um golem n√£o bayesiano deve escolher um estimador. Ambos os golems pagam pelo almo√ßo com suas suposi√ß√µes.

### Avalia√ß√£o {-}

O modelo bayesiano aprende de uma maneira que √© comprovadamente √≥tima, desde que o mundo real, o mundo grande, seja descrito com precis√£o pelo modelo. Ou seja, sua m√°quina bayesiana garante infer√™ncia perfeita, dentro do mundo pequeno. Nenhuma outra maneira de usar a informa√ß√£o dispon√≠vel, e come√ßando com o mesmo estado de informa√ß√£o, poderia fazer melhor.

N√£o fique muito empolgado com essa virtude l√≥gica, contudo. Os c√°lculos podem falhar, ent√£o os resultados sempre precisam ser verificados. E se houver diferen√ßas importantes entre o modelo e a realidade, ent√£o n√£o h√° garantia l√≥gica de desempenho no mundo grande. E mesmo que os dois mundos coincidissem, qualquer amostra particular de dados poderia ainda ser enganosa. Ent√£o vale a pena manter em mente pelo menos dois princ√≠pios cautelosos.

Primeiro, a certeza do modelo n√£o √© garantia de que o modelo √© bom. Conforme a quantidade de dados aumenta, o modelo de lan√ßamento do globo ficar√° cada vez mais seguro da propor√ß√£o de √°gua. Isso significa que as curvas na Figura 2.5 se tornar√£o cada vez mais estreitas e altas, restringindo valores plaus√≠veis dentro de uma faixa muito estreita. Mas modelos de todos os tipos ‚Äî bayesianos ou n√£o ‚Äî podem ser muito confiantes sobre uma infer√™ncia, mesmo quando o modelo √© seriamente enganoso. Isso ocorre porque as infer√™ncias s√£o condicionais ao modelo.

Segundo, √© importante supervisionar e criticar o trabalho do seu modelo. Considere novamente o fato de que a atualiza√ß√£o na se√ß√£o anterior funciona em qualquer ordem de chegada dos dados. Poder√≠amos embaralhar a ordem das observa√ß√µes, contanto que seis W's e tr√™s L's permane√ßam, e ainda terminar com a mesma curva de plausibilidade final. Isso s√≥ √© verdade, contudo, porque o modelo assume que a ordem √© irrelevante para a infer√™ncia. Quando algo √© irrelevante para a m√°quina, n√£o afetar√° a infer√™ncia diretamente. Mas pode afet√°-la indiretamente, porque os dados depender√£o da ordem. Ent√£o √© importante verificar as infer√™ncias do modelo √† luz de aspectos dos dados que ele n√£o conhece. Tais verifica√ß√µes s√£o um empreendimento inerentemente criativo, deixado para o analista e a comunidade cient√≠fica. Golems s√£o muito ruins nisso.

O objetivo n√£o √© testar o valor de verdade das suposi√ß√µes do modelo. Sabemos que as suposi√ß√µes do modelo nunca s√£o exatamente corretas, no sentido de corresponder ao verdadeiro processo gerador de dados. Portanto, n√£o h√° motivo para verificar se o modelo √© verdadeiro. A falha em concluir que um modelo √© falso deve ser uma falha de nossa imagina√ß√£o, n√£o um sucesso do modelo. Al√©m disso, modelos n√£o precisam ser exatamente verdadeiros para produzir infer√™ncias altamente precisas e √∫teis. Em vez disso, o objetivo √© verificar a adequa√ß√£o do modelo para algum prop√≥sito.

> **Repensando: Estat√≠stica deflacion√°ria.** Pode ser que a infer√™ncia bayesiana seja o melhor m√©todo de infer√™ncia de prop√≥sito geral conhecido. Contudo, a infer√™ncia bayesiana √© muito menos poderosa do que gostar√≠amos que fosse. N√£o h√° abordagem √† infer√™ncia que forne√ßa garantias universais. Nenhum ramo da matem√°tica aplicada tem acesso irrestrito √† realidade, porque a matem√°tica n√£o √© descoberta, como o pr√≥ton. Em vez disso, ela √© inventada, como a p√°.

## Componentes do modelo

Agora que voc√™ viu como o modelo bayesiano se comporta, √© hora de abrir a m√°quina e aprender como ela funciona. Considere tr√™s tipos diferentes de coisas que contamos nas se√ß√µes anteriores.

- (1) O n√∫mero de maneiras que cada conjectura poderia produzir uma observa√ß√£o
- (2) O n√∫mero acumulado de maneiras que cada conjectura poderia produzir os dados inteiros
- (3) A plausibilidade inicial de cada causa conjecturada dos dados

Cada uma dessas coisas tem um an√°logo direto na teoria da probabilidade convencional. E assim, a maneira usual de construir um modelo estat√≠stico envolve escolher distribui√ß√µes e dispositivos para cada uma que representem os n√∫meros relativos de maneiras que as coisas podem acontecer.

### Vari√°veis {-}

Vari√°veis s√£o simplesmente s√≠mbolos que podem assumir diferentes valores. Em um contexto cient√≠fico, vari√°veis incluem coisas que desejamos inferir, como propor√ß√µes e taxas, bem como coisas que podemos observar, os dados. No modelo de lan√ßamento do globo, h√° tr√™s vari√°veis.

A primeira vari√°vel √© nosso alvo de infer√™ncia, p, a propor√ß√£o de √°gua no globo. Essa vari√°vel n√£o pode ser observada. Vari√°veis n√£o observadas s√£o geralmente chamadas de **par√¢metros**. Mas, embora p em si n√£o seja observado, podemos inferi-lo a partir das outras vari√°veis.

As outras vari√°veis s√£o as vari√°veis observadas, as contagens de √°gua e terra. Chame a contagem de √°gua de W e a contagem de terra de L. A soma dessas duas vari√°veis √© o n√∫mero de lan√ßamentos do globo: N = W + L.

### Defini√ß√µes {-}

Uma vez que temos as vari√°veis listadas, precisamos definir cada uma delas. Ao definir cada uma, constru√≠mos um modelo que relaciona as vari√°veis umas √†s outras. Lembre-se, o objetivo √© contar todas as maneiras que os dados poderiam surgir, dadas as suposi√ß√µes.

#### Vari√°veis observadas {-}

Para a contagem de √°gua W e terra L, definimos qu√£o plaus√≠vel qualquer combina√ß√£o de W e L seria, para um valor espec√≠fico de p. Cada valor espec√≠fico de p corresponde a uma plausibilidade espec√≠fica dos dados, como na Figura 2.5.

Para que n√£o tenhamos que literalmente contar, podemos usar uma fun√ß√£o matem√°tica que nos diz a plausibilidade correta. Na estat√≠stica convencional, uma fun√ß√£o de distribui√ß√£o atribu√≠da a uma vari√°vel observada √© geralmente chamada de **verossimilhan√ßa**.

No caso do modelo de lan√ßamento do globo, a fun√ß√£o que precisamos pode ser derivada diretamente da hist√≥ria dos dados. Uma vez que adicionamos nossas suposi√ß√µes de que (1) cada lan√ßamento √© independente dos outros e (2) a probabilidade de W √© a mesma em cada lan√ßamento, a teoria da probabilidade fornece uma resposta √∫nica, conhecida como distribui√ß√£o binomial. E assim a probabilidade de observar W √°guas e L terras, com probabilidade p de √°gua em cada lan√ßamento, √©:

$$\Pr(W, L|p) = \frac{(W+L)!}{W!L!} p^{W} (1-p)^{L}$$

Leia o acima como:

> *As contagens de "√°gua" W e "terra" L s√£o distribu√≠das binomialmente, com probabilidade p de "√°gua" em cada lan√ßamento.*

E a f√≥rmula da distribui√ß√£o binomial est√° embutida no R, ent√£o voc√™ pode facilmente calcular a verossimilhan√ßa dos dados ‚Äî seis W's em nove lan√ßamentos ‚Äî sob qualquer valor de p com:

```{r}
dbinom( 6 , size=9 , prob=0.5 )
```

```
[1] 0.1640625
```

Esse n√∫mero √© o n√∫mero relativo de maneiras de obter seis √°guas, mantendo p em 0,5 e $N = W + L$ em nove. Ent√£o ele faz o trabalho de contar o n√∫mero relativo de caminhos pelo jardim. Mude o 0,5 para qualquer outro valor, para ver como o valor muda.

> **Pensando Mais um Pouco: Nomes e distribui√ß√µes de probabilidade.** O "d" em `dbinom` significa *densidade*. Fun√ß√µes nomeadas assim quase sempre t√™m parceiras correspondentes que come√ßam com "r" para amostras aleat√≥rias e que come√ßam com "p" para probabilidades acumuladas. Veja, por exemplo, a ajuda `?dbinom`.

#### Vari√°veis n√£o observadas {-}

As distribui√ß√µes que atribu√≠mos √†s vari√°veis observadas tipicamente t√™m suas pr√≥prias vari√°veis. Na binomial acima, h√° p, a probabilidade de amostrar √°gua. Como p n√£o √© observado, geralmente o chamamos de **PAR√ÇMETRO**. Embora n√£o possamos observar p, ainda precisamos defini-lo.

Na modelagem estat√≠stica, muitas das perguntas mais comuns que fazemos sobre dados s√£o respondidas diretamente por par√¢metros:

- Qual √© a diferen√ßa m√©dia entre grupos de tratamento?
- Qu√£o forte √© a associa√ß√£o entre um tratamento e um resultado?
- O efeito do tratamento depende de uma covari√°vel?
- Quanta varia√ß√£o h√° entre grupos?

Para cada par√¢metro que voc√™ pretende que sua m√°quina bayesiana considere, voc√™ deve fornecer uma distribui√ß√£o de plausibilidade a priori, sua **DISTRIBUI√á√ÉO A PRIORI**. Uma m√°quina bayesiana deve ter uma atribui√ß√£o inicial de plausibilidade para cada valor poss√≠vel do par√¢metro, e essas atribui√ß√µes iniciais fazem trabalho √∫til.

Ent√£o, de onde v√™m as distribui√ß√µes a priori? Elas s√£o tanto suposi√ß√µes de engenharia, escolhidas para ajudar a m√°quina a aprender, quanto suposi√ß√µes cient√≠ficas, escolhidas para refletir o que sabemos sobre um fen√¥meno. A distribui√ß√£o a priori plana na Figura 2.5 √© muito comum, mas raramente √© a melhor distribui√ß√£o a priori.

> **Pensando Mais um Pouco: A distribui√ß√£o a priori como distribui√ß√£o de probabilidade.** Voc√™ poderia escrever a distribui√ß√£o a priori no exemplo aqui como:
>
>$$\Pr(p) = \frac{1}{1-0} = 1.$$
>
>A distribui√ß√£o a priori √© uma distribui√ß√£o de probabilidade para o par√¢metro. Em geral, para uma distribui√ß√£o a priori uniforme de a at√© b, a probabilidade de qualquer ponto no intervalo √© 1/(b-a). Se voc√™ est√° incomodado pelo fato de que a probabilidade de cada valor de p √© 1, lembre-se de que toda distribui√ß√£o de probabilidade deve somar (integrar) para 1. A express√£o 1/(b-a) garante que a √°rea sob a linha plana de a at√© b √© igual a 1.

> **Repensando: Dado ou par√¢metro?** √â t√≠pico conceber dados e par√¢metros como tipos de entidades completamente diferentes. Dados s√£o mensurados e conhecidos; par√¢metros s√£o desconhecidos e devem ser estimados a partir dos dados. Utilmente, no framework bayesiano, a distin√ß√£o entre um dado e um par√¢metro n√£o √© t√£o fundamental. √Äs vezes observamos uma vari√°vel, mas √†s vezes n√£o. Nesse caso, a mesma fun√ß√£o de distribui√ß√£o se aplica, mesmo que n√£o tenhamos observado a vari√°vel. Como resultado, a mesma suposi√ß√£o pode parecer uma "verossimilhan√ßa" ou uma "distribui√ß√£o a priori", dependendo do contexto, sem qualquer mudan√ßa no modelo.

### Um modelo nasce {-}

Com todo o trabalho acima, podemos agora resumir nosso modelo. As vari√°veis observadas W e L recebem contagens relativas atrav√©s da distribui√ß√£o binomial. Ent√£o podemos escrever, como atalho:

$$W \sim \text{Binomial}(N, p)$$

onde N = W + L. O acima √© apenas uma conven√ß√£o para comunicar a suposi√ß√£o de que as contagens relativas de maneiras de realizar W em N tentativas com probabilidade p em cada tentativa v√™m da distribui√ß√£o binomial. E o par√¢metro n√£o observado p similarmente recebe:

$$p \sim \text{Uniform}(0,1)$$

Isso significa que p tem uma distribui√ß√£o a priori uniforme ‚Äî plana ‚Äî sobre toda a sua faixa poss√≠vel, de zero a um. Como mencionei anteriormente, isso obviamente n√£o √© o melhor que poder√≠amos fazer, pois sabemos que a Terra tem mais √°gua que terra, mesmo que ainda n√£o saibamos a propor√ß√£o exata.

## Fazendo o modelo funcionar

Uma vez que voc√™ nomeou todas as vari√°veis e escolheu defini√ß√µes para cada uma, um modelo bayesiano pode atualizar todas as distribui√ß√µes a priori para suas consequ√™ncias puramente l√≥gicas: a **distribui√ß√£o a posteriori**. Para cada combina√ß√£o √∫nica de dados, verossimilhan√ßa, par√¢metros e distribui√ß√£o a priori, h√° uma distribui√ß√£o a posteriori √∫nica. Essa distribui√ß√£o cont√©m a plausibilidade relativa de diferentes valores de par√¢metros, condicional nos dados e no modelo. A distribui√ß√£o a posteriori assume a forma da probabilidade dos par√¢metros, condicional nos dados. Neste caso, seria Pr(p|W, L), a probabilidade de cada valor poss√≠vel de p, condicional nos W e L espec√≠ficos que observamos.

### O teorema de Bayes {-}

A defini√ß√£o matem√°tica da distribui√ß√£o a posteriori surge do **teorema de Bayes**. Este √© o teorema que d√° √† an√°lise bayesiana de dados seu nome. Mas o teorema em si √© uma implica√ß√£o trivial da teoria da probabilidade.

A probabilidade conjunta dos dados W e L e qualquer valor particular de p √©:

$$\Pr(W, L, p) = \Pr(W, L|p) \Pr(p)$$

Isso apenas diz que a probabilidade de W, L e p √© o produto de Pr(W, L|p) e a probabilidade a priori Pr(p). √â como dizer que a probabilidade de chuva e frio no mesmo dia √© igual √† probabilidade de chuva, quando est√° frio, vezes a probabilidade de que esteja frio. At√© aqui √© apenas defini√ß√£o. Mas √© igualmente verdade que:

$$\Pr(W, L, p) = \Pr(p|W, L) \Pr(W, L)$$

Tudo o que fiz foi inverter qual probabilidade √© condicional, no lado direito. Agora, como ambos os lados direitos acima s√£o iguais √† mesma coisa, Pr(W, L, p), eles tamb√©m s√£o iguais entre si:

$$\Pr(W, L|p) \Pr(p) = \Pr(p|W, L) \Pr(W, L)$$

Ent√£o podemos agora resolver para o que queremos, Pr(p|W, L):

$$\Pr(p|W,L) = \frac{\Pr(W,L|p)\Pr(p)}{\Pr(W,L)}$$

E este √© o teorema de Bayes. Ele diz que a probabilidade de qualquer valor particular de p, considerando os dados, √© igual ao produto da plausibilidade relativa dos dados, condicional em p, e da plausibilidade a priori de p, dividido pela probabilidade m√©dia dos dados. Em forma de palavras:

$$Posterior = \frac{\text{Probabilidade dos dados} \times \text{A priori}}{\text{Probabilidade m√©dia dos dados}}$$

A probabilidade m√©dia dos dados, Pr(W, L), √© literalmente a probabilidade m√©dia dos dados. M√©dia sobre o qu√™? Sobre a distribui√ß√£o a priori. Seu trabalho √© apenas padronizar a distribui√ß√£o a posteriori, para garantir que ela some (integre) para um. Em forma matem√°tica:

$$\Pr(W, L) = \mathbb{E}(\Pr(W, L|p)) = \int \Pr(W, L|p) \Pr(p) dp$$

A li√ß√£o principal √© que a distribui√ß√£o a posteriori √© proporcional ao produto da distribui√ß√£o a priori e da probabilidade dos dados.

![](cap-02-small-worlds-large-worlds-pt/_page_19_Figure_2.jpeg)

Figura 2.6. A distribui√ß√£o a posteriori, como produto da distribui√ß√£o a priori e da verossimilhan√ßa. Linha superior: uma distribui√ß√£o a priori plana constr√≥i uma distribui√ß√£o a posteriori que √© simplesmente proporcional √† verossimilhan√ßa. Linha do meio: uma distribui√ß√£o a priori em degrau, atribuindo probabilidade zero a todos os valores menores que 0,5, resultando em uma distribui√ß√£o a posteriori truncada. Linha inferior: uma distribui√ß√£o a priori com pico que desloca e distorce a distribui√ß√£o a posteriori, relativamente √† verossimilhan√ßa.

A Figura 2.6 ilustra a intera√ß√£o multiplicativa de uma distribui√ß√£o a priori e uma probabilidade dos dados. Em cada linha, uma distribui√ß√£o a priori √† esquerda √© multiplicada pela probabilidade dos dados no meio para produzir uma distribui√ß√£o a posteriori √† direita. A probabilidade dos dados em cada caso √© a mesma. As distribui√ß√µes a priori, contudo, variam. Como resultado, as distribui√ß√µes a posteriori variam.

### Motores de estima√ß√£o {-}

Lembre-se de que seu modelo bayesiano √© uma m√°quina, um golem figurativo. Ele tem defini√ß√µes embutidas para a verossimilhan√ßa, os par√¢metros e a distribui√ß√£o a priori. E ent√£o, em seu cora√ß√£o, reside um motor que processa dados, produzindo uma distribui√ß√£o a posteriori.

V√°rias t√©cnicas num√©ricas s√£o necess√°rias para aproximar a matem√°tica que segue da defini√ß√£o do teorema de Bayes. H√° tr√™s motores de condicionamento diferentes, t√©cnicas num√©ricas para calcular distribui√ß√µes a posteriori:

- (1) Aproxima√ß√£o por grade
- (2) Aproxima√ß√£o quadr√°tica
- (3) Markov chain Monte Carlo (MCMC)

H√° muitos outros motores, e novos est√£o sendo inventados o tempo todo. Mas os tr√™s acima s√£o comuns e amplamente √∫teis.

### Aproxima√ß√£o por grade {-}

Uma das t√©cnicas de condicionamento mais simples √© a aproxima√ß√£o por grade. Embora a maioria dos par√¢metros seja *cont√≠nua*, capaz de assumir um n√∫mero infinito de valores, acontece que podemos alcan√ßar uma excelente aproxima√ß√£o da distribui√ß√£o a posteriori cont√≠nua considerando apenas uma grade finita de valores de par√¢metros. Em qualquer valor particular de um par√¢metro, p', √© simples calcular a probabilidade a posteriori: basta multiplicar a probabilidade a priori de p' pela verossimilhan√ßa em p'. Repetir esse procedimento para cada valor na grade gera uma imagem aproximada da distribui√ß√£o a posteriori exata. Esse procedimento √© chamado de **APROXIMA√á√ÉO POR GRADE**.

A aproxima√ß√£o por grade ser√° principalmente √∫til como ferramenta pedag√≥gica, pois aprend√™-la for√ßa o usu√°rio a realmente entender a natureza da atualiza√ß√£o bayesiana. Mas na maioria da sua modelagem real, a aproxima√ß√£o por grade n√£o √© pr√°tica, porque ela escala muito mal conforme o n√∫mero de par√¢metros aumenta.

No contexto do problema de lan√ßamento do globo, a aproxima√ß√£o por grade funciona extremamente bem. Aqui est√° a receita:

- (1) Defina a grade. Isso significa que voc√™ decide quantos pontos usar na estima√ß√£o da distribui√ß√£o a posteriori e ent√£o faz uma lista dos valores de par√¢metros na grade.
- (2) Calcule o valor da distribui√ß√£o a priori em cada valor de par√¢metro na grade.
- (3) Calcule a verossimilhan√ßa em cada valor de par√¢metro.
- (4) Calcule a distribui√ß√£o a posteriori n√£o padronizada em cada valor de par√¢metro, multiplicando a distribui√ß√£o a priori pela verossimilhan√ßa.
- (5) Finalmente, padronize a distribui√ß√£o a posteriori, dividindo cada valor pela soma de todos os valores.

No contexto do lan√ßamento do globo, aqui est√° o c√≥digo para completar todas as cinco etapas:

```{r}
# define grid
p_grid <- seq( from=0 , to=1 , length.out=20 )

# define prior
prior <- rep( 1 , 20 )

# compute likelihood at each value in grid
likelihood <- dbinom( 6 , size=9 , prob=p_grid )

# compute product of likelihood and prior
unstd.posterior <- likelihood * prior

# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
```

O c√≥digo acima faz uma grade de apenas 20 pontos. Para exibir a distribui√ß√£o a posteriori agora:

```{r}
plot( p_grid , posterior , type="b" ,
      xlab="probability of water" , ylab="posterior probability" )
mtext( "20 points" )
```

|  |  |
|:--------:|:--------:|
| ![](cap-02-small-worlds-large-worlds-pt/_page_22_Figure_2.jpeg) | ![](cap-02-small-worlds-large-worlds-pt/_page_22_Figure_3.jpeg) |

Figura 2.7. Calculando a distribui√ß√£o a posteriori por aproxima√ß√£o por grade. Em cada gr√°fico, a distribui√ß√£o a posteriori para os dados e modelo de lan√ßamento do globo √© aproximada com um n√∫mero finito de pontos igualmente espa√ßados. Com apenas 5 pontos (esquerda), a aproxima√ß√£o √© terr√≠vel. Mas com 20 pontos (direita), a aproxima√ß√£o j√° √© bastante boa.

Voc√™ obter√° o gr√°fico da direita na Figura 2.7. Tente grades mais esparsas (5 pontos) e mais densas (100 ou 1000 pontos). A densidade correta para sua grade √© determinada por qu√£o precisa voc√™ quer que sua aproxima√ß√£o seja. Mais pontos significa mais precis√£o. Neste exemplo simples, voc√™ pode exagerar e usar 100.000 pontos, mas n√£o haver√° muita mudan√ßa na infer√™ncia ap√≥s os primeiros 100.

Agora, para replicar as diferentes distribui√ß√µes a priori na Figura 2.5, tente estas linhas de c√≥digo ‚Äî uma de cada vez ‚Äî para a grade da distribui√ß√£o a priori:

```{r}
prior <- ifelse( p_grid < 0.5 , 0 , 1 )
prior <- exp( -5*abs( p_grid - 0.5 ) )
```

O restante do c√≥digo permanece o mesmo.

> **Pensando Mais um Pouco: Vetoriza√ß√£o.** Uma das caracter√≠sticas √∫teis do R √© que ele torna trabalhar com listas de n√∫meros quase t√£o f√°cil quanto trabalhar com valores √∫nicos. Ent√£o, embora ambas as linhas de c√≥digo acima n√£o digam nada sobre qu√£o densa √© sua grade, qualquer comprimento que voc√™ tenha escolhido para o vetor p_grid determinar√° o comprimento do vetor prior. No jarg√£o do R, os c√°lculos acima s√£o *vetorizados*, porque trabalham com listas de valores, *vetores*. Em um c√°lculo vetorizado, o c√°lculo √© realizado em cada elemento do vetor de entrada ‚Äî p_grid neste caso ‚Äî e a sa√≠da resultante, portanto, tem o mesmo comprimento. Em outros ambientes computacionais, o mesmo c√°lculo exigiria um *loop*. R tamb√©m pode usar loops, mas c√°lculos vetorizados s√£o tipicamente mais r√°pidos.

### Aproxima√ß√£o quadr√°tica {-}

Continuaremos com a aproxima√ß√£o por grade da distribui√ß√£o a posteriori do lan√ßamento do globo pelo restante deste cap√≠tulo. Mas em breve voc√™ ter√° que recorrer a outra aproxima√ß√£o, uma que faz suposi√ß√µes mais fortes. A raz√£o √© que o n√∫mero de valores √∫nicos a considerar na grade cresce rapidamente conforme o n√∫mero de par√¢metros em seu modelo aumenta.

Uma abordagem √∫til √© a **APROXIMA√á√ÉO QUADR√ÅTICA**. Sob condi√ß√µes bem gerais, a regi√£o perto do pico da distribui√ß√£o a posteriori ser√° quase gaussiana ‚Äî ou "normal" ‚Äî em forma. Isso significa que a distribui√ß√£o a posteriori pode ser utilmente aproximada por uma distribui√ß√£o gaussiana. Uma distribui√ß√£o gaussiana √© conveniente, porque pode ser completamente descrita por apenas dois n√∫meros: a localiza√ß√£o de seu centro (m√©dia) e sua dispers√£o (vari√¢ncia).

Uma aproxima√ß√£o gaussiana √© chamada de "aproxima√ß√£o quadr√°tica" porque o logaritmo de uma distribui√ß√£o gaussiana forma uma par√°bola.

O procedimento cont√©m dois passos:

- (1) Encontre a moda a posteriori. Isso √© geralmente alcan√ßado por algum algoritmo de otimiza√ß√£o.
- (2) Uma vez que voc√™ encontra o pico da distribui√ß√£o a posteriori, deve estimar a curvatura perto do pico. Essa curvatura √© suficiente para calcular uma aproxima√ß√£o quadr√°tica de toda a distribui√ß√£o a posteriori.

Para calcular a aproxima√ß√£o quadr√°tica dos dados de lan√ßamento do globo usando base R:

```{r}
# Encontrar o MAP (pico da posterior) via otimiza√ß√£o
W <- 6
L <- 3

# Fun√ß√£o log-posterior (prior uniforme + binomial)
log_post <- function(p) {
  dbinom(W, W + L, p, log = TRUE) + dunif(p, 0, 1, log = TRUE)
}

# Otimizar para encontrar o MAP
resultado <- optimize(log_post, interval = c(0, 1), maximum = TRUE)
p_map <- resultado$maximum

# Curvatura (desvio padr√£o da aproxima√ß√£o quadr√°tica)
delta <- 1e-4
d2 <- (log_post(p_map + delta) - 2 * log_post(p_map) + log_post(p_map - delta)) / delta^2
p_sd <- sqrt(-1 / d2)

cat(sprintf("MAP (m√©dia a posteriori): %.2f\n", p_map))
cat(sprintf("Desvio padr√£o (aprox. quadr√°tica): %.2f\n", p_sd))
cat(sprintf("Intervalo 89%%: [%.2f, %.2f]\n",
    qnorm(0.055, p_map, p_sd),
    qnorm(0.945, p_map, p_sd)))
```

```
MAP (m√©dia a posteriori): 0.67
Desvio padr√£o (aprox. quadr√°tica): 0.16
Intervalo 89%: [0.42, 0.92]
```

Voc√™ pode ler essa aproxima√ß√£o como: Supondo que a distribui√ß√£o a posteriori √© gaussiana, ela √© maximizada em 0,67 e seu desvio padr√£o √© 0,16.

Como j√° conhecemos a distribui√ß√£o a posteriori, vamos comparar para ver qu√£o boa √© a aproxima√ß√£o. Usaremos a abordagem anal√≠tica, que usa `dbeta`, para obter exatamente a resposta certa, sem aproxima√ß√µes:

```{r}
# Distribui√ß√£o a posteriori anal√≠tica (exata)
W <- 6
L <- 3
curve( dbeta(x, W+1, L+1), from=0, to=1,
       xlab="p", ylab="densidade", col="blue", lwd=2)

# Aproxima√ß√£o quadr√°tica
curve( dnorm( x , 0.67 , 0.16 ) , lty=2 , add=TRUE, col="black", lwd=2 )
legend("topleft", legend=c("Posterior exata", "Aprox. quadr√°tica"),
       col=c("blue","black"), lty=c(1,2), lwd=2)
```

![](cap-02-small-worlds-large-worlds-pt/_page_25_Figure_2.jpeg)

Figura 2.8. Precis√£o da aproxima√ß√£o quadr√°tica. Em cada gr√°fico, a distribui√ß√£o a posteriori exata √© plotada em azul, e a aproxima√ß√£o quadr√°tica √© plotada como a curva preta. Esquerda: Os dados de lan√ßamento do globo com n = 9 lan√ßamentos e w = 6 √°guas. Meio: O dobro da quantidade de dados, com a mesma fra√ß√£o de √°gua, n = 18 e w = 12. Direita: Quatro vezes mais dados, n = 36 e w = 24.

Conforme a quantidade de dados aumenta, a aproxima√ß√£o quadr√°tica melhora. Esse fen√¥meno, em que a aproxima√ß√£o quadr√°tica melhora com a quantidade de dados, √© muito comum.

### Markov chain Monte Carlo {-}

H√° muitos tipos importantes de modelos, como modelos multin√≠vel (efeitos mistos), para os quais nem a aproxima√ß√£o por grade nem a aproxima√ß√£o quadr√°tica √© sempre satisfat√≥ria. Tais modelos podem ter centenas ou milhares ou dezenas de milhares de par√¢metros. A aproxima√ß√£o por grade rotineiramente falha aqui, porque simplesmente demora demais.

Como resultado, v√°rias t√©cnicas contra-intuitivas de ajuste de modelos surgiram. A mais popular destas √© **Markov Chain Monte Carlo** (MCMC), que √© uma fam√≠lia de motores de condicionamento capazes de lidar com modelos altamente complexos.

O desafio conceitual com MCMC reside em sua estrat√©gia altamente n√£o √≥bvia. Em vez de tentar calcular ou aproximar a distribui√ß√£o a posteriori diretamente, t√©cnicas MCMC meramente sorteiam amostras da distribui√ß√£o a posteriori. Voc√™ termina com uma cole√ß√£o de valores de par√¢metros, e as frequ√™ncias desses valores correspondem √†s plausibilidades a posteriori. Voc√™ pode ent√£o construir uma imagem da distribui√ß√£o a posteriori a partir do histograma dessas amostras.

> **Pensando Mais um Pouco: Monte Carlo e o lan√ßamento do globo.** Uma cadeia de Markov funcional para o modelo de lan√ßamento do globo n√£o requer muito c√≥digo. O seguinte c√≥digo R ser√° suficiente:

```{r}
n_samples <- 1000
p <- rep( NA , n_samples )
p[1] <- 0.5
W <- 6
L <- 3
for ( i in 2:n_samples ) {
    p_new <- rnorm( 1 , p[i-1] , 0.1 )
    if ( p_new < 0 ) p_new <- abs( p_new )
    if ( p_new > 1 ) p_new <- 2 - p_new
    q0 <- dbinom( W , W+L , p[i-1] )
    q1 <- dbinom( W , W+L , p_new )
    p[i] <- ifelse( runif(1) < q1/q0 , p_new , p[i-1] )
}
```

Os valores em p s√£o amostras da distribui√ß√£o a posteriori. Para comparar com a distribui√ß√£o a posteriori anal√≠tica:

```{r}
# Visualizar a distribui√ß√£o das amostras MCMC
plot(density(p), xlim=c(0,1),
     main="MCMC vs. Posterior anal√≠tica",
     xlab="p", ylab="densidade")
# Sobrepor a posterior exata
curve( dbeta( x , W+1 , L+1 ) , lty=2 , add=TRUE, col="blue", lwd=2 )
legend("topleft", legend=c("MCMC", "Exata"),
       col=c("black","blue"), lty=c(1,2))
```

## Resumo

Este cap√≠tulo introduziu a mec√¢nica conceitual da an√°lise bayesiana de dados. O alvo da infer√™ncia na infer√™ncia bayesiana √© uma distribui√ß√£o de probabilidade a posteriori. Probabilidades a posteriori declaram os n√∫meros relativos de maneiras que cada causa conjecturada dos dados poderia ter produzido os dados. Esses n√∫meros relativos indicam plausibilidades das diferentes conjecturas. Essas plausibilidades s√£o atualizadas √† luz das observa√ß√µes, um processo conhecido como atualiza√ß√£o bayesiana.

Mais mecanicamente, um modelo bayesiano √© um composto de vari√°veis e defini√ß√µes distribucionais para essas vari√°veis. A probabilidade dos dados, frequentemente chamada de verossimilhan√ßa, fornece a plausibilidade de uma observa√ß√£o (dados), dado um valor fixo para os par√¢metros. A distribui√ß√£o a priori fornece a plausibilidade de cada valor poss√≠vel dos par√¢metros, antes de considerar os dados. As regras da probabilidade nos dizem que a maneira l√≥gica de calcular as plausibilidades, ap√≥s considerar os dados, √© usar o teorema de Bayes. Isso resulta na distribui√ß√£o a posteriori.

Na pr√°tica, modelos bayesianos s√£o ajustados aos dados usando t√©cnicas num√©ricas, como aproxima√ß√£o por grade, aproxima√ß√£o quadr√°tica e Markov chain Monte Carlo. Cada m√©todo imp√µe diferentes compromissos.
